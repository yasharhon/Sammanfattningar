\section{Inreprodukt}

\subsection{Definitioner}

\paragraph{Inreprodukt över $\R$}
En inreprodukt $\inprod{x}{y}$ på ett vektorrum $V$ över $\R$ är en avbildning $V\times V\to \R$ som är
\begin{itemize}
	\item bilinjär, dvs.
	\begin{itemize}
		\item $\inprod{x + y}{z} = \inprod{x}{z} + \inprod{y}{z}$.
		\item $\inprod{ax}{y} = a\inprod{x}{y}$.
		\item $\inprod{x}{y + z} = \inprod{x}{y} + \inprod{x}{z}$.
		\item $\inprod{x}{ay} = a\inprod{x}{y}$.
	\end{itemize}
	\item symmetrisk, dvs. $\inprod{x}{y} = \inprod{y}{x}$.
	\item positivt definit, dvs. $\inprod{x}{x} > 0$ om $x \neq 0$.
\end{itemize}

\paragraph{Inreprodukt över $\C$}
En inreprodukt $\inprod{x}{y}$ på ett vektorrum $V$ över $\C$ är en avbildning $V\times V\to \C$ som är
\begin{itemize}
	\item seskvilinjär, dvs. bilinjär, men $\inprod{ax}{y} = \cc{a}\inprod{x}{y}$.
	\item konjugatsymmetrisk, dvs. $\inprod{x}{y} = \cc{\inprod{y}{x}}$.
	\item positivt definit, dvs. $\inprod{x}{x} > 0$ om $x \neq 0$. Notera att detta och konjugatsymmetrin implicerar att $\inprod{x}{x}$ har ingen imaginärdel.
\end{itemize}

\paragraph{Inreprodukt från matris}
Vi kan få en inreprodukt i $\C^{n}$ från en matris genom
\begin{align*}
	\inprod{x}{y} = \sum a_{ij}\cc{x_{i}}{y_{j}} = (\cc{x})^{T}Ay.
\end{align*}

Om detta skall uppfylla konjugatsymmetri, ger det
\begin{align*}
	(\cc{x})^{T}Ay = \cc{(\cc{y})^{T}Ax} = y^{T}\cc{A}\cc{x}.
\end{align*}

Transponering av högersidan ger
\begin{align*}
	(\cc{x})^{T}Ay = (\cc{x})^{T}(\cc{A})^{T}y,
\end{align*}
och därmed uppfylls konjugatsymmetrin om
\begin{align*}
	A = (\cc{A})^{T}.
\end{align*}
Om matrisen uppfyller detta, säjs den vara konjugatsymmetrisk eller Hermitesk.

\paragraph{Norm}
Normen eller längden av en vektor definieras som
\begin{align*}
	\abs{x} = \sqrt{\inprod{x}{x}}.
\end{align*}

\paragraph{Vinkel}
Vinkeln $\theta$ mellan två vektorer definieras som
\begin{align*}
	\cos{\theta} = \frac{\inprod{x}{x}}{\abs{x}\abs{y}}.
\end{align*}

\paragraph{Ortogonalitet}
$x$ och $y$ är ortogonala om
\begin{align*}
	\inprod{x}{y} = 0.
\end{align*}

\paragraph{Ortogonalt komplement}
Om $W\subseteq V$ är ett delrum så finns det ett ortogonalt komplement
\begin{align*}
	W^{\perp} = \left\{x\in V: \inprod{x}{y} = 0\forall y\in W\right\} \subseteq V.
\end{align*}

\paragraph{Projektion}
Låt $V$ vara ett delrum med bas bas $B = \{e_{i}\}_{i= 0}^{n}$. Då definieras projektionen som
\begin{align*}
	\proj{V}{x} = \sum\limits_{i = 0}^{n}\frac{\inprod{x_{i}}{e_{j}}}{\norm{e_{i}}^{2}}e_{i}.
\end{align*}

\paragraph{Adjungerade operatorer}
På ett inreproduktrum $V$ är $\adj{L}$ den adjungerade operatorn till $L$ om
\begin{align*}
	\inprod{\adj{L}(x)}{y} = \inprod{x}{L(y)}\forall x, y\in V.
\end{align*}
\paragraph{Självadjungerade operatorer}
På ett inreproduktrum $V$ är $L$ självadjungerad om
\begin{align*}
	\inprod{L(x)}{y} = \inprod{x}{L(y)}\forall x, y\in V.
\end{align*}
Matrisen för en sådan operator sägs vara Hermitesk.

\paragraph{Cauchyföljder}
En Cauchyföljd är en följd som indexeras med naturliga talen och som uppfyller att för varje $\varepsilon > 0$ finns det ett $N$ så att
\begin{align*}
	i, j > N\implies \norm{x_{i} - x_{j}} < \varepsilon.
\end{align*}

\paragraph{Fullständiga rum}
Ett rum $V$ är fullständigt om alla Cauchy-följder konvergerar.

\paragraph{Hilbertrum}
Ett Hilbertrum är ett inreproduktrum som är fullständigt.

\paragraph{$\ell^{2}$}
Vi definierar $\ell^{2}(\C)$ som mängden av alla följder av tal i $\C$ så att
\begin{align*}
	\sum\limits_{i = 0}^{N}\abs{a_{i}}^{2}
\end{align*}
är begränsad, med inreprodukten
\begin{align*}
	\inprod{A}{B} = \sum\limits_{i = 0}^{N}\cc{a_{i}}b_{i}.
\end{align*}

\paragraph{$L^{2}$}
Vi definierar $L^{2}([0, 1], \C)$ som mängden av alla komplexvärda funktioner på $[0, 1]$ med inreprodukt
\begin{align*}
	\inprod{f}{g} = \inteval{0}{1}{\cc{f}(t)g(t)}{t}.
\end{align*}

\subsection{Satser}

\paragraph{Cauchy-Schwarz olikhet}

\begin{align*}
	\abs{\inprod{x}{y}} \leq \abs{x}\abs{y}.
\end{align*}

\proof

\paragraph{Triangelolikheten}

\begin{align*}
	\abs{x + y} \leq \abs{x} + \abs{y}.
\end{align*}

\paragraph{Ortogonalt komplement och vektorrum}
Om $V$ är ett ändligdimensionellt vektorrum, är
\begin{align*}
	W = W \oplus W^{\perp}.
\end{align*}

\proof
Det gäller att
\begin{align*}
	W \cap W^{\perp} = \{0\}.
\end{align*}

\paragraph{Bra och dualrum}
Om $V$ är ett inreproduktum, definierar båd $x\to\bra{x}$ och $x\to\bra{\cc{x}}$ en injektiv avbildning $V\to V^{*}$. Om $V$ är ändligdimensionellt, är detta dessutom en isomorfi.

\proof

\paragraph{Inreproduktrum och ortogonal bas}
Ett ändligdimensionellt vektorrum har en ortogonal bas.

\proof

\paragraph{Gram-Schmidts metod}
Låt $V$ vara ett vektorrum med ändlig dimension eller en uppräknelig bas $B = \{x_{i}\}_{i= 0}^{n}$. Då bildar vektorerna
\begin{align*}
	e_{i} = x_{i} - \sum\limits_{j = 0}^{i - 1}\frac{\inprod{e_{j}}{x_{i}}}{\norm{e_{j}}^{2}}e_{j}
\end{align*}
en ortogonal bas för $V$.

\proof

\paragraph{Matrisen för en adjungerad operator}
Låt $L$ beskrivas av matrisen $A$ i någon ortonormal bas. Då beskrivs $\adj{L}$ av matrisen $\cc{(A^{T})}$.

\proof
Vi har
\begin{align*}
	L(e_{i}) = \sum\limits_{j}a_{ij}e_{j},
\end{align*}
vilket ger
\begin{align*}
	\inprod{e_{i}}{L(e_{j})} = \inprod{e_{i}}{\sum\limits_{k}a_{jk}e_{k}} = \sum\limits_{k}\inprod{e_{i}}{a_{jk}e_{k}} = \sum\limits_{k}a_{jk}\inprod{e_{i}}{e_{k}} = \sum\limits_{k}a_{jk}\delta_{ik} = a_{ji}.
\end{align*}
Om $B$ är matrisen för $\adj{L}$, så vi nu att dens komponenter kan skrivas som $b_{ji} = \inprod{e_{i}}{\adj{L}(e_{j})}$. Vi utvecklar detta och får
\begin{align*}
	b_{ji} = \inprod{e_{i}}{\adj{L}(e_{j})} = \cc{\inprod{\adj{L}(e_{j})}{e_{i}}} = \cc{\inprod{e_{j}}{L(e_{i})}} = \cc{a_{ij}},
\end{align*}
och därmed är beviset klart.

\paragraph{Egenvärden för självadjungerade operatorer}
Självadjungerade operatorer har bara reella egenvärden.

\proof
\begin{align*}
	\inprod{L(x)}{x} = \inprod{x}{L(x)}.
\end{align*}
Detta kan utvecklas om $x$ är en egenvektor för att ge
\begin{align*}
	\cc{\lambda}\inprod{x}{x} = \lambda\inprod{x}{x},
\end{align*}
och beviset är klart.

\paragraph{Diagonalisering av självadjungerade operatorer}
Alla självadjungerade operatorer på ändligdimensionella inreproduktrum kan diagonaliseras.

\proof
Vi gör induktion över $\dim{V}$.

Det är trivialt för dimension $1$.

Annars, om vi har en egenvektor $x$ motsvarande egenvärdet $\lambda$, bilda $W = \Span{x}$. Då har man $L(W)\subseteq W$. Vidare, om $y\in W^{\perp}$, har man
\begin{align*}
	\inprod{x}{y} = 0\implies \inprod{\lambda x}{y} = \inprod{L(x)}{y} = \inprod{x}{L(y)} = 0,
\end{align*}
och $L(W^{\perp})\subseteq W^{\perp}$. Man kan vidare bilda en bas för $V$ med basen för $W^{\perp}$ och $x$. Matrisen för $L$ med avseende på denna basen är
\begin{align*}
	\mqty[
		\lambda & 0 \\
		0       & X
	].
\end{align*}
Per induktion finns det då en ortogonal bas för $W^{\perp}$ så att matrisen för $L$ på $W^{\perp}$ blir diagonal.

\paragraph{Ortogonal bas och självadjungerade operatorer}
Om $L$ är en självadjungerad operator på ett ändligdimensionellt vektorrum $V$, finns det en ortogonal bas av egenvektorer till $L$.

\proof

\paragraph{Självadjungerade operatorer och ortogonala egenvektorer}
Låt $x$ vara en egenvektor till $L$ med egenvärdet $\lambda $och $y$ vara en egenvektor med egenvärde $\mu$. Om $\lambda - \mu \neq 0$ är $\inprod{x}{y} = 0$.

\proof
\begin{align*}
	\inprod{L(x)}{y} = \inprod{x}{L(y)}.
\end{align*}
Vi använder att $x$ och $y$ är egenvektorer och får
\begin{align*}
	\cc{\lambda}\inprod{x}{y} = \mu\inprod{x}{y}.
\end{align*}
Enligt antagandet måste då $\inprod{x}{y} = 0$.