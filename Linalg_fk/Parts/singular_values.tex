\section{Singulärvärden}

\subsection{Definitioner}

\paragraph{Singulärvärden och singulära vektorer}
Låt $L: V\to W$. Ett singulärvärde till $L$ är ett icke-negativt tal $\sigma$ så att
\begin{align*}
	L(x) = \sigma y, \adj{L}(x) = \sigma x
\end{align*}
där $x, y\neq 0$. $x$ kallas en högersingulär vektor och $y$ en vänstersingulär vektor.

\paragraph{Singulärvärdesuppdelning}
Singulärvärdesuppdelningnen av matrisen $A$ för operatorn $L$ är faktoriseringen
\begin{align*}
	A = Y\Sigma\adj{X},
\end{align*}
där kolonnerna i $Y$ är de vänstersingulära vektorerna, kolonnerna i $Y$ är de högersingulära vektorerna och $\Sigma$ är en diagonalmatris med singulärvärdena i fallande ordning på diagonalen. Konstruktionen ger att $X$ och $Y$ är unitära.

\paragraph{Pseudoinverser}
Låt $A$ ha singulärvärdesuppdelning $Y\Sigma\adj{X}$. Då definieras pseudoinversen till $A$ som
\begin{align*}
	A^{+} = X\Sigma^{-1}\adj{Y}, \ \Sigma^{-1} =
	\mqty[
		D^{-1} & 0 \\
		0      & 0
	].
\end{align*}

\subsection{Satser}

\paragraph{Förenkling av linjära avbildningar}
Låt $L: V\to W$. Då kan man välja baser för $V$ och $W$ så att matrisen för $L$ ges av
\begin{align*}
	\mqty[
		I & 0 \\
		0 & 0
	].
\end{align*}

\proof
Välj delrum $V'$ och $W'$ så att $V = V'\oplus\ker{L}$ och $W = W'\oplus\Im{L}$, och bilda baser för $V$ och $W$ som utgår från baser för $V'$ respektiva bilden av basen till $V'$. Då verkar $L$ på dessa baserna enligt matrisen i satsen, och beviset är klart.

\paragraph{Möjlighet för singulärvärdesuppdelning}
Låt $L: V\to W$ vara linjär och $V$ och $W$ vara (ändligdimensionella) inreproduktrum. Då kan man välja ortonormala baser för $V$ och $W$ så att matrisen för $L$ ges av
\begin{align*}
	\mqty[
		D & 0 \\
		0 & 0
	],
\end{align*}
där $D$ är en positiv reell diagonalmatris.

\proof
Det gäller att $V = \ker{L}\oplus (\ker{L})^{\perp}$ och $W = \Im{L}\oplus (\Im{L})^{\perp}$. Restriktionen av $L$ till $(\ker{L})^{\perp}$ är injektiv på grund av linjariteten och surjektiv på grund av dimensionssatsen. Därmed är $L$ en isomorfi mellan $(\ker{L})^{\perp}$ och $\Im{L}$. Satsen är därmed bevisat om $L$ har rätt form i fallen där den är inverterbar.

Bilda nu $H: V\times W\to V\times W, H(x, y) = (\adj{L}(y), L(x))$. Denna har matris
\begin{align*}
	B = 
	\mqty[
		0 & \adj{A} \\
		A & 0
	].
\end{align*}
$H$ kommuterar vidare med $H^{2}$, och därmed är dessa två samtidigt diagonaliserbara. Egenvektorerna är på formen $(x_{i}, y_{i})$, och uppfyller
\begin{align*}
	\adj{A}y_{i} = \lambda_{i}x_{i},\ Ax_{i} = \lambda_{i}y_{i},\ \adj{A}Ax_{i} = \mu_{i}x_{i},\ A\adj{A}y_{i} = \mu_{i}y_{i}
\end{align*}
Vi får från detta att $\mu_{i} = \lambda_{i}^{2}$ och att $(x_{i}, -y_{i})$ även är en egenvektor med egenvärde $-\lambda_{i}$ ty
\begin{align*}
	\mqty[
		0 & \adj{A} \\
		A & 0
	]
	\mqty[
		x_{i} \\
		-y_{i}
	]
	=
	\mqty[
		-\adj{A}y_{i} \\
		Ax_{i}
	]
	=
	\mqty[
		-\lambda_{i}x_{i} \\
		\lambda_{i}y_{i}
	].
\end{align*}

Vi kan nu anta att alla egenvektorer är normerade och ordnade så att de positiva egenvärden kommer först. Då utgör $\{x_{i}\}$ och $\{y_{j}\}$ ortonormala baser för $V$ respektiva $W$. Vi vet att matrisen för $L$ med avseende på dessa baser är en diagonalmatris, men hur fan det här bevisar att elementerna är positiva vet inte ens Mats Boij.

\paragraph{Delvis singulärvärdesuppdelning}
Låt $A = Y\Sigma\adj{X}$, där $X$ har kolumner $x_{i}$ och $Y$ kolumner $y_{i}$ som motsvarar singulärvärdet $\sigma_{i}$. Då är
\begin{align*}
	A_{s} = \sum\limits_{i = 1}^{s}\sigma_{i}y_{i}\adj{y_{i}}
\end{align*}
den matris av rang $s$ som minimerar $\norm{A_{s} - A}$.

\proof

\paragraph{Pseudoinversens egenskaper}
Pseudoinversen är den unika lösningen till ekvationssystemet
\begin{align*}
	XAX = X,\ AXA = A,\ \adj{(AX)} = AX,\ \adj{(XA)} = XA.
\end{align*}

\proof

\paragraph{Minsta kvadrat-problem}
Bland alla minsta kvadrat-lösningar till $Ax = b$ är $x = A^{+}b$ den lösningen som själv har minst norm.

\proof

\subsection{Algoritmer}

\paragraph{Singulärvärdesuppdelning}
Högst tveksamt.

Låt $L: V\to W$. Vi vill hitta baser för $V$ och $W$ så att matrisen för $L$ blir på formen
\begin{align*}
	\mqty[
		I & 0 \\
		0 & 0
	].
\end{align*}
Detta görs vid att
\begin{itemize}
	\item välja en bas för $\ker{L}$.
	\item utvidga detta till en bas för $V$ vid att lägga till vektorer i början av basen.
	\item välja en bas för $W$ vid att utgå från avbildningarna av vektorerna i basen för $V$ och lägga på vektorer.
\end{itemize}

Om $V$ och $W$ är inreproduktrum och du vill välja en ON-bas för båda, kommer du få en diagonalmatris i stället för identitetsmatrisen.