\section{Derivata}

\subsection{Definitioner}

\paragraph{Partiella derivator}
Låt $f: D\to\R^p$ med $D\subset\R^n$. $f$ är partiellt deriverbar med avseende på $x_i$ i den inre punkten $\vect{a}\in D$ om gränsvärdet
\begin{align*}
	\limit{h}{0}\frac{f(\vect{a} + h\vect{e}_i) - f(\vect{a})}{h}
\end{align*}
existerar. Gränsvärdet kallas partiella derivatan av $f$ med avseende på $x_i$ i $\vect{a}$ och betecknas $\pdeval{f}{x_i}{\vect{a}}$.

\paragraph{Differentierbarhet}
Låt $f: D\to\R$ med $D\subset\R^n$. $f$ är differentierbar i $\vect{a}$ om $\exists A_1, \dots, A_n$ och en $\rho(\vect{h})$ så att
\begin{align*}
	f(\vect{a} + \vect{h}) - f(\vect{a}) = \sum\limits_{i = 1}^{n}A_ih_i + \abs{\vect{h}}\rho(\vect{h})
\end{align*}
och $\limit{\vect{h}}{\vect{0}}\rho(\vect{h}) = 0$. $f$ är differentierbar om detta är uppfylld för alla $\vect{a}\in D$.

\paragraph{$C^1$}
Låt $f: D\to\R$ med $D\subset\R^n$. $f$ är klass $C^1$ om $f$ är partiellt deriverbar och alla de partiella derivatorna är kontinuerliga i $D$.

\paragraph{$C^k$}
Låt $f: D\to\R$ med $D\subset\R^n$. $f$ är klass $C^k$ om $f$ alla partiella derivator till och med ordning $k$ existerar och är kontinuerliga i $D$.

\paragraph{Gradient}
Låt $f$ vara reellvärd och differentierbar i $\vect{x}$. Gradienten definieras som
\begin{align*}
	\grad{f} = \sum\limits_{i = 1}^{n}\pdeval{f}{x_i}{\vect{x}}\vect{e}_i.
\end{align*}

\paragraph{Riktningsderivata}
Låt $\abs{\vect{v}} = 1$. Derivatan av $f$ i punkten $\vect{a}$ i riktningen $\vect{v}$ är
\begin{align*}
	\grad_{\vect{u}}f = \limit{t}{0}\frac{f(\vect{a} + t\vect{v}) - f(\vect{a})}{t}.
\end{align*}

\paragraph{Stationära punkter}
$\vect{a}$ är en stationär punkt till $f$ om $\grad{f}(\vect{a}) = \vect{0}$.

\paragraph{Differentialer}
Låt $f:D\to\R$ med $D\subset\R^n$ öppen och låt $f$ vara differentierbar. Funktionen $\vect{h}\to\sum\pdeval{f}{x_i}{\vect{x}}h_i$ kallas differentialen av $f$ i $\vect{x}$ och betecknas $\dd{f} (\vect{x})$. Vid att skriva differentialen som en matris
\begin{align*}
	\dd{f} (\vect{x}) = \left[\pdeval{f}{x_1}{\vect{x}}\dots\pdeval{f}{x_n}{\vect{x}}\right]
\end{align*}
kan differentialet skrivas som en matrismultiplikation enligt
\begin{align*}
	\dd{f} (\vect{x})(\vect{h}) = \left[\pdeval{f}{x_1}{\vect{x}}\dots\pdeval{f}{x_n}{\vect{x}}\right]\vect{h}.
\end{align*}

\paragraph{Funktionalmatriser}
Låt $f:D\to\R^p$ med $D\subset\R^n$. $f$:s funktionalmatris definieras som
\begin{align*}
	\left[\begin{array}{ccc}
		\deval{f_1}{x_1}{\vect{x}} & \dots  & \deval{f_1}{x_n}{\vect{x}} \\
		\vdots                     & \ddots & \vdots \\
		\deval{f_p}{x_1}{\vect{x}} & \dots  & \deval{f_p}{x_n}{\vect{x}}
	\end{array}\right]
\end{align*}
och betecknas $f'(\vect{x}) = \dd{f} (\vect{x}) = \deval{(f_1\dots f_p)}{(x_1\dots x_n)}{\vect{x}}$.

\paragraph{Linjarisering}
Linjariseringen av en funktion $f$ ges av
\begin{align*}
	f(\vect{x} + \vect{h}) = f(\vect{x}) + \dd{f} (\vect{x})\vect{h}.
\end{align*}

\paragraph{Divergens}
Divergensen av ett vektorfält $\vect{u}$ definieras som
\begin{align*}
	\div{\vect{u}}(\vect{x}) = \sum\pdeval{u_i}{x_i}(\vect{x}).
\end{align*}

\paragraph{Rotation}
Rotation av ett vektorfält $\vect{u}: \R^3\to\R^3$ definieras som
\begin{align*}
	\curl{\vect{u}}(\vect{x}) = \left(\pdv{u_3}{x_2} - \pdv{u_2}{x_3}, \pdv{u_1}{x_3} - \pdv{u_3}{x_1}, \pdv{u_2}{x_1} - \pdv{u_1}{x_2}\right).
\end{align*}

\subsection{Satser}

\paragraph{Differentierbarhet och kontinuitet}
Låt $f$ vara differentierbar i $\vect{a}$. Då är $f$ kontinuerlig i $\vect{a}$.

\proof
Definitionen implicerar $\limit{\vect{h}}{\vect{0}}f(\vect{a} + \vect{h}) - f(\vect{a}) = 0$.

\paragraph{Differentierbarhet och partiell deriverbarhet}
Låt $f$ vara differentierbar i $\vect{a}$. Då är $f$ partiellt deriverbar med avseende på alla variabler i $\vect{a}$ och $\pdv{f}{x_i}(\vect{a}) = A_i$.

\proof
Med $\vect{h} = t\vect{e}_i$ ger definitionen av differentierbarhet
\begin{align*}
	\frac{f(\vect{a} + t\vect{e}_i) - f(\vect{a})}{t} = A_i + \frac{\abs{t}}{t}\rho(t\vect{e}_i).
\end{align*}
Gränsvärdet när $t$ går mot $0$ ger på den ena sidan definitionen av den partiella derivatan och $A_i$ på andra sidan.

\paragraph{Differentierbarhet av funktioner i $C^1$}
Varje $f\in C^1$ är differentierbar.

\proof
Låt $\vect{a}\in D$. Enligt envariabelsanalysens medelvärdesats har vi
\begin{align*}
	&f(\vect{a} + h_1\vect{e}_1) - f(\vect{a}) = \pdeval{f}{x_1}{\vect{a} + \theta _1h_1\vect{e}_1} \\
	&f(\vect{a} + h_1\vect{e}_1 + h_2\vect{e}_2) - f(\vect{a} + h_1\vect{e}_1) = \pdeval{f}{x_2}{\vect{a} + h_1\vect{e}_1 + \theta_2h_2\vect{e}_2} \\
	&\vdots \\
	&f(\vect{a} + \sum\limits_{i = 1}^{n}h_i\vect{e}_i) - f(\vect{a} + \sum\limits_{i = 1}^{n - 1}h_i\vect{e}_i) = \pdeval{f}{x_n}{\vect{a} + \sum\limits_{i = 1}^{n - 1}h_i\vect{e}_i + \theta_nh_n\vect{e}_n},
\end{align*}
där alla $\theta_i\in [0, 1]$. Eftersom de partiella derivatorna är kontinuerliga kan vi skriva
\begin{align*}
	\pdeval{f}{x_k}{\vect{a} + \sum\limits_{i = 1}^{k - 1}h_i\vect{e}_i + \theta_kh_k\vect{e}_k} = \pdeval{f}{x_k}{\vect{a}} + \rho_k(\sum\limits_{i = 1}^{n}h_i\vect{e}_i) = \pdeval{f}{x_k}{\vect{a}} + \rho_k(\vect{h}),
\end{align*}
där $\limit{\vect{h}}{\vect{0}}\rho(\vect{h}) = 0$. Då får man
\begin{align*}
	f(\vect{a} + \vect{h}) = \sum\limits_{i = 1}^{n}\left(\pdeval{f}{x_i}{\vect{a}} + \rho_i(\vect{h})\right)h_i.
\end{align*}

Den sista delen av beviset använder
\begin{align*}
	\limit{\vect{h}}{\vect{0}}\frac{\sum\limits_{i = 1}^{n}\rho_i(\vect{h})h_i}{\abs{\vect{h}}}.
\end{align*}

\paragraph{Allmänna kedjeregeln}
Låt $f: \R^n\to\R^p$ och $g: \R^q\to\R^n$ och låt alla komponenter av $f, g$ vara differentierbara. Då är alla komponenter av $f\circ g$ differentierbara. Med $u = f\circ g$ har vi
\begin{align*}
	\pdeval{u_i}{t_k}{\vect{t}} = \sum\limits_{i = 1}^{n}\pdeval{f}{x_i}{g(\vect{t})}\pdeval{g}{t_k}{\vect{t}}
\end{align*}
för varje komponent.

\paragraph{Specialfall: $p = 1$}
Låt $f$ vara en differentierbar funktion av $n$ variabler och $g: \R\to\R^n$, där alla $g_i$ är partiellt deriverbara. Då är $f\circ g$ deriverbar och
\begin{align*}
	\deval{f\circ g}{t}{t} = \sum\limits_{i = 1}^{n}\pdeval{f}{x_i}{g(t)}\deval{g_i}{t}{t}.
\end{align*}

\proof

\paragraph{Konstantfunktioner och gradient}
Låt $D\subset\R^n$ vara öppen och bågvis sammanhängande och $f\in C^1(D, R^n)$. Om $\grad{f(\vect{x})} = 0$ för alla $\vect{x}\in D$, är $f$ konstant i $D$.

\proof
Använd att
\begin{align*}
	\deval{f}{t}{\vect{x}(t)} = \grad{f(\vect{x}(t))}\cdot\deval{\vect{x}}{t}{t} = 0.
\end{align*}

\paragraph{Gradient och riktningsderivata}
Gradienten i riktning $\vect{v}$ ges av
\begin{align*}
	\grad_{\vect{v}}f(\vect{a}) = \grad{f}(\vect{a})\cdot\vect{v}.
\end{align*}

\proof
Bilda $u(t) = f(\vect{a} + t\vect{v}) = u(\vect{g}(t))$, vilket ger $\grad_{\vect{v}}f(\vect{a}) = \deval{u}{t}{0}$. Enligt kedjeregeln blir detta
\begin{align*}
	\sum\limits_{i = 1}^{n}\deval{f}{x_i}{0}\deval{g_i}{t}{0} = \grad{f}(\vect{a})\cdot\deval{(\vect{a} + t\vect{v})}{t}{0} = \grad{f}(\vect{a})\cdot\vect{v}.
\end{align*}

\paragraph{Maximal riktningsderivata}
$\grad{f(\vect{a})}$ pekar i den riktning i vilken $f$ växar snabbast i $\vect{a}$, och den maximala tillväxthastigheten är $\abs{\grad{f(\vect{a})}}$.

\proof
Cauchy-Schwarz-olikheten ger
\begin{align*}
	\grad_{\vect{u}}f = \grad{f}(\vect{a})\cdot\vect{v}\leq\abs{\grad{f}(\vect{a})}\abs{\vect{v}},
\end{align*}
med likhet om och endast om $\vect{v}$ är parallell med gradienten.

\paragraph{Gradient och nivåytor}
Låt $f: \R^n\to\R$ och $\grad{f}(\vect{a})\neq\vect{0}$. Då är gradienten normal på nivåytan $f(\vect{x}) = f(\vect{a})$.

\proof
Låt $\vect{x}(t)$ vara en $C^1$-kurva i nivåytan $f(\vect{x}) = f(\vect{a})$ så att $\vect{x}(0) = \vect{a}$. Detta ger
\begin{align*}
	0 = \deval{f\circ \vect{x}}{t}{0} = \grad{f}(\vect{a})\cdot\deval{\vect{x}}{t}{0}.
\end{align*}
Eftersom $\deval{\vect{x}}{t}{0}$ är parallell med nivåytan är beviset klart.

\paragraph{Symmetri av derivator i $C^2$}
För varje $f\in C^2$ gäller att
\begin{align*}
	\pdv{f}{x_i}{x_j} = \pdv{f}{x_j}{x_i}.
\end{align*}

\proof
Vi beviser endast för en tvåvariabelfunktion, då det allmänna fallet följer direkt från detta. Låt $q(h, k) = f(x + h, y + k) - f(x + h, y) - f(x, y + k) + f(x, y), \phi(t) = f(x + h, t) - f(x, t)$. Detta ger
\begin{align*}
	q(h, k) &= \phi(y + k) - \phi(y) \\
	        &= k\deval{\phi}{t}{y + \theta k} \\
	        &= k(\pdeval{f}{y}{x + h, y + \theta k} - \pdeval{f}{y}{x, y + \theta k}) \\
	        &= kh\pdv{f}{x}{y} (x + \eta h, y + \theta k),
\end{align*}
där vi har användt medelvärdesatsen två gånger. Då har vi
\begin{align*}
	\limit{(h, k)}{(0, 0)}\frac{q(h, k)}{hk} = \pdv{f}{x}{y} (x, y).
\end{align*}
Beviset kan upprepas i motsatt ordning, och detta fullförar beviset.

\paragraph{Taylors formel}
Låt $D\subset\R^2$ vara öppen, $(a, b)\in D$ och $f$ vara $C^3$. Då gäller:
\begin{align*}
	f(a + h, b + k) =& f(a, b) + \pdeval{f}{x}{a, b}h + \pdeval{f}{y}{a, b}k \\
	                 &+ \frac{1}{2}\left(\pdeval[2]{f}{x}{a, b}h^2 + 2\pdv{f}{x}{y} (a, b)hk + \pdeval[2]{f}{y}{a, b}k^2\right) \\
	                 &+ \left(\sqrt{h^2 + k^2}\right)^3B(h, k),
\end{align*}
där $B(h, k)$ är begränsad i en omgivning av origo.

\proof
Låt $F(t) = f(a + th, b + tk)$. Detta ger
\begin{align*}
	&\deval{F}{t}{t} = h\pdeval{f}{x}{a + th, b + tk} + k\pdeval{f}{y}{a + th, b + tk}, \\
	&\deval[2]{F}{t}{t} = h\left(h\pdeval[2]{f}{x}{a + th, b + tk} + k\pdv{f}{x}{y} (a, b)\right) + k\left(h\pdeval[2]{f}{y}{a + th, b + tk} + h\pdv{f}{x}{y} (a, b)\right), \\
	&\deval[3]{F}{t}{t} = \pdeval[3]{f}{x}{a, b}h^3 + 3\pdv{f}{x^2}{y} (a, b)h^2k + 3\pdv{f}{x}{y^2} (a, b)hk^2 + \pdeval[3]{f}{y}{a, b}k^3.
\end{align*}
$F$:s Taylorpolynom kring $0$ är
\begin{align*}
	F(t) = F(0) + \deval{F}{t}{0}t + \frac{1}{2!}\deval[2]{F}{t}{0}t^2 + \frac{1}{3!}\deval[2]{F}{t}{\theta}t^3.
\end{align*}
Vi evaluerar i $1$:
\begin{align*}
	F(1)            =& F(0) + \deval{F}{t}{0} + \frac{1}{2!}\deval[2]{F}{t}{0} + \frac{1}{3!}\deval[2]{F}{t}{\theta} \\
	f(a + h, b + k) =& f(a, b) + \pdeval{f}{x}{a, b}h + \pdeval{f}{y}{a, b}k \\
	                 &+ \frac{1}{2}\left(\pdeval[2]{f}{x}{a, b}h^2 + 2\pdv{f}{x}{y} (a, b)hk + \pdeval[2]{f}{y}{a, b}k^2\right) \\
	                &+ \frac{1}{3!}\deval[2]{F}{t}{\theta}.
\end{align*}
Vi analyserar sen den sista termen:
\begin{align*}
	\frac{\deval[3]{F}{t}{t}}{\left(\sqrt{h^2 + k^2}\right)^3} = \frac{1}{\left(\sqrt{h^2 + k^2}\right)^3}\left(\pdeval[3]{f}{x}{a, b}h^3 + 3\pdv{f}{x^2}{y} (a, b)h^2k + 3\pdv{f}{x}{y^2} (a, b)hk^2 + \pdeval[3]{f}{y}{a, b}k^3\right).
\end{align*}
Vi ser att detta är konvergent eftersom vi t.ex. kan betrakta
\begin{align*}
	\abs{\frac{3\pdv{f}{x^2}{y} (a, b)h^2k}{\left(\sqrt{h^2 + k^2}\right)^3}}\leq C\frac{\abs{h}^2}{h^2 + k^2}\frac{\abs{k}}{\sqrt{h^2 + k^2}}\leq C.
\end{align*}
Derivatan är kontinuerlig, vilket enligt sats garanterar att den är begränsad. Därmed är den sista termen på rätt form, och beviset är klart.

\paragraph{Lokala extrempunkter och partiella derivator}
Om $f$ har ett lokalt extremvärde i $\vect{a}\in D$ och $f$ är partiellt deriverbar i $\vect{a}$ är $\pdeval{f}{x_i}{\vect{a}} = 0, i = 1, \dots, n$.

\proof
Följer av motsvarande sats i en variabel applicerad på $x_i\to f(a_1, \dots, x_i, \dots, a_n)$.

\paragraph{Kvadratiska former och extrempunkt}
Låt $(a, b)$ vara en inre punkt till $D$ och en stationär punkt till $f$. Om $f$:s Taylorpolynom kring $(a, b)$ ges av $f(a + h, b + k) = c + Q(h, k)$. Då gäller att:
\begin{itemize}
	\item Om $Q$ är positivt definit har $f$ ett strängt lokalt minimum i $(a, b)$.
	\item Om $Q$ är negativt definit har $f$ ett strängt lokalt maximum i $(a, b)$.
	\item Om $Q$ är indefinit har $f$ en sadelpunkt (varken ett maximum eller ett minimum) i $(a, b)$.
\end{itemize}

\paragraph{Små ändringar och funktionalmatriser}
Låt $f:D\to\R^p$ med $D\subset\R^n$ vara $C^1$. Då kan vi för små $\abs{\vect{h}}$ skriva
\begin{align*}
	f(\vect{x} + \vect{h}) = f(\vect{x}) + \dd{f} (\vect{x})\vect{h} + \abs{\vect{h}}\rho (\vect{h})
\end{align*}
där $\rho$ tar värden i $\R^p$ och $\limit{\vect{h}}{\vect{0}}\rho (\vect{h}) = \vect{0}$.

\proof
Betrakta varje komponent.

\paragraph{Kedjeregeln och funktionalmatriser}
\begin{align*}
	\dd{(f\circ g)} (\vect{t}) = \dd{f} (g(\vect{t}))\dd{g} (\vect{t})
\end{align*}

\proof
Inses lätt.

\paragraph{Derivation under integraltecken}
Antag att $f, \pdv{f}{s}$ är kontinuerliga i $\alpha < s < \beta, a\leq x\leq b$. Då är funktionen $F:\R\to\R, s\to\int\limits_{a}^{b}f(s, x)\dd{x}$ deriverbar i $\alpha < s < \beta$ och
\begin{align*}
	\deval{F}{s}{s} = \int\limits_{a}^{b}\deval{f}{s}{s, x}\dd{x}.
\end{align*}

\proof

\paragraph{Utvidgad derivation under integraltecken}
Antag att $f, \pdv{f}{s}$ är kontinuerliga i $\alpha < s < \beta, A\leq x\leq B$. Låt $b$ vara en $C^1$-funktion av $\alpha < s < \beta$ med $A < b(s) < B$. Då är $F:\R\to\R, s\to\int\limits_{a}^{b(s)}f(s, x)\dd{x}$ deriverbar och
\begin{align*}
	\deval{F}{s}{s} = \int\limits_{a}^{b}\deval{f}{s}{s, x}\dd{x} + f(s, b(s))\deval{b}{s}{s}.
\end{align*}

\paragraph{Derivation under integraltecken för generaliserade integraler}
Antag att 
\begin{itemize}
	\item $f, \pdv{f}{s}$ är kontinuerliga i $\alpha < s < \beta, x\geq a$.
	\item $F(s) = \int\limits_{a}^{\infty}f(s, x)\dd{x}$ är konvergent för $\alpha < s < \beta$.
	\item Till varje kompakta delintervall $[\alpha_1, \beta_1]\subset (\alpha, \beta)$ finns en majorerande funktion $g$ så att
	\begin{itemize}
		\item $\abs{\pdeval{f}{s}{s, x}} < g(x)\ \forall\ s\in [\alpha_1, \beta_1], x\geq a$.
		\item $\int\limits_{a}^{\infty}g(x)\dd{x}$ är konvergent.
	\end{itemize}
\end{itemize}
Då är $F$ deriverbar och
\begin{align*}
	\deval{F}{s}{s} = \int\limits_{a}^{\infty}\deval{f}{s}{s, x}\dd{x}.
\end{align*}

\proof