\section{Matriser}

\subsection{Definitioner}

\paragraph{Matris-vektor-produkt}
Betrakta $m\times n$-matrisen
\begin{align*}
	A =
	\left[\begin{array}{cccc|c}
    	a_{1,1} & a_{1,2} & \dots  & a_{1,n} & b_1 \\
    	a_{2,1} & a_{2,2} & \dots  & a_{2,n} & b_2 \\
    	\vdots  & \vdots  & \ddots & \vdots  & \vdots \\
	    a_{m,1} & a_{m,2} & \dots  & a_{m,n} & b_n
	\end{array}\right]
\end{align*}
och vektoren i $\R^n$
\begin{align*}
	\vectorbold{x} =
	\left[\begin{array}{c}
    	x_1    \\
    	x_2    \\
    	\vdots \\
	    x_n
	\end{array}\right]
\end{align*}
Matrisproduktet $A\vectorbold{x}$ definieras som vektoren
\begin{align*}
	A\vectorbold{x} =
	\left[\begin{array}{c}
    	a_{1,1}x_1 + a_{1,2}x_2 + \dots + a_{1,n}x_n \\
    	a_{2,1}x_1 + a_{2,2}x_2 + \dots + a_{2,n}x_n \\
    	\vdots                                       \\
	    a_{m,1}x_1 + a_{m,2}x_2 + \dots + a_{m,n}x_n
	\end{array}\right]
\end{align*}
i $\R^m$.

\paragraph{Homogena ekvationssystem}
Ett homogent ekvationssystem kan skrivas på formen
\begin{align*}
	A\vect{x} = \vect{0}.
\end{align*}
Motsatsen är då inhomogena ekvationssystem.

\paragraph{Addition av matriser}
För två matriser $A = (a_{i,j}), B = (b_{i,j})$ har man
\begin{align*}
	A + B = (a_{i,j} + b_{i,j}).
\end{align*} 

\paragraph{Mutliplikation av matriser med konstanter}
För en matris $A = (a_{i,j})$ har man
\begin{align*}
	cA = (ca_{i,j}), c\in\R.
\end{align*}

\paragraph{Diagonalmatriser}
En matris $D = (d_{i,j})$ kallas en diagonal matris om $d_{i,j} = 0$ när $i\neq j$.

\paragraph{Transponat}
För en matris $A = (a_{i,j})$ definieras transponatet som $A^T = (a_{j,i})$.

\paragraph{Matrismultiplikation}
Matrismultiplikation av en $m\times p$-matris $A$ och en $p\times n$-matris $B$ ges av
\begin{align*}
	AB = C: c_{i,j} = \sum\limits_{k = 1}^{p} a_{i, k}b_{k,j}.
\end{align*}

\paragraph{Inversen av en matris}
En matris $A$ sin invers $A^{-1}$ uppfyller
\begin{align*}
	AA^{-1} = A^{-1}A = I.
\end{align*}

\paragraph{Elementärmatriser}
En matris $E$ är en elementärmatris om produktet $EA$ kan fås vid att göra en radoperation på $A$.

\paragraph{Rang}
Rangen till en matris, skrivit som $\rank A$, är $\dim{\Col A}$.

\paragraph{Determinant}
För en $n\times n$-matris $A$ ges determinanten av
\begin{align*}
	\det{A} = \abs{A} &= \sum\limits_{i = 1}^{n}(-1)^{i + j}a_{ij}\det{A_ij} \\
	&= \sum\limits_{j = 1}^{n}(-1)^{i + j}a_{ij}\det{A_ij},
\end{align*}
var $A_{ij}$ är matrisen $A$ utan rad $i$ och kolumn $j$. De två summorna visar att man kan räkna ut determinanten vid att utveckla den långs en given kolumn $j$ i första fallet eller en given rad $i$ i det andra fallet. Formelen är rekursiv, och base case är $n=2$, som ges av
\begin{align*}
	\mdet{a & d \\ c & b} = ab - cd.
\end{align*}

\subsection{Satser}

\paragraph{Matriskolumner och linjära höljen}
Följande påståenden är ekvivalenta:
\begin{itemize}
	\item[a)] $A\vectorbold{x} = \vect{b}$ har lösning för varje
	\item[b)] Varje $\vect{b}\in \R^{m}$ är en linjär kombination av kolumnerna i $A$.
	\item[c)] $\Span{\vect{A_1}, \vect{A_2}, \dots, \vect{A_n}} = \R^m$.
	\item[d)] Den reducerade matrisen till $A$ har $m$ ledande ettor.
\end{itemize}

\subparagraph{Bevis}
Ekvivalensen till a, b och c är vel trivial eller någonting.

Antag att c gäller och att A ej har $m$ ledande ettor. Då måste man vid Gauss-Jordan-elimination av $A$ få en rad med bara nollor. Antag att detta är sista raden i matrisen. Betrakta vektorn
\begin{align*}
	\vect{b}' =
	\left[\begin{array}{c}
    	0    \\
    	0    \\
    	\vdots \\
	    1
	\end{array}\right]
\end{align*}
Eftersom Gauss-Jordan-elimination inte ändrar det linjära höljet av kolummnerna till en matris, borde man kunne hitta en kombination av elementerna i den sista raden i $A$ så att man får $1$, eftersom $\vect{b}'\in\R^m$. Då alla elementerna i denna raden är nollor, är detta omöjligt.

\paragraph{Lösningen till inhomogena ekvationssystem}
Om det inhomogena ekvationssystemet
\begin{align*}
	A\vect{x} = \vect{0}
\end{align*}
har lösningen $\vect{x}_\text{h}$, har det inhomogena ekvationssystemet
\begin{align*}
	A\vect{x} = \vect{b}
\end{align*}
lösningen $\vect{x} = \vect{x}_\text{h} + \vect{x}_\text{i}$, var $\vect{x}_\text{i}$ är någon vektor som uppfyllar ekvationssystemet.

\subparagraph{Bevis}
Ganska enkelt.

\paragraph{Linjärt beroende av kolumner i en matris}
Kolumnerna i en matris är linjärt oberoende omm (om och endast om) $A\vect{x} = \vect{0}$ endast har den triviala lösningen. Specielt gäller det att om antal rader är mindre än antal kolumner är kolumnvektorerna linjärt beroende.

\subparagraph{Bevis}
Någonting med radreduktion.

\paragraph{Inverterbarhet av en matris}
En matris $A$ är inverterbar om och endast om $\det A = 0$.

\subparagraph{Bevis}
Använd elementärmatriser.

\paragraph{Rangsatsen}
För en $n\times m$-matris $A$ är $\rank A + \dim{\Null A} = m$.

\subparagraph{Bevis}
Something something pivotkolumner.

\paragraph{Determinanten för triangulära matriser}
För en triangulär $n\times n$-matris $A$, dvs. en matris som har endast nollor över eller under diagonalen, ges determinanten av
\begin{align*}
	\det{A} = \prod\limits_{i = 1}^{n} a_{ii}.
\end{align*}

\subparagraph{Bevis}
Inses lätt.

\paragraph{Determinant och elementärmatriser}
För en elementärmatris $E$ har man
\begin{align*}
	\det{E} =
	\begin{cases}
		-1, &E\text{ byter plats på två rader.} \\
		1,  &E\text{ adderar en multippel av en rad till en annan.} \\
		t,  &E\text{ multiplicerar en rad med en skalär} t\neq 0.
	\end{cases}
\end{align*}
och att
\begin{align*}
	B = EA \implies \det{B} = \det{E}\det{A}
\end{align*}

\subparagraph{Bevis}
Radreducera med matriser.

\paragraph{Determinant för matrisprodukt}
\begin{align*}
	\det{AB} = \det{A}\det{B}
\end{align*}

\subparagraph{Bevis}
Fallindelning och annat bra.