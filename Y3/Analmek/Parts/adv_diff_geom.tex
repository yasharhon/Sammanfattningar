\section{Advanced Differential Geometry}

In this part we will expand on the previously discussed concepts of differential geometry, mainly by incorporating our knowledge of tensors into it.

\paragraph{The Metric Tensor}
The metric tensor $g$ is a rank $2$ tensor. We start by defining it as $g(\vb{v}, \vb{w}) = \vb{v}\cdot\vb{w}$, but more generally the metric tensor defines the inner product.

The metric tensor is symmetric. Its components satisfy
\begin{align*}
	v_{a} = \vb{E}_{a}\cdot v^{b}\vb{E}_{b} = g(\vb{E}_{a}, \vb{E}_{b})v^{b} = g_{ab}v^{b},
\end{align*}
and likewise
\begin{align*}
	v^{a} = g^{ab}v_{b}
\end{align*}
where $\vb{v}$ is a vector. This demonstrates the capabilities of the metric to raise and lower indices.

We note that
\begin{align*}
	v_{a} = g_{ab}v^{b} = g_{ab}g^{bc}v_{c},
\end{align*}
which implies $g_{ab}g^{bc} = \kdelta{a}{c}$.

\example{The Metric in Polar Coordinates}
The contravariant components of the metric tensor, according to the definition, are
\begin{align*}
	g_{rr} = \tb{r}\cdot\tb{r} = 1,\ g_{r\phi} = g_{\phi r} = \tb{r}\cdot\tb{\phi} = 0,\ g_{\phi\phi} = \tb{\phi}\cdot\tb{\phi} = r^{2}.
\end{align*}
Likewise, the covariant components are
\begin{align*}
	g^{rr} = \db{r}\cdot\db{r} = 1,\ g_{r\phi} = g_{\phi r} = \db{r}\cdot\db{\phi} = 0,\ g_{\phi\phi} = \db{\phi}\cdot\db{\phi} = \frac{1}{r^{2}}.
\end{align*}

\paragraph{Christoffel Symbols}
When computing the derivative of a vector quantity, one must account both for the change in the quantity itself and the change in the basis vectors. We define the Christoffel symbols according to
\begin{align*}
	\del{b}{\tb{a}} = \chris{c}{b}{a}\tb{c}.
\end{align*}
These can be computed according to
\begin{align*}
	\db{c}\cdot\del{b}{\tb{a}} = \db{c}\cdot\chris{d}{b}{a}\tb{d} = \kdelta{d}{c}\chris{d}{b}{a} = \chris{c}{b}{a}.
\end{align*}
Note that
\begin{align*}
	\del{a}{\tb{b}} = \del{a}{\del{b}{\vb{r}}} = \del{b}{\del{a}{\vb{r}}} = \del{b}{\tb{a}},
\end{align*}
which implies
\begin{align*}
	\chris{c}{b}{a} = \chris{c}{a}{b}.
\end{align*}

Do the Christoffel symbols define a tensor? Clearly they do not. One simple counterexample is when converting from Cartesian coordinates to any non-trivial coordinate system. In Cartesian coordinates all Christoffel symbols are zero, and no linear combination of these could possibly produce non-zero values. There is a transformation rule, however. To find it, we study
\begin{align*}
	\tensor{(\Gamma^{\prime})}{^{a}_{bc}} &= (\db{a})^{\prime}\cdot\del[\prime]{b}{(\tb{c})^{\prime}} \\
	                                      &= \del{d}{(\chi')^{a}}\db{d}\cdot\del[\prime]{b}{(\del[\prime]{c}{\chi^{f}}\tb{f})} \\
	                                      &= \del{d}{(\chi')^{a}}\db{d}\cdot(\tb{f}\del[\prime]{b}{\del[\prime]{c}{\chi^{f}}} + \del[\prime]{c}{\chi^{f}}\del[\prime]{b}{\tb{f}}) \\
	                                      &= \del{d}{(\chi')^{a}}(\kdelta{f}{d}\del[\prime]{b}{\del[\prime]{c}{\chi^{f}}} + \del[\prime]{c}{\chi^{f}}\db{d}\cdot\del[\prime]{b}{\chi^{g}}\del{g}{\tb{f}}) \\
	                                      &= \del{d}{(\chi')^{a}}(\del[\prime]{b}{\del[\prime]{c}{\chi^{d}}} + \del[\prime]{c}{\chi^{f}}\del[\prime]{b}{\chi^{g}}\chris{d}{g}{f}) \\
	                                      &= \del{d}{(\chi')^{a}}\del[\prime]{c}{\chi^{f}}\del[\prime]{b}{\chi^{g}}\chris{d}{g}{f} + \del{d}{(\chi')^{a}}\del[\prime]{b}{\del[\prime]{c}{\chi^{d}}}.
\end{align*}

\example{Christoffel Symbols in Polar Coordinates}
To compute these, we need partial derivative of the basis vectors. We have
\begin{align*}
	\del{r}{\tb{r}} = \vb{0},\ \del{\phi}{\tb{r}} = \del{r}{\tb{\phi}} = \frac{1}{r}\tb{\phi},\ \del{\phi}{\tb{\phi}} = -r\tb{r}.
\end{align*}
We thus obtain
\begin{align*}
	\chris{a}{r}{r} = 0,\ \chris{r}{r}{\phi} = 0,\ \chris{\phi}{r}{\phi} = \frac{1}{r},\ \chris{r}{\phi}{\phi} = -r,\ \chris{\phi}{\phi}{\phi} = 0.
\end{align*}

\paragraph{Covariant Derivatives}
The partial derivate of $\vb{v} = v^{a}\tb{a}$ with respect to $\chi^{a}$ is given by
\begin{align*}
	\del{a}{\vb{v}} = \tb{b}\del{a}{v^{b}} + v^{b}\del{a}{\tb{b}} = \tb{b}\del{a}{v^{b}} + v^{b}\chris{c}{a}{b}\tb{c}.
\end{align*}
Renaming the summation indices yields
\begin{align*}
	\del{a}{\vb{v}} = \tb{b}(\del{a}{v^{b}} + v^{c}\chris{b}{a}{c}),
\end{align*}
which contains one term from the change in the coordinates and one term from the change in basis.

Realizing that derivatives of vector quantities must take both of these into account in order to transform like a tensor, we would like to define a differentiation operation that takes both of these to account when differentiating vector components. This is the covariant derivative. We define its action on contravariant vector components as
\begin{align*}
	\dcov{a}{v^{b}} = \del{a}{v^{b}} + v^{c}\chris{b}{a}{c},
\end{align*}
such that
\begin{align*}
	\del{a}{\vb{v}} = E_{b}\dcov{a}{v^{a}}.
\end{align*}
In a similar fashion we would like to define its action on covariant vector components. To do this, we use the fact that
\begin{align*}
	\del{a}{(\tb{b}\cdot\db{c})} = \del{a}{\kdelta{b}{c}} = 0.
\end{align*}
The product rule yields
\begin{align*}
	\tb{b}\cdot\del{a}{\db{c}} + \db{c}\cdot\del{a}{\tb{b}} = \tb{b}\cdot\del{a}{\db{c}} + \db{c}\cdot\chris{d}{a}{b}\tb{d} = \tb{b}\cdot\del{a}{\db{c}} + \kdelta{d}{c}\cdot\chris{d}{a}{b} = \tb{b}\cdot\del{a}{\db{c}} + \chris{c}{a}{b},
\end{align*}
which implies
\begin{align*}
	\del{a}{\db{c}} = -\chris{c}{a}{b}\db{b}.
\end{align*}
Repeating the steps above now yields
\begin{align*}
	\dcov{a}{v_{b}} = \del{a}{v_{b}} - \chris{c}{a}{b}v_{c}.
\end{align*}

\paragraph{Covariant Derivatives of Tensor Fields}
Next we study the derivatives of a tensor field
\begin{align*}
	\tau = \tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}\tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}.
\end{align*}
The tensor basis element differentiates according to the product rule, but with multiplication replaced by the tensor product. Hence
\begin{align*}
	\del{a}{\tau} &= \tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}\del{a}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} + \tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}\del{a}{\tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}} \\
	              &= \tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}\del{a}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} + \tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}\left(\sum\limits_{k = 1}^{n}\chris{c_{k}}{a}{a_{k}}\tensor*{e}{^{b_{1}\dots b_{m}}_{c_{1}\dots c_{n}}} - \sum\limits_{l = 1}^{m}\chris{b_{l}}{a}{d_{l}}\tensor*{e}{^{d_{1}\dots d_{m}}_{a_{1}\dots a_{n}}}\right) \\
	              &= \tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}\del{a}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} + \sum\limits_{k = 1}^{n}\tensor*{\tau}{^{c_{1}\dots c_{n}}_{b_{1}\dots b_{m}}}\chris{a_{k}}{a}{c_{k}}\tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}} - \sum\limits_{l = 1}^{m}\tensor*{\tau}{^{a_{1}\dots a_{n}}_{d_{1}\dots d_{m}}}\chris{d_{l}}{a}{b_{l}}\tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}} \\
	              &= \tensor*{e}{^{b_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}\left(\del{a}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} + \sum\limits_{k = 1}^{n}\tensor*{\tau}{^{c_{1}\dots c_{n}}_{b_{1}\dots b_{m}}}\chris{a_{k}}{a}{c_{k}} - \sum\limits_{l = 1}^{m}\tensor*{\tau}{^{a_{1}\dots a_{n}}_{d_{1}\dots d_{m}}}\chris{d_{l}}{a}{b_{l}}\right).
\end{align*}
We thus define
\begin{align*}
	\dcov{a}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} = \del{a}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} + \sum\limits_{k = 1}^{n}\tensor*{\tau}{^{c_{1}\dots c_{n}}_{b_{1}\dots b_{m}}}\chris{a_{k}}{a}{c_{k}} - \sum\limits_{l = 1}^{m}\tensor*{\tau}{^{a_{1}\dots a_{n}}_{d_{1}\dots d_{m}}}\chris{d_{l}}{a}{b_{l}}.
\end{align*}

\paragraph{The Gradient of a Tensor Field}
Based on the above, the directional derivative of a tensor field is
\begin{align*}
	\grad_{\vb{n}}{\tau} = n^{a}\del{a}{\tau}.
\end{align*}
This is equal to the contraction of $\vb{n}$ with the object
\begin{align*}
	\grad{\tau} = \db{c}\otimes\del{c}{\tau},
\end{align*}
which is defined as the gradient of $\tau$. More explicitly, we have
\begin{align*}
	\grad{\tau} = \tensor*{e}{^{cb_{1}\dots b_{m}}_{a_{1}\dots a_{n}}}\dcov{c}{\tensor*{\tau}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}}.
\end{align*}
It has the interesting property of having a rank one higher than $\tau$, which matches what we know - for instance, the gradient transforms a scalar into a vector.

\paragraph{Christoffel Symbols and the Metric}
The derivatives of the metric tensor are given by
\begin{align*}
	\del{c}{g_{ab}} = \tb{a}\cdot\del{c}{\tb{b}} + \tb{b}\cdot\del{c}{\tb{a}} = \tb{a}\cdot\chris{d}{c}{b}\tb{d} + \tb{b}\cdot\chris{d}{c}{a}\tb{d} = \chris{d}{c}{b}g_{ad} + \chris{d}{c}{a}g_{bd}.
\end{align*}
Multiplying by $g^{ea}$ and summing over $a$ yields
\begin{align*}
	g^{ea}\del{c}{g_{ab}} = \chris{d}{c}{b}g_{ad}g^{ea} + \chris{d}{c}{a}g_{bd}g^{ea} = \chris{d}{c}{b}g_{da}g^{ae} + \chris{d}{c}{a}g_{bd}g^{ea} = \chris{e}{c}{b} + \chris{d}{c}{a}g_{bd}g^{ea}.
\end{align*}
The hope is that this can be used to obtain an expression for the Christoffel symbols. To try to do that, we will compare this to the expression obtained by switching $c$ and $b$. This expression is
\begin{align*}
	g^{ea}\del{b}{g_{ac}} = \chris{e}{b}{c} + \chris{d}{b}{a}g_{cd}g^{ea} = \chris{e}{c}{b} + \chris{d}{b}{a}g_{cd}g^{ea},
\end{align*}
yielding
\begin{align*}
	\chris{e}{c}{b} &= \frac{1}{2}\left(g^{ea}\del{c}{g_{ab}} + g^{ea}\del{b}{g_{ac}} - \chris{d}{c}{a}g_{bd}g^{ea} - \chris{d}{b}{a}g_{cd}g^{ea}\right) \\
	                &= \frac{1}{2}g^{ea}\left(\del{c}{g_{ab}} + \del{b}{g_{ac}} - \chris{d}{a}{c}g_{bd} - \chris{d}{a}{c}g_{cd}\right) \\
	                &= \frac{1}{2}g^{ea}\left(\del{c}{g_{ab}} + \del{b}{g_{ac}} - \del{a}{g_{bc}}\right).
\end{align*}

\paragraph{Curve Length}
Consider some curve parametrized by $t$, and let $\dot{\vb{\gamma}}$ denote its tangent. The curve length is given by
\begin{align*}
	\dd{s}^{2} = \dd{\vb{x}}\cdot\dd{\vb{x}} = g(\dot{\vb{\gamma}}, \dot{\vb{\gamma}})\dd{t}^{2} = g_{ab}\dot{\chi^{a}}\dot{\chi^{b}}\dd{t}^{2}.
\end{align*}
The curve length is now given by
\begin{align*}
	L = \integ{}{}{t}{\sqrt{g_{ab}\dot{\chi^{a}}\dot{\chi^{b}}}}.
\end{align*}

\paragraph{Geodesics}
A geodesic is a curve that extremises the curve length between two points. From variational calculus, it is known that such curves satisfy the Euler-Lagrange equations, and we would like a differential equation that describes such a curve. By defining $\mathcal{L} = \sqrt{g_{ab}\dot{\chi}^{a}\dot{\chi}^{b}}$, the Euler-Lagrange equations for the curve length becomes
\begin{align*}
	\del{\chi^{a}}{\mathcal{L}} - \dv{t}\del{\dot{\chi}^{a}}{\mathcal{L}} = 0.
\end{align*}
The Euler-Lagrange equation thus becomes
\begin{align*}
	&\frac{1}{2\mathcal{L}}\dot{\chi}^{b}\dot{\chi}^{c}\del{a}{g_{bc}} - \dv{t}\left(\frac{1}{2\mathcal{L}}g_{bc}(\dot{\chi}^{b}\kdelta{a}{c} + \dot{\chi}^{c}\kdelta{a}{b})\right) = 0, \\
	&\frac{1}{2\mathcal{L}}\dot{\chi}^{b}\dot{\chi}^{c}\del{a}{g_{bc}} - \dv{t}\left(\frac{1}{2\mathcal{L}}(g_{ba}\dot{\chi}^{b} + g_{ac}\dot{\chi}^{c}\right) = 0, \\
	&\frac{1}{2\mathcal{L}}\dot{\chi}^{b}\dot{\chi}^{c}\del{a}{g_{bc}} - \dv{t}\left(\frac{1}{\mathcal{L}}g_{ac}\dot{\chi}^{c}\right) = 0.
\end{align*}
Expanding the time derivative yields
\begin{align*}
	\frac{1}{2\mathcal{L}}\dot{\chi}^{b}\dot{\chi}^{c}\del{a}{g_{bc}} - \frac{1}{\mathcal{L}}\dv{t}(g_{ac}\dot{\chi}^{c}) + g_{ac}\dot{\chi}^{c}\frac{1}{\mathcal{L}^{2}}\dv{\lag}{t} = \frac{1}{2\mathcal{L}}\dot{\chi}^{b}\dot{\chi}^{c}\del{a}{g_{bc}} - \frac{1}{\lag}\dv{t}(g_{ac}\dot{\chi}^{c}) + \frac{1}{\lag}g_{ac}\dot{\chi}^{c}\dv{\ln{\lag}}{t} = 0.
\end{align*}
The curve may be reparametrized such that $\lag$ is equal to $1$ everywhere, yielding
\begin{align*}
	\frac{1}{2\mathcal{L}}\left(\dot{\chi}^{a}\dot{\chi}^{b}\del{c}{g_{ab}} - \dv{t}(2\dot{\chi}^{a}g_{ac})\right) = 0.
\end{align*}
We note that the expression in the paranthesis is the Euler-Lagrange equation for the integral of $\mathcal{L}^{2}$, a nice fact for the future. Expanding the derivative yields
\begin{align*}
	\frac{1}{\mathcal{L}}\left(\frac{1}{2}\dot{\chi}^{a}\dot{\chi}^{b}\del{c}{g_{ab}} - g_{ac}\ddot{\chi}^{a} - \dot{\chi}^{a}\dot{\chi}^{b}\del{b}{g_{ac}}\right) = 0.
\end{align*}
To remove the metric from the second derivative, we multiply by $-g^{cd}\mathcal{L}$ to obtain
\begin{align*}
	&g_{ac}g^{cd}\ddot{\chi}^{a} + \frac{1}{2}\dot{\chi}^{a}\dot{\chi}^{b}g^{cd}(2\del{b}{g_{ac}} - \del{c}{g_{ab}}) = 0, \\
	&g_{ac}g^{cd}\ddot{\chi}^{a} + \frac{1}{2}\dot{\chi}^{a}\dot{\chi}^{b}g^{cd}(\del{b}{g_{ac}} + \del{a}{g_{bc}} - \del{c}{g_{ab}}) = 0, \\
	&\ddot{\chi}^{d} + \frac{1}{2}\dot{\chi}^{a}\dot{\chi}^{b}g^{cd}(\del{b}{g_{ac}} + \del{a}{g_{bc}} - \del{c}{g_{ab}}) = 0.
\end{align*}
This is the geodesic equation. It may alternatively be written in terms of the Christoffel symbols as
\begin{align*}
	\ddot{\chi}^{d} + \chris{d}{a}{b}\dot{\chi}^{a}\dot{\chi}^{b} = 0.
\end{align*}

\paragraph{Christoffel Symbols and the Geodesic Equation}
Consider a straight line with a tangent vector of constant magnitude. In euclidean space, this is a geodesic. This curve satisfies
\begin{align*}
	\vb{0} = \dv{\dot{\vb*{\gamma}}}{t} = (\dot{\vb*{\gamma}}\cdot\grad)\dot{\vb*{\gamma}} = \dot{\chi}^{a}\del{a}{\dot{\vb*{\gamma}}} = \dot{\chi}^{a}(\dcov{a}{\dot{\chi}^{d}})\tb{d} = (\dot{\chi}^{a}\del{a}{\dot{\chi}^{d}} + \dot{\chi}^{a}\dot{\chi}^{c}\chris{d}{a}{c})\tb{d}.
\end{align*}
Comparing this to the geodesic equation yields
\begin{align*}
	\chris{d}{a}{b} = \frac{1}{2}g^{dc}(\del{b}{g_{ac}} + \del{a}{g_{cb}} - \del{c}{g_{ab}}).
\end{align*}
A better approach would have been to go through the derivation of the geodesic equation again, identifying the Christoffel symbols as you go, but I am not sure if that is what I did in the previous paragraph. In any case we have already obtained this result.

\paragraph{Manifolds}
A manifold is a set which is locally isomorphic to $\R^{n}$. We will take this to mean that we can locally impose coordinates $\chi^{a}$ on the manifold.

More formally, a manifold is described by a number of sets $U_{i}\subset\R^{n}$ called charts. To each chart belongs a set of coordinate functions $\chi_{i}$ which map from a subset $M_{i}\subset M$ to $U_{i}$ such that $\chi_{i}$ is a smooth bijection. A set of charts such that every point $p\in M$ is found in at least one chart is called an atlas.

\paragraph{Manifolds and Vectors}
Even though manifolds are locally isomorphic to Euclidean space, the vectors that were previously developed do not make sense when applied to this Euclidean space.

\example{Tangent Vectors on $S_{2}$}
Consider $S_{2}$, the unit sphere in $\R^{3}$, and suppose you cover it with a layer of water like an ocean, introduce north and south poles, place two sailors on opposite sides of the equator and tell both of them to sail south at some given speed. In practice, this means that they should both travel in their local $-y$ direction. Assuming vectors in the two spaces to make sense, you would conclude that the sailors are sailing in the same direction at the same speed and could not possibly hit each other. The accident which would occur at the south pole would of course prove you wrong. This example is one, very verbose, way of expressing why the vectors in the local Euclidean spaces do not make sense.

This argument seems to have one hole in it, namely that $S_{2}$ is implicitly embedded in $\R^{3}$. Using this fact, the collision between the sailors could be deduced using the previously developed concepts of vectors. The reason why this would work is that you could impose a position vector in $\R^{3}$ onto every point on $S_{2}$. This is not a feature of more general manifolds, meaning that this hole does not exist for more general manifolds.

\paragraph{Tangent Vectors}
Tangent vectors describe how scalar fields change with displacement along a curve. In Euclidean space the tangent basis was composed of derivatives with respect to the set of coordinates. In general curved spaces, we define
\begin{align*}
	\tb{a} = \del{a}{}.
\end{align*}
Derivatives are linear operators, so at least the set of tangent bases span some vector space and it makes sense to call a derivative a vector. A general tangent vector is now
\begin{align*}
	X = X^{a}\tb{a} = X^{a}\del{a}{}.
\end{align*}
These live in the tangent space $\ts{p}{M}$ of the manifold $M$ at the point $p$.

To get more of a sense of how this can be related to vectors, consider the directional derivative
\begin{align*}
	\grad_{\vb{n}} = \vb{n}\cdot\grad = n^{a}\del{a}{}.
\end{align*}
When applied to Euclidean space, there is a direct correspondence between $\vb{n}$ and the directional derivative, as $\grad_{\vb{n}}{\vb{x}} = \vb{n}$. For more general manifolds, tangent vectors are defined to be directional derivatives. Note that this definition carries with it the same dependence on position as was previously warned about.

Tangent vectors transform according to
\begin{align*}
	X^{a}\del{a}{} = X^{a}\del{a}{(\chi^{\prime})^{b}}\del[\prime]{b}{},
\end{align*}
implying the transformation rule
\begin{align*}
	(X^{\prime})^{a} = \del{b}{(\chi^{\prime})^{a}}X^{b},
\end{align*}
which is the same as the transformation rule for contravariant vector components in Euclidean space.

\paragraph{Dual Vectors}
To define dual vectors, we first introduce the dual space as the set of all linear operations from the tangent space to real numbers. This is also a vector space. The basis for the space is defined such that
\begin{align*}
	\db{a}(\del{b}{}) = \kdelta{b}{a}.
\end{align*}

In Euclidean space the dual basis was constructed from the gradient. The only concept here that carries over to manifolds is a definition based on small changes in the coordinates. More specifically, for any smooth scalar field $f$ we define a dual vector field according to
\begin{align*}
	df(X) = Xf = X^{a}\del{a}{f}
\end{align*}
and call it the differential. This has a similar structure to an inner product if the dual vector field has components $df_{a} = \del{a}{f}$. These components correspond to those of the gradient in Euclidean space. The basis we desire is $\db{a} = d\chi^{a}$. These live in the dual space $\ds{p}{M}$ of the manifold $M$ at the point $p$.

The dual basis satisfies satisfies
\begin{align*}
	d\chi^{a}(\del{b}{}) = \del{b}{\chi^{a}} = \kdelta{b}{a},
\end{align*}
as expected. Using this, we obtain
\begin{align*}
	df = (\del{a}{f})d\chi^{a},
\end{align*}
which at least looks like the differential of a function.

The components transform according to
\begin{align*}
	\del{a}{f} = \del[\prime]{b}{f}\del{a}{(\chi^{\prime})^{b}},
\end{align*}
which is the transformation rule for covariant vector components.

\paragraph{Tensors}
Having identified a basis for the tangent and dual spaces, we may now construct tensors similarly to what we have previously done. Note now that as the tangent and dual vectors belong to different vector spaces, the notion of type $(n, m)$ tensors is more clear. This also explains why we needed to be careful with indices being up or down when studying Euclidean space, as the difference is huge for manifolds.

\paragraph{Flow of Vector Fields}
The tangent bundle of a manifold is defined as $TM = \bigcup\limits_{p}\ts{p}{M}$. A vector field is a map $X: M\to\tbun{M}$ such that $X(p)\in\ts{p}{M}$. Given this, we may define the flow of a vector field as a collection of curves $\gamma_{X}$ which given some starting point $p$ satisfy
\begin{align*}
	\deval{\gamma_{X}}{\tau}{p, s} = \eval{X}_{\gamma_{X}(p, s)}.
\end{align*}

\paragraph{Pushforwards and Pullbacks}
Consider some function $f$ which maps a manifold $M_{1}$ to another manifold $M_{2}$, as well as a function $g: M_{2}\to\R$. We then define the pullback of $g$ to $M_{1}$ by $f$ as $\pub{f}{g} = g\circ f$. We also define the pushforward of a vector $V\in\ts{p}{M}$ as $(\puf{f}{V})\phi = V(\pub{f}{\phi})$.

\paragraph{Tangents and the Pushforward}
$f$ maps the cooordinates $\chi^{a}$ of $M_{1}$ to the coordinates $\eta^{\mu}$ of $M_{2}$. By definition we have
\begin{align*}
	(\puf{f}{V})\phi &= V(\pub{f}{\phi}) \\
	                 &= V^{a}\del{a}{(\phi\circ f)} \\
	                 &= V^{a}\del{\mu}{\phi}\del{a}{\eta^{\mu}},
\end{align*}
meaning $\puf{f}{V} = V^{a}\del{a}{\eta^{\mu}}\del{\mu}{}$.

How do we interpret this? Consider some curve $\gamma$ in $M_{1}$ which is mapped to a curve $\alpha$ $M_{2}$ by $f$. If $V$ is the tangent of $\gamma$ at some particular point, we have
\begin{align*}
	\dot{\alpha} = \dot{\eta^{\mu}}\del{\mu}{} = \del{a}{\eta^{\mu}}\dot{\chi^{a}}\del{\mu}{} = \del{a}{\eta^{\mu}}V^{a}\del{\mu}{},
\end{align*}
meaning that the pushforward of a tangent by $f$ is the tangent of the curve produced by $f$.

\paragraph{The Pullback of Tensors}
We can now define the pullback of a $(0, m)$ tensor on $M_{2}$ according to
\begin{align*}
	\pub{f}{\omega}(V_{1}, \dots, V_{m}) = \omega(\puf{f}{V_{1}}, \dots, \puf{f}{V_{m}}).
\end{align*}
If $f$ is a bijection we may also define the more general pullback of a $(n, m)$ tensor on $M_{2}$ as
\begin{align*}
	\pub{f}{T}(V_{1}, \dots, V_{m}, \omega_{1}, \dots, \omega_{n}) = T(\puf{f}{V_{1}}, \dots, \puf{f}{V_{m}}, \pub{(f^{-1})}{\omega_{1}}, \dots, \pub{(f^{-1})}{\omega_{n}}).
\end{align*}

\paragraph{The Lie Derivative}
The composition $XY$ of two tangent vectors does not produce a new vector, hence this is not a way to produce a derivative on manifolds. Instead we introduce the Lie bracket
\begin{align*}
	\lied{X}{Y} =\comm{X}{Y} = XY - YX &= X^{a}\del{a}{(Y^{b}\del{b}{})} - Y^{b}\del{b}{(X^{a}\del{a}{})} \\
	                                   &= X^{a}\del{a}{(Y^{b})}\del{b}{} + X^{a}Y^{b}\del{a}{\del{b}{}} - Y^{b}\del{b}{(X^{a})}\del{a}{} - Y^{b}X^{a}\del{b}{\del{a}{}} \\
	                                   &= (X^{b}\del{b}{(Y^{a})} - Y^{b}\del{b}{(X^{a})})\del{a}{},
\end{align*}
which is a new vector. This derivative satisfies many properties that are desirable for a derivative - in particular the product rule
\begin{align*}
	\lied{X}{fY} &= (X^{b}\del{b}{(fY^{a})} - fY^{b}\del{b}{(X^{a})})\del{a}{} \\
	             &= (X^{b}(Y^{a}\del{b}{(f)} + f\del{b}{(Y^{a})}) - fY^{b}\del{b}{(X^{a})})\del{a}{} \\
	             &= X^{b}\del{b}{(f)}Y^{a}\del{a}{} + f(X^{b}\del{b}{(Y^{a})} - Y^{b}\del{b}{(X^{a})})\del{a}{} \\
	             &= X(f)Y + f\lied{X}{Y}.
\end{align*}

\paragraph{Differential Forms}
The set of $p$-forms, or differential forms, is the set of $(0, p)$ tensors that are completely antisymmetric. They are constructed using the wedge product, defined as
\begin{align*}
	\bigwedge\limits_{k = 1}^{p}d\chi^{a_{k}} = \sum\limits_{\sigma\in S_{p}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p}d\chi^{a_{\sigma(k)}}.
\end{align*}
Here $S_{p}$ is the set of permutations of $p$ elements. There exists
\begin{align*}
	n_{p}^{N} = {N\choose k}
\end{align*}
basis elements. We note that the wedge product is antisymmetric under the exchange of two basis elements. Hence, once an ordering of indices has been chosen, any permutation will simply create a linearly dependent map.

Consider now some antisymmetric tensor $\omega$. Introducing the antisymmetrizer
\begin{align*}
	\bigotimes_{k = 1}^{p}d\chi^{[a_{\sigma(k)}]} = \frac{1}{p!}\sum\limits_{\sigma\in S_{p}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p}d\chi^{a_{\sigma(k)}},
\end{align*}
the symmetry yields
\begin{align*}
	\omega = \omega_{a_{1}\dots a_{p}}\bigotimes_{k = 1}^{p}d\chi^{a_{\sigma(k)}} = \omega_{a_{1}\dots a_{p}}\bigotimes_{k = 1}^{p}d\chi^{[a_{\sigma(k)}]} = \frac{1}{p!}\omega_{a_{1}\dots a_{p}}\bigwedge\limits_{k = 1}^{p}d\chi^{a_{k}}.
\end{align*}

\paragraph{The Exterior Derivative}
We define the exterior derivative of a differential form according to
\begin{align*}
	d\omega = \frac{1}{p!}\del{a_{1}}{\omega_{a_{2}\dots a_{p + 1}}}\bigwedge\limits_{k = 1}^{p + 1}d\chi^{a_{k}},
\end{align*}
which is a $p + 1$-form. This notation makes sense, as at least in the case of a $0$-form, we obtain
\begin{align*}
	d\omega = \del{a}{\omega}d\chi^{a},
\end{align*}
which is exactly the form of a dual vector. Somehow this transforms as a tensor.

\paragraph{Integration of Differential Forms}
Consider a set of $p$ tangent vectors $X_{i}$. The corresponding coordinate displacements are $\dd{\chi_{i}^{a}} = X_{i}^{a}\dd{t_{i}}$, with no sum over $i$. We would now like to compute the $p$-dimensional volume defined by the $X_{i}$ and $\dd{t_{i}}$. We expect that if any of the $X_{i}$ are linearly dependent the volume should be zero. We also expect that the volume be linear in the $X_{i}$. This implies
\begin{align*}
	\dd{V_{p}} = \omega(X_{1}, \dots, X_{p})\dd{t_{1}}\dots\dd{t_{p}}
\end{align*}
for some differential form $\omega$. We now define the integral over the $p$-volume $S$ over the $p$-form $\omega$ as
\begin{align*}
	\minteg{S}{\omega} = \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p}}{\omega(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p})}}.
\end{align*}
Here the $\gamma_{i}$ are the set of curves that span $S$, the dot symbolizes the derivative with respect to the individual curve parameters and the right-hand integration is performed over the appropriate set of parameter values.

\paragraph{Stokes' Theorem}
Stokes' theorem relates the integral of a differential form $d\omega$ over some subset $V$ of a manifold to an integral over \bound{V} of another differential form.

To derive it, consider a $p + 1$-volume parametrized such that all $t_{i}$ range from 0 to 1 and such that for any fixed $t_{p + 1}$, the remaining $t_{i}$ parametrize a $p$-dimensional surface $V_{p}$ with a boundary independent of $t_{p + 1}$. This construction is somewhat restrictive, but only necessary in the derivation.

For some $p$-form $\omega$ and $p + 1$-volume $V$ we have
\begin{align*}
	\minteg{V}{d\omega} &= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{d\omega(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}} \\
	                    &= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\left(\del{a_{1}}{\omega_{a_{2}\dots a_{p + 1}}}\sum\limits_{\sigma\in S_{p + 1}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p + 1}d\chi^{a_{\sigma(k)}}\right)(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}} \\
	                    &= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\left(\del{a_{1}}{\omega_{a_{2}\dots a_{p + 1}}}\bigotimes_{k = 1}^{p + 1}d\chi^{a_{\sigma(k)}}\right)(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}} \\
	                    &= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\left(\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\bigotimes_{k = 1}^{p + 1}d\chi^{a_{\sigma(k)}}\right)(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}},
\end{align*}
where the latter follows from the cyclicity imposed by the summation. We have
\begin{align*}
	d\chi^{a_{\sigma(k)}}{\dot{\gamma}_{k}} = \dv{\chi^{a}}{t_{k}}\del{a}{\chi^{a_{\sigma(k)}}} = \dv{\chi^{a_{\sigma(k)}}}{t_{k}},
\end{align*}
and thus
\begin{align*}
	\minteg{V}{d\omega} &= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p + 1}\del{t_{k}}{\chi^{a_{\sigma(k)}}}}} \\
	                    &= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p + 1}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}},
\end{align*}
where we have once again utilized the cyclicity. Denote the integral inside the sum as $I(\sigma, \omega)$. We have
\begin{align*}
	I(\sigma, \omega) &= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p + 1}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}} \\
	                  &= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{t_{\sigma(p + 1)}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}.
\end{align*}
To proceed, we integrate by parts and obtain
\begin{align*}
	I(\sigma, \omega) &= \eval{\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\omega_{a_{1}\dots a_{p}}\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}}_{t_{\sigma(p + 1)} = t_{\sigma(p + 1)}^{-}}^{t_{\sigma(p + 1)} = t_{\sigma(p + 1)}^{+}} - \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\omega_{a_{1}\dots a_{p}}\del{t_{\sigma(p + 1)}}{\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}},
\end{align*}
where the former terms contains no integration over $t_{\sigma(p + 1)}$, and is instead evaluated at the maximal and minimal values of $t_{\sigma(p + 1)}$ given the values of the other parameters.

Let us proceed to simplify this. For starters, if $\sigma(p + 1) \neq p + 1$, the remaining integration in the first term is done over the boundary of $V_{p}$. Furthermore, there exists a $k$ such that $\sigma(k) = p + 1$, and as we are at the boundary of $V_{p}$ we must have
\begin{align*}
	\del{t_{\sigma(k)}}{\chi^{a_{k}}} = 0.
\end{align*}
Otherwise, the remaining integration domain is $V_{p}$. Next, the latter integral contains a sequence of terms proportional to
\begin{align*}
	\del{t_{\sigma(p + 1)}}{\del{t_{\sigma(k)}}{\chi^{a_{k}}}},
\end{align*}
which is symmetric with respect to exchanging $p + 1$ and $k$. These terms therefore cancel in the sum, and we are left with
\begin{align*}
	\minteg{V}{d\omega} &= \sum\limits_{\sigma\in S_{p}}\frac{\text{sgn}(\sigma)}{p!}\eval{\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p}}{\omega_{a_{1}\dots a_{p}}\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}}_{t_{\sigma(p + 1)} = 0}^{t_{\sigma(p + 1)} = 1} \\
	                    &= \eval{\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p}}{\omega}}}_{t_{\sigma(p + 1)} = 0}^{t_{\sigma(p + 1)} = 1}
\end{align*}
where the condition that $\sigma(p + 1) = p + 1$ restricts the summation to $S_{p}$.

The remaining integration domain is, as stated before, a parametrization of $V_{p}$, which at the extremal values of $t_{p + 1}$ must be at the boundary of $V$. The minus sign from the integral evaluation tells us that the integrals are taken with opposite orientation, meaning that together they indeed form an integration over the (closed) boundary of $V$. We thus arrive at Stokes' theorem,
\begin{align*}
	\minteg{V}{d\omega} = \oint\limits_{\bound{V}}\omega.
\end{align*}

\example{Reobtaining Familiar Theorems}
Many familiar integration theorems are in fact consequences of Stokes' theorem. Let us rederive them.

We start with a $1$-form $d\omega$, which will be integrated over a $1$-dimensional volume, i.e. a curve. We have
\begin{align*}
	\minteg{\gamma}{d\omega} = \omega(p) - \omega(q),
\end{align*}
where $q$ and $p$ are the start and end points of $\gamma$. This is the analogue of integrating a vector field along a curve.

Next, we consider a $2$-form written as the exterior derivative of a $1$-form. Writing $\omega = \omega_{i}d\chi^{i}$ we have
\begin{align*}
	d\omega = \del{j}{\omega_{i}}d\chi^{j}\wedge d\chi^{i}.
\end{align*}
Using Cartesian coordinates and restricting ourselves to two dimensions we have
\begin{align*}
	\df{\chi^{j}}\wedge\df{\chi^{i}}(\dot{\gamma}_{s}, \dot{\gamma}_{t})\dd{s}\dd{t} &= (\df{\chi^{j}}\otimes\df{\chi^{i}} - \df{\chi^{i}}\otimes\df{\chi^{j}})(\dot{\gamma}_{s}, \dot{\gamma}_{t})\dd{s}\dd{t} \\
	&= (\del{s}{\chi^{j}}\del{t}{\chi^{i}} - \del{s}{\chi^{i}}\del{t}{\chi^{j}})\dd{s}\dd{t} \\
	&= (\delta_{jk}\delta_{im} - \delta_{ik}\delta_{jm})\del{s}{\chi^{k}}\del{t}{\chi^{m}}\dd{s}\dd{t} \\
	&= \varepsilon_{jin}\varepsilon_{nkm}\del{s}{\chi^{k}}\del{t}{\chi^{m}}\dd{s}\dd{t} \\
	&= \varepsilon_{jik}\dd{S_{k}}.
\end{align*}
Thus we have
\begin{align*}
	\minteg{S}{d\omega} = \integ{S}{}{S_{k}}{\varepsilon_{ijk}\del{i}{\omega_{j}}} = \integ{S}{}{\vb{S}}{\cdot\curl{\vb*{\omega}}}.
\end{align*}
At the same time we have
\begin{align*}
	\minteg{\bound{S}}{\omega} &= \integ{\bound{S}}{}{t}{\omega_{a}\df{\chi^{a}}(\dot{\gamma}_{t})} \\
	                           &= \integ{\bound{S}}{}{t}{\omega_{a}\dv{\chi^{a}}{t}} \\
	                           &= \integ{\bound{S}}{}{\vb{r}}{\cdot\vb*{\omega}},
\end{align*}
hence
\begin{align*}
	\integ{S}{}{\vb{S}}{\cdot\curl{\vb*{\omega}}} = \integ{\bound{S}}{}{\vb{r}}{\cdot\vb*{\omega}},
\end{align*}
which is the more boring version of Stokes' theorem.

Next we consider a $2$-form and its exterior derivative. We have
\begin{align*}
	\minteg{V}{\df{\omega}} &= \frac{1}{2}\minteg{V}{\del{a}{\omega_{bc}}\df{\chi^{a}}\wedge\df{\chi^{b}}\wedge\df{\chi^{c}}}.
\end{align*}
As the components of $\omega$ may be chosen such that $\omega_{ab} = -\omega_{ba}$ we may write $\omega_{ab} = \varepsilon_{abc}\omega_{c}$ for some suitable (and arbitrary) choice of $\omega_{c}$. We thus have
\begin{align*}
	\minteg{V}{\df{\omega}} &= \frac{1}{2}\minteg{V}{\varepsilon_{bcd}\del{a}{\omega_{d}}\df{\chi^{a}}\wedge\df{\chi^{b}}\wedge\df{\chi^{c}}} \\
	                        &= \frac{1}{2}\integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\varepsilon_{bcd}\varepsilon_{abc}\del{a}{\omega_{d}}}}} \\
	                        &= \frac{1}{2}\integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{(\delta_{ad}\delta_{bb} - \delta_{ab}\delta_{bd})\del{a}{\omega_{d}}}}} \\
	                        &= \integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\del{a}{\omega_{a}}}}} \\
	                        &= \integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\div{\vb*{\omega}}}}}.
\end{align*}
At the same time we have
\begin{align*}
	\minteg{\bound{V}}{\omega} &= \frac{1}{2}\minteg{\bound{V}}{\varepsilon_{ijk}\omega_{i}\df{\chi^{j}}\wedge\df{\chi^{k}}} \\
	                           &= \frac{1}{2}\integ{\bound{V}}{}{S_{m}}{\varepsilon_{ijk}\varepsilon_{jkm}\omega_{i}} \\
	                           &= \frac{1}{2}\integ{\bound{V}}{}{S_{m}}{(\delta_{im}\delta_{jj} - \delta_{ij}\delta_{jm})\omega_{i}} \\
	                           &= \integ{\bound{V}}{}{S_{i}}{\omega_{i}} \\
	                           &= \integ{\bound{V}}{}{\vb{S}}{\cdot\vb*{\omega}}.
\end{align*}
Hence we have
\begin{align*}
	\integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\div{\vb*{\omega}}}}} = \integ{\bound{V}}{}{\vb{S}}{\cdot\vb*{\omega}},
\end{align*}
which is the divergence theorem.

\example{The $n$-Dimensional Divergence Theorem}

\paragraph{The Geometry of Curved Space}
We can also impose a metric tensor such that $\vb{v}\cdot\vb{w} = g_{ab}v^{a}w^{b}$, where the metric tensor is symmetric and positive definite.

Dual vectors can be defined as linear maps from tangent vectors to scalars, i. e. on the form
\begin{align*}
	V(\vb{w}) = V_{a}w^{a}.
\end{align*}
In particular, the dual vector $\dd{f}$ can be defined as
\begin{align*}
	\dd{f}(\vb{v}) = v^{a}\del{a}{f} = \dv{f}{t}
\end{align*}
along a curve with $\vb{v}$ as a tangent. A basis for the space of dual vectors is $e^{a} = \dd{\chi^{a}}$. The tangent and dual spaces, if a metric exists, are related by $v_{a} = g_{ab}v^{b}$.

Curve lengths are defined and computed as before. By defining geodesics as curves that extremize path length, this gives a set of Christoffel symbols and therefore a covariant derivative and a sense of what it means for a vector to change along a curve.