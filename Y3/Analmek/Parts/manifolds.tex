\section{Differential Geometry on Manifolds}

\paragraph{Manifolds}
A manifold is a set which is locally isomorphic to $\R^{n}$. We will take this to mean that we can locally impose coordinates $\chi^{a}$ on the manifold.

More formally, a manifold is described by a number of sets $U_{i}\subset\R^{n}$ called charts. To each chart belongs a set of coordinate functions $\chi_{i}$ which map from a subset $M_{i}\subset M$ to $U_{i}$ such that $\chi_{i}$ is a smooth bijection. A set of charts such that every point $p\in M$ is found in at least one chart is called an atlas.

\paragraph{Manifolds and Vectors}
Even though manifolds are locally isomorphic to Euclidean space, the vectors that were previously developed do not make sense when applied to this Euclidean space.

\example{Tangent Vectors on $S_{2}$}
Consider $S_{2}$, the unit sphere in $\R^{3}$, and suppose you cover it with a layer of water like an ocean, introduce north and south poles, place two sailors on opposite sides of the equator and tell both of them to sail south at some given speed. In practice, this means that they should both travel in their local $-y$ direction. Assuming vectors in the two spaces to make sense, you would conclude that the sailors are sailing in the same direction at the same speed and could not possibly hit each other. The accident which would occur at the south pole would of course prove you wrong. This example is one, very verbose, way of expressing why the vectors in the local Euclidean spaces do not make sense.

This argument seems to have one hole in it, namely that $S_{2}$ is implicitly embedded in $\R^{3}$. Using this fact, the collision between the sailors could be deduced using the previously developed concepts of vectors. The reason why this would work is that you could impose a position vector in $\R^{3}$ onto every point on $S_{2}$. This is not a feature of more general manifolds, meaning that this hole does not exist for more general manifolds.

\paragraph{Tangent Vectors}
Tangent vectors describe how scalar fields change with displacement along a curve. In Euclidean space the tangent basis was composed of derivatives with respect to the set of coordinates. In general curved spaces, we define
\begin{align*}
\tb{a} = \del{a}{}.
\end{align*}
Derivatives are linear operators, so at least the set of tangent bases span some vector space and it makes sense to call a derivative a vector. A general tangent vector is now
\begin{align*}
X = X^{a}\tb{a} = X^{a}\del{a}{}.
\end{align*}
These live in the tangent space $\ts{p}{M}$ of the manifold $M$ at the point $p$.

To get more of a sense of how this can be related to vectors, consider the directional derivative
\begin{align*}
\grad_{\vb{n}} = \vb{n}\cdot\grad = n^{a}\del{a}{}.
\end{align*}
When applied to Euclidean space, there is a direct correspondence between $\vb{n}$ and the directional derivative, as $\grad_{\vb{n}}{\vb{x}} = \vb{n}$. For more general manifolds, tangent vectors are defined to be directional derivatives. Note that this definition carries with it the same dependence on position as was previously warned about.

Tangent vectors transform according to
\begin{align*}
X^{a}\del{a}{} = X^{a}\del{a}{(\chi^{\prime})^{b}}\del[\prime]{b}{},
\end{align*}
implying the transformation rule
\begin{align*}
(X^{\prime})^{a} = \del{b}{(\chi^{\prime})^{a}}X^{b},
\end{align*}
which is the same as the transformation rule for contravariant vector components in Euclidean space.

\paragraph{Dual Vectors}
To define dual vectors, we first introduce the dual space as the set of all linear operations from the tangent space to real numbers. This is also a vector space. The basis for the space is defined such that
\begin{align*}
\db{a}(\del{b}{}) = \kdelta{b}{a}.
\end{align*}

In Euclidean space the dual basis was constructed from the gradient. The only concept here that carries over to manifolds is a definition based on small changes in the coordinates. More specifically, for any smooth scalar field $f$ we define a dual vector field according to
\begin{align*}
df(X) = Xf = X^{a}\del{a}{f}
\end{align*}
and call it the differential. This has a similar structure to an inner product if the dual vector field has components $df_{a} = \del{a}{f}$. These components correspond to those of the gradient in Euclidean space. The basis we desire is $\db{a} = d\chi^{a}$. These live in the dual space $\ds{p}{M}$ of the manifold $M$ at the point $p$.

The dual basis satisfies satisfies
\begin{align*}
d\chi^{a}(\del{b}{}) = \del{b}{\chi^{a}} = \kdelta{b}{a},
\end{align*}
as expected. Using this, we obtain
\begin{align*}
df = (\del{a}{f})d\chi^{a},
\end{align*}
which at least looks like the differential of a function.

The components transform according to
\begin{align*}
\del{a}{f} = \del[\prime]{b}{f}\del{a}{(\chi^{\prime})^{b}},
\end{align*}
which is the transformation rule for covariant vector components.

\paragraph{Tensors}
Having identified a basis for the tangent and dual spaces, we may now construct tensors similarly to what we have previously done. Note now that as the tangent and dual vectors belong to different vector spaces, the notion of type $(n, m)$ tensors is more clear. This also explains why we needed to be careful with indices being up or down when studying Euclidean space, as the difference is huge for manifolds.

\paragraph{Flow of Vector Fields}
The tangent bundle of a manifold is defined as $TM = \bigcup\limits_{p}\ts{p}{M}$. A vector field is a map $X: M\to\tbun{M}$ such that $X(p)\in\ts{p}{M}$. Given this, we may define the flow of a vector field as a collection of curves $\gamma_{X}$ which given some starting point $p$ satisfy
\begin{align*}
\deval{\gamma_{X}}{\tau}{p, s} = \eval{X}_{\gamma_{X}(p, s)}.
\end{align*}
We may for a fixed $s$ define the function $\gamma_{sX}(p) = \gamma_{X}(p, s)$, which maps $M$ to itself.

\paragraph{Pushforwards and Pullbacks}
Consider some function $f$ which maps a manifold $M_{1}$ to another manifold $M_{2}$, as well as a function $g: M_{2}\to\R$. We then define the pullback of $g$ to $M_{1}$ by $f$ as $\pub{f}{g} = g\circ f$. We also define the pushforward of a vector $V\in\ts{p}{M}$ as $(\puf{f}{V})\phi = V(\pub{f}{\phi})$.

\paragraph{Tangents and the Pushforward}
$f$ maps the cooordinates $\chi^{a}$ of $M_{1}$ to the coordinates $\eta^{\mu}$ of $M_{2}$. By definition we have
\begin{align*}
(\puf{f}{V})\phi &= V(\pub{f}{\phi}) \\
&= V^{a}\del{a}{(\phi\circ f)} \\
&= V^{a}\del{\mu}{\phi}\del{a}{\eta^{\mu}},
\end{align*}
meaning $\puf{f}{V} = V^{a}\del{a}{\eta^{\mu}}\del{\mu}{}$.

How do we interpret this? Consider some curve $\gamma$ in $M_{1}$ which is mapped to a curve $\alpha$ $M_{2}$ by $f$. If $V$ is the tangent of $\gamma$ at some particular point, we have
\begin{align*}
\dot{\alpha} = \dot{\eta^{\mu}}\del{\mu}{} = \del{a}{\eta^{\mu}}\dot{\chi^{a}}\del{\mu}{} = \del{a}{\eta^{\mu}}V^{a}\del{\mu}{},
\end{align*}
meaning that the pushforward of a tangent by $f$ is the tangent of the curve produced by $f$.

\paragraph{The Pullback of Tensors}
We can now define the pullback of a $(0, m)$ tensor on $M_{2}$ according to
\begin{align*}
\pub{f}{\omega}(V_{1}, \dots, V_{m}) = \omega(\puf{f}{V_{1}}, \dots, \puf{f}{V_{m}}).
\end{align*}
If $f$ is a bijection we may also define the more general pullback of a $(n, m)$ tensor on $M_{2}$ as
\begin{align*}
\pub{f}{T}(V_{1}, \dots, V_{m}, \omega_{1}, \dots, \omega_{n}) = T(\puf{f}{V_{1}}, \dots, \puf{f}{V_{m}}, \pub{(f^{-1})}{\omega_{1}}, \dots, \pub{(f^{-1})}{\omega_{n}}).
\end{align*}

\paragraph{The Lie Derivative}
For a tensor field $T$ we define the Lie derivative in the $X$-direction as
\begin{align*}
\lied{X}{T} = \lim\limits_{\varepsilon\to 0}\frac{1}{\varepsilon}\left(\pub{\gamma_{\varepsilon X}}{T} - T\right).
\end{align*}

\paragraph{An Expression for the Lie Derivative}
As the definition of the Lie derivative is similar to that of the usual derivative, it follows that it is linear in its argument and satisfies the product rule, where the product in question is now the tensor product. This means that we can find a general expression for the Lie derivative of a tensor field by considering its action on tangent and dual vectors.

First, for scalars we simply have $\lied{X}{f} = X^{a}\del{a}{f}$.

When studying the effect on tangent vectors we will have to be extra careful. Let $\gamma_{\varepsilon X}$ map $p$ to $q$, and let $\eval{Y}_{p}(\omega) = \eval{Y^{a}}_{p}\eval{\del{a}{\omega}}_{p}$ to clarify at what point we are working. To first order in $\varepsilon$ we then have
\begin{align*}
\eval{\pub{\gamma_{\varepsilon X}}{Y}}_{q}(\omega) &= \eval{Y}_{q}(\pub{\gamma_{-\varepsilon X}}{\omega}) \\
&= \eval{Y^{a}}_{q}\eval{\del{a}{(\omega\circ\gamma_{-\varepsilon X})}}_{q} \\
&\approx \left(\eval{Y^{a}}_{p} + \varepsilon\eval{ X^{b}\del{b}{Y^{a}}}_{p}\right) \eval{\del{c}{\omega}}_{\gamma_{-\varepsilon X}(q)}\eval{\del{a}{(\gamma_{-\varepsilon X})^{c}}}_{q} \\
&\approx \left(\eval{Y^{a}}_{p} + \varepsilon\eval{ X^{b}\del{b}{Y^{a}}}_{p}\right) \left(\kdelta{a}{c} - \varepsilon\del{a}{X^{c}}\right)\eval{\del{c}{\omega}}_{p} \\
&\approx \left(\kdelta{a}{c}\eval{Y^{a}}_{p} + \varepsilon\kdelta{a}{c}\eval{ X^{b}\del{b}{Y^{a}}}_{p} - \varepsilon\del{a}{X^{c}}\eval{Y^{a}}_{p}\right)\eval{\del{c}{\omega}}_{p} \\
&= \eval{Y^{a}}_{p}\eval{\del{a}{\omega}}_{p} + \varepsilon\eval{ X^{b}\del{b}{Y^{a}}}_{p}\eval{\del{a}{\omega}}_{p} - \eval{Y^{a}}_{p}\varepsilon\del{a}{X^{c}}\eval{\del{c}{\omega}}_{p},
\end{align*}
and thus $\lied{X}{Y} = \comm{X}{Y}$. In particular, we have $\lied{X}{\del{a}{}} = -(\del{a}{X^{b}})\del{b}{}$.

To find the Lie derivative of dual vectors, we use the fact that the product rule (somehow) respects contraction, meaning
\begin{align*}
\lied{X}{\omega(Y)} &= (\lied{X}{\omega})(Y) + \omega(\lied{X}{Y}) \\
&= (\lied{X}{\omega})_{a}Y^{a} + \omega_{a}(X^{b}\del{b}{Y^{a}} - Y^{b}\del{b}{X^{a}}).
\end{align*}
As the left-hand side is simply equal to $X^{a}\del{a}{(\omega_{b}Y^{b})}$, we obtain
\begin{align*}
(\lied{X}{\omega})_{a}Y^{a} &= X^{a}\del{a}{(\omega_{b}Y^{b})} - \omega_{b}X^{a}\del{a}{Y^{b}} + \omega_{a}Y^{b}\del{b}{X^{a}} \\
&= Y^{a}X^{b}\del{b}{\omega_{a}} + \omega_{b}Y^{a}\del{a}{X^{b}},
\end{align*}
and thus
\begin{align*}
(\lied{X}{\omega})_{a} &= X^{b}\del{b}{\omega_{a}} + \omega_{b}\del{a}{X^{b}}.
\end{align*}
In particular, we have $\lied{X}{\df{\chi^{a}}} = \del{c}{X^{a}}\df{\chi^{c}}$.

Finally, for a tensor, we somehow obtain
\begin{align*}
\tensor*{(\lied{X}{T})}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}} &= X^{c}\del{c}{\tensor*{T}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} - \sum\limits_{i = 1}^{n}\tensor*{T}{^{a_{1}\dots a_{i - 1}ca_{i + 1}\dots a_{n}}_{b_{1}\dots b_{m}}}\del{c}{X^{a_{i}}} + \sum\limits_{j = 1}^{m}\tensor*{T}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{j - 1}cb_{j + 1}\dots b_{m}}}\del{b_{j}}{X^{c}}.
\end{align*}

\paragraph{Connections}
A connection is an operator that satisfies the following:
\begin{itemize}
	\item $\dcov{X}{f} = Xf = X^{a}\del{a}{f}$ for a scalar field $f$.
	\item $\dcov{X + Y}{T} = \dcov{X}{T} + \dcov{Y}{T}$.
	\item $\dcov{fX}{T} = f\dcov{X}{T}$.
	\item $\dcov{X}{(TS)} = (\dcov{X}{T})S + T\dcov{X}{S}$.
\end{itemize}

\paragraph{Connections on Manifolds}
On a manifold, a connection is specified by choosing $n$ independent vectors $X_{i}$ and defining
\begin{align*}
\dcov{X_{i}}{X_{j}} = \chris{k}{i}{j}X_{k},
\end{align*}
where the expansion coefficients are called connection coefficients or Christoffel symbols. There is no unique way to do this, as the connection then depends on the choice of vectors.

\paragraph{The Connection of a Tensor Field}
%TODO: Show
By a lengthy process of product rule application one obtains
\begin{align*}
\tensor*{(\dcov{X}{T})}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}} &= X^{a}\left(\del{a}{\tensor*{T}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} + \sum\limits_{i = 1}^{n}\chris{a_{i}}{a}{b}\tensor*{T}{^{a_{1}\dots a_{i - 1}ba_{i + 1}\dots a_{n}}_{b_{1}\dots b_{m}}} - \sum\limits_{j = 1}^{m}\chris{b}{a}{b_{j}}\tensor*{T}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{j - 1}bb_{j + 1}\dots b_{m}}}\right).
\end{align*}

\paragraph{Parallel Transport}
A vector $X$ is termed parallel if $\dcov{a}{X} = 0$. This system is overdetermined, and generally has no solution on a manifold. We may, however, define $X$ to be parallel along a curve $\gamma$ if
\begin{align*}
\dcov{\dot{\gamma}}{X} = 0.
\end{align*}
This allows us to define the parallel transport as the vector field that solves the above equation with the vector $X$ as its initial condition. This system of equations is solvable.

In particular, using the properties of the connection we find
\begin{align*}
\dcov{\dot{\gamma}}{X} &= \dcov{\dot{\chi}^{a}\del{a}{}}{X^{c}\del{c}{}} \\
&= \dot{\chi}^{a}\dcov{a}{X^{c}\del{c}{}} \\
&= \dot{\chi}^{a}((\dcov{a}{X^{c}})\del{c}{} + X^{c}\dcov{a}{\del{c}{}}) \\
&= \dot{\chi}^{a}(\del{a}{X^{b}} + X^{c}\chris{b}{a}{c})\del{b}{}.
\end{align*}

\paragraph{Geodesics and the Geodesic Equation}
A geodesic is defined as a curve with a tangent vector that is parallel along itself.

By definition a geodesic satisfies
\begin{align*}
\dcov{\dot{\gamma}}{\dot{\gamma}} = \dot{\chi}^{a}(\del{a}{\dot{\chi}^{b}} + \dot{\chi}^{c}\chris{b}{a}{c})\del{b}{} = (\ddot{\chi}^{b} + \dot{\chi}^{a}\dot{\chi}^{c}\chris{b}{a}{c})\del{b}{} = 0.
\end{align*}
This is the geodesic equation. Given a starting point and a tangent vector, it is solvable.

\paragraph{Torsion}
The torsion tensor is a $(1, 2)$ tensor defined as
\begin{align*}
T(X, Y) = \dcov{X}{Y} - \dcov{Y}{X} - \comm{X}{Y}.
\end{align*}
To find its components, we note that
\begin{align*}
T(\del{a}{}, \del{b}{}) &= \dcov{a}{\del{b}{}} - \dcov{b}{\del{a}{}} - \comm{\del{X}{a}}{\del{Y}{b}} \\
&= (\chris{c}{a}{b} - \chris{c}{b}{a})\del{c}{}.
\end{align*}

\paragraph{Curvature}
Consider some vector $Z$ parallel transported along a small closed loop. The parallel transport is linear, so the result of this process must be connected to some $(1, 1)$ tensor. Supposing that the loop is spanned by $X$ and $Y$, we have
\begin{align*}
Z^{\prime} - Z = R(X, Y)Z = \dcov{X}{\dcov{Y}{Z}} - \dcov{Y}{\dcov{X}{Z}} - \dcov{\comm{X}{Y}}{Z}.
\end{align*}
We define $R(X, Y)Z$ as the Riemann curvature tensor. It is a $(1, 3)$ tensor. Its components are defined by
\begin{align*}
R(\del{a}{}, \del{b}{})\del{c}{} &= \tensor{R}{^{d}_{cab}}\del{d}{} \\
&= \dcov{a}{\dcov{b}{\del{c}{}}} - \dcov{b}{\dcov{a}{\del{c}{}}} \\
&= \dcov{a}{\chris{f}{b}{c}\del{f}{}} - \dcov{b}{\chris{f}{a}{c}\del{f}{}} \\
&= (\dcov{a}{\chris{f}{b}{c}})\del{f}{} + \chris{f}{b}{c}\dcov{a}{\del{f}{}} - (\dcov{b}{\chris{f}{a}{c}})\del{f}{} - \chris{f}{a}{c}\dcov{b}{\del{f}{}} \\
&= (\del{a}{\chris{d}{b}{c}} + \chris{f}{b}{c}\chris{d}{a}{f} - \del{b}{\chris{d}{a}{c}} - \chris{f}{a}{c}\chris{d}{b}{f})\del{d}{}, 
\end{align*}
and thus
\begin{align*}
\tensor{R}{^{d}_{cab}} = \del{a}{\chris{d}{b}{c}} - \del{b}{\chris{d}{a}{c}} + \chris{f}{b}{c}\chris{d}{a}{f} - \chris{f}{a}{c}\chris{d}{b}{f}.
\end{align*}
Note the placements of the indices.

\paragraph{The Metric Tensor}
The metric tensor will be taken as the $(0, 2)$ tensor that defines inner products on manifolds. The inner product, and therefore also the metric tensor, is a map from $\ts{p}{M}\times\ts{p}{M}$ that is symmetric and positive definite. Using this we may extend more of the previously performed work, for instance on curve length.

\paragraph{Metric Compatibility}
A connection is metric compatible if $\dcov{X}{g} = 0$ for all vectors $X$.

\paragraph{The Geodesic Equation Revisited}
As the metric defines length, we define the curve length as
\begin{align*}
l_{\gamma} = \integ{\gamma}{}{s}{} = \integ{0}{1}{t}{\sqrt{g_{ab}\dot{\chi}^{a}\dot{\chi}^{b}}}.
\end{align*}
Defining $\sqrt{\lag} = g_{ab}\dot{\chi}^{a}\dot{\chi}^{b}$, the curve that minimizes the distance between the start and end points satisfies
\begin{align*}
\del{a}{\sqrt{\lag}} - \dv{t}\pdv{\sqrt{\lag}}{\dot{\chi}^{a}} = \frac{1}{2\sqrt{\lag}}\left(\del{a}{\lag} - \sqrt{\lag}\dv{t}\left(\frac{1}{\sqrt{\lag}}\pdv{\lag}{\dot{\chi}^{a}}\right)\right) = 0.
\end{align*}
One can always choose a parametrization such that $\sqrt{\lag} = 0$ (the arc length parametrization is one example), yielding
\begin{align*}
\frac{1}{2\sqrt{\lag}}\left(\del{a}{\lag} - \dv{t}\pdv{\lag}{\dot{\chi}^{a}}\right) = 0,
\end{align*}
which is equivalent to extremizing the integral of $\lag$. In terms of the coordinate functions we thus have
\begin{align*}
\del{a}{g_{ab}}\dot{\chi}^{a}\dot{\chi}^{b} - \dv{t}\pdv{\lag}{\dot{\chi}^{a}}
\end{align*}
%TODO: Finish

\paragraph{The Levi-Civita Connection}
For any manifold with some metric there exists a unique connection that is both metric compatible and torsion free. This connection is termed the Levi-Civita connection.

\paragraph{The Levi-Civita Connection and Geodesics}
The connection coefficients (or Christoffel symbols) defined by the Levi-Civita connection are symmetric due to the torsion being zero. This implies
\begin{align*}
\chris{d}{a}{b} = \frac{1}{2}g^{cd}(\del{b}{g_{ac}} + \del{a}{g_{bc}} - \del{c}{g_{ab}}).
\end{align*}

\paragraph{The Induced Metric}
Given some immersion $f$ of $M_{1}$ into $M_{2}$ and supposing that the metric $g$ exists on $M_{2}$, this induces a metric $\tilde{g} = \pub{f}{g}$ on $M_{1}$.

\paragraph{Curvature and the Metric}
Using a Levi-Civita connection, we introduce the covariant curvature with components
\begin{align*}
R_{abcd} &= \frac{1}{2}\left(\del{a}{\del{d}{g_{bc}}} + \del{b}{\del{c}{g_{ad}}} - \del{a}{\del{c}{g_{bd}}} - \del{b}{\del{d}{g_{ac}}}\right) + g_{fh}(\chris{f}{b}{c}\chris{h}{a}{d} - \chris{f}{b}{d}\chris{h}{a}{c}).
\end{align*}
We find $R_{abcd} = R_{cdab} = -R_{abdc} = -R_{bacd}$. In addition, the curvature satisfies the Bianchi identity $R(X, Y)Z + R(Y, Z)X + R(Z, X)Y = 0$, implying $R_{abcd} + R_{acdb} + R_{adbc} = 0$, meaning that the total number of independent components is $\frac{1}{12}n^{2}(n^{2} - 1)$.

\paragraph{The Ricci Tensor}
The Ricci tensor is defined as $R_{ab} = \tensor{R}{^{c}_{acb}}$.

\paragraph{The Ricci Scalar}
The Ricci scalar is defined as the trace of the Ricci scalar: $\mathcal{R} = g^{ab}R_{ab} = g^{ab}\tensor{R}{^{c}_{acb}}$.

\paragraph{The Einstein Tensor}
The Einstein tensor is defined as $G_{ab} = R_{ab} - \frac{1}{2}g_{ab}\mathcal{R}$.

\paragraph{Killing Fields}
$K$ is a Killing field (be careful looking this up on the internet) if $\lied{K}{g} = 0$.

\paragraph{The Lie Derivative with Killing Fields}
Let $K$ be a Killing field. We then obtain
\begin{align*}
\lied{K}{g_{ab}} &= K^{a}\del{c}{g_{ab}} + g_{ac}\del{b}{K^{c}} + g_{cb}\del{a}{K^{c}} \\
&= K^{d}(\chris{c}{d}{a}g_{cb} + \chris{c}{d}{b}g_{ac}) + g_{ac}\del{b}{K^{c}} + g_{cb}\del{a}{K^{c}} \\
&= g_{ac}(\del{b}{K^{c}} + \chris{c}{d}{b}K^{d}) + g_{cb}(\del{a}{K^{c}} + K^{d}\chris{c}{d}{a}) \\
&= g_{ac}\dcov{b}{K^{c}} + g_{cb}\dcov{a}{K^{c}} \\
&= \dcov{b}{K_{a}} + \dcov{a}{K_{b}} = 0,
\end{align*}
where we are now using the proper covariant derivative.

\paragraph{Differential Forms}
The set of $p$-forms, or differential forms, is the set of $(0, p)$ tensors that are completely antisymmetric. They are constructed using the wedge product, defined as
\begin{align*}
\bigwedge\limits_{k = 1}^{p}d\chi^{a_{k}} = \sum\limits_{\sigma\in S_{p}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p}d\chi^{a_{\sigma(k)}}.
\end{align*}
Here $S_{p}$ is the set of permutations of $p$ elements. There exists
\begin{align*}
n_{p}^{N} = {N\choose k}
\end{align*}
basis elements. We note that the wedge product is antisymmetric under the exchange of two basis elements. Hence, once an ordering of indices has been chosen, any permutation will simply create a linearly dependent map.

Consider now some antisymmetric tensor $\omega$. Introducing the antisymmetrizer
\begin{align*}
\bigotimes_{k = 1}^{p}d\chi^{[a_{\sigma(k)}]} = \frac{1}{p!}\sum\limits_{\sigma\in S_{p}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p}d\chi^{a_{\sigma(k)}},
\end{align*}
the symmetry yields
\begin{align*}
\omega = \omega_{a_{1}\dots a_{p}}\bigotimes_{k = 1}^{p}d\chi^{a_{\sigma(k)}} = \omega_{a_{1}\dots a_{p}}\bigotimes_{k = 1}^{p}d\chi^{[a_{\sigma(k)}]} = \frac{1}{p!}\omega_{a_{1}\dots a_{p}}\bigwedge\limits_{k = 1}^{p}d\chi^{a_{k}}.
\end{align*}

\paragraph{The Exterior Derivative}
We define the exterior derivative of a differential form according to
\begin{align*}
d\omega = \frac{1}{p!}\del{a_{1}}{\omega_{a_{2}\dots a_{p + 1}}}\bigwedge\limits_{k = 1}^{p + 1}d\chi^{a_{k}},
\end{align*}
which is a $p + 1$-form. This notation makes sense, as at least in the case of a $0$-form, we obtain
\begin{align*}
d\omega = \del{a}{\omega}d\chi^{a},
\end{align*}
which is exactly the form of a dual vector. Somehow this transforms as a tensor.

\paragraph{Integration of Differential Forms}
Consider a set of $p$ tangent vectors $X_{i}$. The corresponding coordinate displacements are $\dd{\chi_{i}^{a}} = X_{i}^{a}\dd{t_{i}}$, with no sum over $i$. We would now like to compute the $p$-dimensional volume defined by the $X_{i}$ and $\dd{t_{i}}$. We expect that if any of the $X_{i}$ are linearly dependent the volume should be zero. We also expect that the volume be linear in the $X_{i}$. This implies
\begin{align*}
\dd{V_{p}} = \omega(X_{1}, \dots, X_{p})\dd{t_{1}}\dots\dd{t_{p}}
\end{align*}
for some differential form $\omega$. We now define the integral over the $p$-volume $S$ over the $p$-form $\omega$ as
\begin{align*}
\minteg{S}{\omega} = \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p}}{\omega(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p})}}.
\end{align*}
Here the $\gamma_{i}$ are the set of curves that span $S$, the dot symbolizes the derivative with respect to the individual curve parameters and the right-hand integration is performed over the appropriate set of parameter values.

\paragraph{Stokes' Theorem}
Stokes' theorem relates the integral of a differential form $d\omega$ over some subset $V$ of a manifold to an integral over \bound{V} of another differential form.

To derive it, consider a $p + 1$-volume parametrized such that all $t_{i}$ range from 0 to 1 and such that for any fixed $t_{p + 1}$, the remaining $t_{i}$ parametrize a $p$-dimensional surface $V_{p}$ with a boundary independent of $t_{p + 1}$. This construction is somewhat restrictive, but only necessary in the derivation.

For some $p$-form $\omega$ and $p + 1$-volume $V$ we have
\begin{align*}
\minteg{V}{d\omega} &= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{d\omega(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}} \\
&= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\left(\del{a_{1}}{\omega_{a_{2}\dots a_{p + 1}}}\sum\limits_{\sigma\in S_{p + 1}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p + 1}d\chi^{a_{\sigma(k)}}\right)(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}} \\
&= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\left(\del{a_{1}}{\omega_{a_{2}\dots a_{p + 1}}}\bigotimes_{k = 1}^{p + 1}d\chi^{a_{\sigma(k)}}\right)(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}} \\
&= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\left(\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\bigotimes_{k = 1}^{p + 1}d\chi^{a_{\sigma(k)}}\right)(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p + 1})}},
\end{align*}
where the latter follows from the cyclicity imposed by the summation. We have
\begin{align*}
d\chi^{a_{\sigma(k)}}{\dot{\gamma}_{k}} = \dv{\chi^{a}}{t_{k}}\del{a}{\chi^{a_{\sigma(k)}}} = \dv{\chi^{a_{\sigma(k)}}}{t_{k}},
\end{align*}
and thus
\begin{align*}
\minteg{V}{d\omega} &= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p + 1}\del{t_{k}}{\chi^{a_{\sigma(k)}}}}} \\
&= \sum\limits_{\sigma\in S_{p + 1}}\frac{\text{sgn}(\sigma)}{p!}\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p + 1}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}},
\end{align*}
where we have once again utilized the cyclicity. Denote the integral inside the sum as $I(\sigma, \omega)$. We have
\begin{align*}
I(\sigma, \omega) &= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{a_{p + 1}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p + 1}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}} \\
&= \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\del{t_{\sigma(p + 1)}}{\omega_{a_{1}\dots a_{p}}}\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}.
\end{align*}
To proceed, we integrate by parts and obtain
\begin{align*}
I(\sigma, \omega) &= \eval{\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\omega_{a_{1}\dots a_{p}}\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}}_{t_{\sigma(p + 1)} = t_{\sigma(p + 1)}^{-}}^{t_{\sigma(p + 1)} = t_{\sigma(p + 1)}^{+}} - \integ{}{}{t_{1}}{\dots \integ{}{}{t_{p + 1}}{\omega_{a_{1}\dots a_{p}}\del{t_{\sigma(p + 1)}}{\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}},
\end{align*}
where the former terms contains no integration over $t_{\sigma(p + 1)}$, and is instead evaluated at the maximal and minimal values of $t_{\sigma(p + 1)}$ given the values of the other parameters.

Let us proceed to simplify this. For starters, if $\sigma(p + 1) \neq p + 1$, the remaining integration in the first term is done over the boundary of $V_{p}$. Furthermore, there exists a $k$ such that $\sigma(k) = p + 1$, and as we are at the boundary of $V_{p}$ we must have
\begin{align*}
\del{t_{\sigma(k)}}{\chi^{a_{k}}} = 0.
\end{align*}
Otherwise, the remaining integration domain is $V_{p}$. Next, the latter integral contains a sequence of terms proportional to
\begin{align*}
\del{t_{\sigma(p + 1)}}{\del{t_{\sigma(k)}}{\chi^{a_{k}}}},
\end{align*}
which is symmetric with respect to exchanging $p + 1$ and $k$. These terms therefore cancel in the sum, and we are left with
\begin{align*}
\minteg{V}{d\omega} &= \sum\limits_{\sigma\in S_{p}}\frac{\text{sgn}(\sigma)}{p!}\eval{\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p}}{\omega_{a_{1}\dots a_{p}}\prod\limits_{k = 1}^{p}\del{t_{\sigma(k)}}{\chi^{a_{k}}}}}}_{t_{\sigma(p + 1)} = 0}^{t_{\sigma(p + 1)} = 1} \\
&= \eval{\integ{}{}{t_{1}}{\dots \integ{}{}{t_{p}}{\omega}}}_{t_{\sigma(p + 1)} = 0}^{t_{\sigma(p + 1)} = 1}
\end{align*}
where the condition that $\sigma(p + 1) = p + 1$ restricts the summation to $S_{p}$.

The remaining integration domain is, as stated before, a parametrization of $V_{p}$, which at the extremal values of $t_{p + 1}$ must be at the boundary of $V$. The minus sign from the integral evaluation tells us that the integrals are taken with opposite orientation, meaning that together they indeed form an integration over the (closed) boundary of $V$. We thus arrive at Stokes' theorem,
\begin{align*}
\minteg{V}{d\omega} = \oint\limits_{\bound{V}}\omega.
\end{align*}

\example{Reobtaining Familiar Theorems}
Many familiar integration theorems are in fact consequences of Stokes' theorem. Let us rederive them.

We start with a $1$-form $d\omega$, which will be integrated over a $1$-dimensional volume, i.e. a curve. We have
\begin{align*}
\minteg{\gamma}{d\omega} = \omega(p) - \omega(q),
\end{align*}
where $q$ and $p$ are the start and end points of $\gamma$. This is the analogue of integrating a vector field along a curve.

Next, we consider a $2$-form written as the exterior derivative of a $1$-form. Writing $\omega = \omega_{i}d\chi^{i}$ we have
\begin{align*}
d\omega = \del{j}{\omega_{i}}d\chi^{j}\wedge d\chi^{i}.
\end{align*}
Using Cartesian coordinates and restricting ourselves to two dimensions we have
\begin{align*}
\df{\chi^{j}}\wedge\df{\chi^{i}}(\dot{\gamma}_{s}, \dot{\gamma}_{t})\dd{s}\dd{t} &= (\df{\chi^{j}}\otimes\df{\chi^{i}} - \df{\chi^{i}}\otimes\df{\chi^{j}})(\dot{\gamma}_{s}, \dot{\gamma}_{t})\dd{s}\dd{t} \\
&= (\del{s}{\chi^{j}}\del{t}{\chi^{i}} - \del{s}{\chi^{i}}\del{t}{\chi^{j}})\dd{s}\dd{t} \\
&= (\delta_{jk}\delta_{im} - \delta_{ik}\delta_{jm})\del{s}{\chi^{k}}\del{t}{\chi^{m}}\dd{s}\dd{t} \\
&= \varepsilon_{jin}\varepsilon_{nkm}\del{s}{\chi^{k}}\del{t}{\chi^{m}}\dd{s}\dd{t} \\
&= \varepsilon_{jik}\dd{S_{k}}.
\end{align*}
Thus we have
\begin{align*}
\minteg{S}{d\omega} = \integ{S}{}{S_{k}}{\varepsilon_{ijk}\del{i}{\omega_{j}}} = \integ{S}{}{\vb{S}}{\cdot\curl{\vb*{\omega}}}.
\end{align*}
At the same time we have
\begin{align*}
\minteg{\bound{S}}{\omega} &= \integ{\bound{S}}{}{t}{\omega_{a}\df{\chi^{a}}(\dot{\gamma}_{t})} \\
&= \integ{\bound{S}}{}{t}{\omega_{a}\dv{\chi^{a}}{t}} \\
&= \integ{\bound{S}}{}{\vb{r}}{\cdot\vb*{\omega}},
\end{align*}
hence
\begin{align*}
\integ{S}{}{\vb{S}}{\cdot\curl{\vb*{\omega}}} = \integ{\bound{S}}{}{\vb{r}}{\cdot\vb*{\omega}},
\end{align*}
which is the more boring version of Stokes' theorem.

Next we consider a $2$-form and its exterior derivative. We have
\begin{align*}
\minteg{V}{\df{\omega}} &= \frac{1}{2}\minteg{V}{\del{a}{\omega_{bc}}\df{\chi^{a}}\wedge\df{\chi^{b}}\wedge\df{\chi^{c}}}.
\end{align*}
As the components of $\omega$ may be chosen such that $\omega_{ab} = -\omega_{ba}$ we may write $\omega_{ab} = \varepsilon_{abc}\omega_{c}$ for some suitable (and arbitrary) choice of $\omega_{c}$. We thus have
\begin{align*}
\minteg{V}{\df{\omega}} &= \frac{1}{2}\minteg{V}{\varepsilon_{bcd}\del{a}{\omega_{d}}\df{\chi^{a}}\wedge\df{\chi^{b}}\wedge\df{\chi^{c}}} \\
&= \frac{1}{2}\integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\varepsilon_{bcd}\varepsilon_{abc}\del{a}{\omega_{d}}}}} \\
&= \frac{1}{2}\integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{(\delta_{ad}\delta_{bb} - \delta_{ab}\delta_{bd})\del{a}{\omega_{d}}}}} \\
&= \integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\del{a}{\omega_{a}}}}} \\
&= \integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\div{\vb*{\omega}}}}}.
\end{align*}
At the same time we have
\begin{align*}
\minteg{\bound{V}}{\omega} &= \frac{1}{2}\minteg{\bound{V}}{\varepsilon_{ijk}\omega_{i}\df{\chi^{j}}\wedge\df{\chi^{k}}} \\
&= \frac{1}{2}\integ{\bound{V}}{}{S_{m}}{\varepsilon_{ijk}\varepsilon_{jkm}\omega_{i}} \\
&= \frac{1}{2}\integ{\bound{V}}{}{S_{m}}{(\delta_{im}\delta_{jj} - \delta_{ij}\delta_{jm})\omega_{i}} \\
&= \integ{\bound{V}}{}{S_{i}}{\omega_{i}} \\
&= \integ{\bound{V}}{}{\vb{S}}{\cdot\vb*{\omega}}.
\end{align*}
Hence we have
\begin{align*}
\integ{}{}{x^{1}}{\integ{}{}{x^{2}}{\integ{}{}{x^{3}}{\div{\vb*{\omega}}}}} = \integ{\bound{V}}{}{\vb{S}}{\cdot\vb*{\omega}},
\end{align*}
which is the divergence theorem.

\example{The $n$-Dimensional Divergence Theorem}

\paragraph{The Geometry of Curved Space}
We can also impose a metric tensor such that $\vb{v}\cdot\vb{w} = g_{ab}v^{a}w^{b}$, where the metric tensor is symmetric and positive definite.

Dual vectors can be defined as linear maps from tangent vectors to scalars, i. e. on the form
\begin{align*}
V(\vb{w}) = V_{a}w^{a}.
\end{align*}
In particular, the dual vector $\dd{f}$ can be defined as
\begin{align*}
\dd{f}(\vb{v}) = v^{a}\del{a}{f} = \dv{f}{t}
\end{align*}
along a curve with $\vb{v}$ as a tangent. A basis for the space of dual vectors is $e^{a} = \dd{\chi^{a}}$. The tangent and dual spaces, if a metric exists, are related by $v_{a} = g_{ab}v^{b}$.

Curve lengths are defined and computed as before. By defining geodesics as curves that extremize path length, this gives a set of Christoffel symbols and therefore a covariant derivative and a sense of what it means for a vector to change along a curve.