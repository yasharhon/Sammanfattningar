\section{Mathematical Prior}

\paragraph{The Residue Theorem}
The residue theorem states that for a function $f(z)$ with a pole of order $n$ at $z_{0}$, the integral of $f$ about a positively oriented contour around $z_{0}$ satisfies
\begin{align*}
	\oint\frac{\dd{z}}{2\pi i}f(z) = \text{Res}(f, z_{0}),
\end{align*}
with
\begin{align*}
	\text{Res}(f, z_{0}) = \frac{1}{(n - 1)!}\lim\limits_{z\to z_{0}}\dv[n - 1]{z}\left((z - z_{0})^{n}f(z)\right).
\end{align*}

\paragraph{The Lie Derivative}
For a tensor field $T$ we define the Lie derivative in the $X$-direction as
\begin{align*}
	\lied{X}{T} = \lim\limits_{\varepsilon\to 0}\frac{1}{\varepsilon}\left(\pub{\gamma_{\varepsilon X}}{T} - T\right).
\end{align*}
As the definition is similar to that of the usual derivative, it follows that it is linear in its argument and satisfies the product rule, where the product in question is now the tensor product. We have
\begin{align*}
	\tensor*{(\lied{X}{T})}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}} &= X^{a}\del{}{a}{\tensor*{T}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{m}}}} - \sum\limits_{i = 1}^{n}\tensor*{T}{^{a_{1}\dots a_{i - 1}aa_{i + 1}\dots a_{n}}_{b_{1}\dots b_{m}}}\del{}{a}{X^{a_{i}}} + \sum\limits_{j = 1}^{m}\tensor*{T}{^{a_{1}\dots a_{n}}_{b_{1}\dots b_{i - 1}ab_{i + 1}\dots b_{m}}}\del{}{b_{j}}{X^{a}}.
\end{align*}

\paragraph{Pushforwards and Pullbacks}
Consider some function $f$ which maps a manifold $M_{1}$ to another manifold $M_{2}$, as well as a function $g: M_{2}\to\R$. We then define the pullback of $g$ to $M_{1}$ by $f$ as $\pub{f}{g} = g\circ f$. We also define the pushforward of a vector $V\in\ts{p}{M_{1}}$ by $f$ as the map $\ts{p}{M_{1}}\to\ts{p}{M_{2}}$ such that $(\puf{f}{V})\phi = V(\pub{f}{\phi})$.

We can also define the pullback of a $(0, m)$ tensor on $M_{2}$ by $f$ according to
\begin{align*}
	\pub{f}{\omega}(V_{1}, \dots, V_{m}) = \omega(\puf{f}{V_{1}}, \dots, \puf{f}{V_{m}}).
\end{align*}
Its components are
\begin{align*}
	\tensor{(\pub{f}{\omega})}{_{a_{1}\dots a_{m}}} =& \omega_{\mu_{1}\dots\mu_{m}}\prod\limits_{i = 1}^{m}\del{}{a_{i}}{f^{\mu_{i}}}.
\end{align*}

Finally, if $f$ is a bijection we may also define the more general pullback of a $(n, m)$ tensor on $M_{2}$ as
\begin{align*}
	\pub{f}{T}(V_{1}, \dots, V_{m}, \omega_{1}, \dots, \omega_{n}) = T(\puf{f}{V_{1}}, \dots, \puf{f}{V_{m}}, \pub{(f^{-1})}{\omega_{1}}, \dots, \pub{(f^{-1})}{\omega_{n}}).
\end{align*}
Its components are
\begin{align*}
	\tensor*{(\pub{f}{T})}{^{b_{1}\dots b_{n}}_{a_{1}\dots a_{m}}} = T^{\mu_{1}\dots \mu_{n}}_{\nu_{1}\dots\nu_{m}}\prod\limits_{i = 1}^{m}\del{}{a_{i}}f^{\nu_{i}}\prod\limits_{j = 1}^{n}\del{}{\mu_{j}}(f^{-1})^{b_{j}}.
\end{align*}

\paragraph{Properties of the Pullback}
One important property of the pullback is its symmetry preservation. To study it, it will be sufficient to study the pullback of a $(0, 2)$ tensor, as the proof generalizes to an arbitrary number of indices.

We have
\begin{align*}
	\tensor*{(\pub{f}{T})}{_{ab}} \pm \tensor*{(\pub{f}{T})}{_{ba}} =& T_{\mu\nu}\del{}{a}f^{\mu}\del{}{b}f^{\nu} \pm T_{\mu\nu}\del{}{b}f^{\mu}\del{}{a}f^{\nu} \\
	=& (T_{\mu\nu} \pm T_{\nu\mu})\del{}{b}f^{\mu}\del{}{a}f^{\nu},
\end{align*}
which implies that (anti)symmetry is preserved by the pullback. The important property is that the pullback is linear in the tensor that is pulled back, and as such the argument generalizes to (anti)symmetry with respect to an arbitrary number of indices.

\paragraph{Embeddings and Immersions}
Consider two manifolds $M$ and $N$ connected by a map $f$. $f$ induces both the pullback and pushforward, at least when restricted to tangent and dual vectors, and it turns out that if one of these is invertible, so is the other. If $f$ induces an invertible pushforward and pullback is called an immersion of $M$ into $N$, and if $f$ is itself invertible, it is called an embedding of $M$ into $N$. The image $f(M)$ is then called a submanifold of $N$.

One noteworthy thing about embeddings is the induction of tensors through them, the metric being a great example. We have
\begin{align*}
	\tilde{g}_{ab} = (\pub{f}{g})_{ab} = g_{\mu\nu}\del{}{a}f^{\mu}\del{}{b}f^{\nu},
\end{align*}
and so the length element is
\begin{align*}
	\dd{\tilde{s}}^{2} = \tilde{g}_{ab}\dd{x^{a}}\dd{x^{b}} = g_{\mu\nu}\del{}{a}f^{\mu}\del{}{b}f^{\nu}\dd{x^{a}}\dd{x^{b}} = g_{\mu\nu}\dd{y^{\mu}}\dd{y^{\nu}} = \dd{s}^{2}.
\end{align*}
That is, this induced metric preserves the notion of length under the mapping.

\paragraph{Differential Forms}
The set of $p$-forms, or differential forms, is the set of $(0, p)$ tensors that are completely antisymmetric. They are constructed using the wedge product, defined as
\begin{align*}
	\bigwedge\limits_{k = 1}^{p}d\chi^{\mu_{k}} = \sum\limits_{\sigma\in S_{p}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p}d\chi^{\mu_{\sigma(k)}}.
\end{align*}
Here $S_{p}$ is the set of permutations of $p$ elements. There exists
\begin{align*}
	n_{p}^{N} = {N\choose k}
\end{align*}
basis elements. We note that the wedge product is antisymmetric under the exchange of two basis elements. Hence, once an ordering of indices has been chosen, any permutation will simply create a linearly dependent map.

Consider now some antisymmetric tensor $\omega$. Introducing the antisymmetrizer
\begin{align*}
	\bigotimes_{k = 1}^{p}d\chi^{[\mu_{\sigma(k)}]} = \frac{1}{p!}\sum\limits_{\sigma\in S_{p}}\text{sgn}(\sigma)\bigotimes_{k = 1}^{p}d\chi^{\mu_{\sigma(k)}},
\end{align*}
the symmetry yields
\begin{align*}
	\omega = \omega_{\mu_{1}\dots \mu_{p}}\bigotimes_{k = 1}^{p}d\chi^{\mu_{\sigma(k)}} = \omega_{\mu_{1}\dots \mu_{p}}\bigotimes_{k = 1}^{p}d\chi^{[\mu_{\sigma(k)}]} = \frac{1}{p!}\omega_{\mu_{1}\dots \mu_{p}}\bigwedge\limits_{k = 1}^{p}d\chi^{\mu_{k}}.
\end{align*}
In other words, we can antisymmetrize the components of $\omega$ to write it as a differential form.

Two important classes of differential forms are exact and closed forms. An exact form is the exterior derivative of another, while a closed form has zero external derivative.

\paragraph{The Exterior Derivative}
We define the exterior derivative of a differential form according to
\begin{align*}
	d\omega = \frac{1}{p!}\del{}{\mu_{1}}\omega_{\mu_{2}\dots \mu_{p + 1}}\bigwedge\limits_{k = 1}^{p + 1}d\chi^{\mu_{k}},
\end{align*}
which is a $p + 1$-form. By its nature this is an antiderivative - that is,
\begin{align*}
	\df{(a\wedge b)} = \df{a}\wedge b + (-1)^{p}a\wedge\df{b},
\end{align*}
where $p$ is the rank of $a$.

\paragraph{Differential Forms and Pullbacks}
We will now briefly show some properties of differential forms related to the pullback.

The first is, for two maps $f: M_{1}\to M_{2}$ and $g: M_{2}\to M_{3}$, that
\begin{align*}
	(\pub{(g\circ f)}{\omega})(X_{1}, \dots, X_{n}) =& \omega(\puf{(g\circ f)}{X_{1}}, \dots, \puf{(g\circ f)}{X_{n}}),
\end{align*}
with $\omega$ being an $n$-form on $M_{3}$ and $X_{i}$ vectors on $M_{1}$. For a vector we have
\begin{align*}
	(\puf{(g\circ f)}{X})(\phi) = X(\pub{(g\circ f)}{\phi}) = X(\phi\circ(g\circ f)).
\end{align*}
As function compositions are associative, this implies
\begin{align}
	\puf{(g\circ f)}{X} = \puf{g}{\puf{f}{X}},
\end{align}
and thus
\begin{align*}
	(\pub{(g\circ f)}{\omega})(X_{1}, \dots, X_{n}) =& \omega(\puf{g}{\puf{f}{X_{1}}}, \dots, \puf{g}{\puf{f}{X_{n}}}) \\
	=& \pub{g}{\omega}(\puf{f}{X_{1}}, \dots, \puf{f}{X_{n}}) \\
	=& \pub{f}{\pub{g}{\omega}}(X_{1}, \dots, X_{n}),
\end{align*}
and thus $\pub{(g\circ f)}{} = \pub{f}{}\circ\pub{g}{}$.

Next,
\begin{align*}
	\pub{f}{(\omega\wedge\eta)}(X_{1}, \dots, X_{n}, X_{n + 1}, \dots, X_{n + m}) =& \omega(\puf{f}{X_{1}}, \dots, \puf{f}{X_{n}})\wedge\eta(\puf{f}{X_{n + 1}}, \dots, \puf{f}{X_{n + m}}) \\
	=& \pub{f}{\omega}(X_{1}, \dots, X_{n})\wedge\pub{f}{\eta}(X_{n + 1}, \dots, X_{n + m}),
\end{align*}
and thus $\pub{f}{(\omega\wedge\eta)} = \pub{f}{\omega}\wedge\pub{f}{\eta}$.

This can be used to study
\begin{align*}
	\pub{f}{\left(\phi\df{\psi_{1}}\wedge\dots\wedge\df{\psi_{n}}\right)} =& \pub{f}{\phi}\cdot\pub{f}{(\df{\psi_{1}}\wedge\dots\wedge\df{\psi_{n}})}.
\end{align*}
We have
\begin{align*}
	\pub{f}{\df{\psi}}(X) = \df{\psi}(\puf{f}{X}) = (\puf{f}{X})(\psi) = X(\puf{f}{\psi}) = X(\psi\circ f) = \df{(\psi\circ f)}(X),
\end{align*}
and thus $\pub{f}{\df{\psi}} = \df{(\psi\circ f)}$, implying
\begin{align*}
	\pub{f}{\left(\phi\df{\psi_{1}}\wedge\dots\wedge\df{\psi_{n}}\right)} =& (\phi\circ f)\df{(\psi_{1}\circ f)}\wedge\dots\wedge\df{(\psi_{n}\circ f)}.
\end{align*}

A final important property comes from studying
\begin{align*}
	\pub{f}{(\df{\omega})} =& \pub{f}{\left(\frac{1}{n!}\del{}{\mu_{1}}\omega_{\mu_{2}\dots\mu_{n + 1}}\df{\chi^{\mu_{2}}}\wedge\dots\wedge\df{\chi^{\mu_{n + 1}}}\right)} \\
	=& \df{\left(\frac{1}{n!}\omega_{\mu_{2}\dots\mu_{n + 1}}\circ f\right)}\df{(\chi^{\mu_{2}}\circ f)}\wedge\dots\wedge\df{(\chi^{\mu_{n  +1}}\circ f)}.
\end{align*}
The pullback of the $1$-forms nets you basis vectors in the manifold to which you pull back, and thus you have
\begin{align*}
	\pub{f}{(\df{\omega})} =& \df{(\pub{f}{\omega})}.
\end{align*}

\paragraph{Interior Multiplication}
The interior multiplication of a differential form with a vector is defined as
\begin{align*}
	i_{X}\omega(\dots) = \omega(X, \dots).
\end{align*}
Its action on a 0-form is defined to yield zero. In index notation it is the contration of the first index of $\omega$ by $X$. It satisfies
\begin{align*}
	i_{X}(\eta\wedge\omega) = i_{X}(\eta)\wedge\omega + (-1)^{p}\eta\wedge(i_{X}\omega),
\end{align*}
where $p$ is the rank of $\eta$.

\paragraph{The Infinitesimal Homotopy Relation}
The infinitesimal homotopy relation relates the Lie derivative and the interior product. We will prove it by induction. First, for a 1-form, we have
\begin{align*}
	\df{(i_{X}\omega)} + i_{X}\df{\omega} =& \del{}{a}(X^{b}\omega_{b})\df{\chi^{a}} + \del{}{a}\omega_{b}\df{\chi^{a}}(X)\wedge\df{\chi^{b}} \\
	=& X^{b}\del{}{a}\omega_{b}\df{\chi^{a}} + \del{}{a}(X^{b})\omega_{b}\df{\chi^{a}} + \del{}{b}\omega_{a}\df{\chi^{b}}(X)\wedge\df{\chi^{a}} \\
	=& \left(X^{b}\del{}{a}\omega_{b} + \del{}{a}(X^{b})\omega_{b} + X^{b}\del{}{b}\omega_{a} - X^{b}\del{}{a}\omega_{b}\right)\df{\chi^{a}} \\
	=& \left(\del{}{a}(X^{b})\omega_{b} + X^{b}\del{}{b}\omega_{a}	\right)\df{\chi^{a}} \\
	=& \lied{X}{\omega}.
\end{align*}
We can see that this applies for 0-forms as well, as the first term will not be present in that case due to $i_{x}f = 0$ by definition. Finally, using the product rule we have
\begin{align*}
	\df{(i_{X}(\omega\wedge\eta))} + i_{X}\df{(\omega\wedge\eta)} =& \df{(i_{X}\omega\wedge\eta + (-1)^{p}\omega\wedge i_{X}\eta)} + i_{X}(\df{\omega}\wedge\eta + (-1)^{p}\omega\wedge\df{\eta}) \\
	=& \df{(i_{X}\omega)}\wedge\eta + (-1)^{p - 1}i_{X}\omega\wedge\df{\eta} + (-1)^{p}(\df{\omega}\wedge i_{X}\eta + (-1)^{p}\omega\wedge\df{(i_{X}\eta)}) \\
	 &+ i_{X}(\df{\omega})\wedge\eta + (-1)^{p + 1}\df{\omega}\wedge i_{X}\eta + (-1)^{p}(i_{X}\omega\wedge\df{\eta} + (-1)^{p}\omega\wedge i_{X}(\df{\eta})) \\
	=& (\df{(i_{X}\omega)} + i_{X}(\df{\omega}))\wedge\eta + (-1)^{p}\omega\wedge(\df{(i_{X}\eta)} + i_{X}(\df{\eta})).
\end{align*}
What we have shown here is that this operator follows the product rule under the wedge product. As it applies for 1-forms and 0-forms, from which higher forms can be constructed, it follows that
\begin{align*}
	\lied{X}{\omega} = \df{(i_{X}\omega)} + i_{X}\df{\omega}
\end{align*}
for any differential form.

\paragraph{The Volume Form}
The metric gives a notion of distance, and therefore a notion of volume. This is what we will discuss now. That volume is described by a differential form follows from our notion of orientation of volumes and surfaces in two and three dimensions. As such, the volume form $\eta$ should be of the form
\begin{align*}
	\eta = f(\chi)\df{\chi^{1}}\wedge\dots\wedge\df{\chi^{n}}.
\end{align*}
The form of $f$ is as of yet unknown.

Let us consider real space first. In three dimensions we have
\begin{align*}
	\dd{V} = \varepsilon_{ijk}\del{}{1}r^{i}\del{}{2}r^{j}\del{}{3}r^{k}\dd{\chi^{1}}\dd{\chi^{2}}\dd{\chi^{3}},
\end{align*}
with the Cartesian position vector $\vb{r}(\chi)$ acting as the embedding of coordinate space in $\R^{3}$. The prefactor for the differential must be proportional to $\varepsilon_{123}$ by matching with the chase where $\chi^{i} = r^{i}$, and because the metric in $\R^{3}$ is diagonal with elements $1$, the rest must be equal to $\sqrt{\det(g)}$. We thus infer
\begin{align*}
	\eta = \phi(\chi)\sqrt{\det(g)}\df{\chi^{1}}\wedge\dots\wedge\df{\chi^{n}}.
\end{align*}
To identify $\phi$, we consider orthogonal coordinates. In this case the metric is diagonal with elements $h_{i}^{2}$. On the other hand we expect a small cube spanned by vectors $X_{a} = \dd{t}\del{}{a}$ to have volume equal to $\dd{t}^{n}h_{1}\dots h_{n}$, and thus we must have $\phi = 1$. Thus the volume form is
\begin{align*}
	\eta = \sqrt{\det(g)}\df{\chi^{1}}\wedge\dots\wedge\df{\chi^{n}}.
\end{align*}

The volume of a manifold is slightly less trivial to define, but we can do it if the manifold is embedded by $f$ in some manifold with a volume form (the typical case is a manifold defined by a surface in real space). The idea we start with is flux. For a surface in real space, assuming the surface to be parametrized by $s^{i}$ and have tangent vectors $\dot{\gamma}_{i}\dd{s^{i}}$ (no sum) starting at a point and extending to some region limited by variations $\dd{s^{i}}$, the flux of a field $F$ is known to be equal to the volume spanned by $F$ and the tangents. This suggests that
\begin{align*}
	\dd{\Phi} = \eta(F, \dot{\gamma}_{1}\dd{s^{1}}, \dots, \dot{\gamma}_{n - 1}\dd{s^{n - 1}}) = i_{J}\eta(\dot{\gamma}_{1}\dd{s^{1}}, \dots, \dot{\gamma}_{n - 1}\dd{s^{n - 1}}).
\end{align*}
In particular, the volume can be computed using the flux of a field normal to the surface with unit length. Dubbing this field $\nu$ the volume form of the manifold is then
\begin{align*}
	\tilde{\eta} = \pub{f}{(i_{\nu}\eta)}.
\end{align*}

Let us now consider the exactness and closedness of the volume form. First of all, the volume form is not exact globally on a compact manifold (one without a boundary). Assuming the contrary, i.e. $\dd{\alpha} = \eta$, we find
\begin{align*}
	\inte{M}{}\eta = \inte{\bound{M}}{}\alpha.
\end{align*}
The left-hand side ought to be non-zero by construction, but the right-hand side clearly is, making the contradiction clear. A way to make this more flexible is to split $M$ into two parts, and we then have
\begin{align*}
	\inte{M}{}\eta = \inte{M_{1}}{}\eta + \inte{M_{2}}{}\eta.
\end{align*}
Assuming exactness on each half we have
\begin{align*}
	\inte{M}{}\eta = \inte{\bound{M_{1}}}{}\alpha_{1} + \inte{\bound{M_{2}}}{}\alpha_{2} = \inte{\bound{M_{1}}}{}\alpha_{1} - \alpha_{2}.
\end{align*}

\paragraph{Matrix-Valued Differential Forms}
A matrix-valued differential form is a differential form whose components are matrices. For these we need to define a slightly different wedge product according to
\begin{align*}
	\tensor{(A\wedge B)}{^{a}_{b}} = \tensor{A}{^{a}_{c}}\wedge\tensor{B}{^{c}_{b}}.
\end{align*}
In words, its components are found by computing the matrix product of the corresponding components of $A$ and $B$, but using the wedge product instead of the normal multiplication. The output of this is then a new matrix-valued differential form. Their exterior derivatives are defined as for normal differential forms. We will use greek indices for the differential form structure and latin indices for the matrix structure.

\paragraph{Non-Abelian Gauge Theory - an Example}
We define the field strength 2-form
\begin{align*}
	F = \df{A} + A^{2},
\end{align*}
where we now suppress wedge products, as tensor products will not appear. By definition we have
\begin{align*}
	A^{2} = (A_{\mu}\df{\chi^{\mu}})\wedge(A_{\nu}\df{\chi^{\nu}}) = \frac{1}{2}(A_{\mu}A_{\nu} - A_{\nu}A_{\mu})\df{\chi^{\mu}}\df{\chi^{\nu}} = \frac{1}{2}\comm{A_{\mu}}{A_{\nu}}\df{\chi^{\mu}}\df{\chi^{\nu}}.
\end{align*}
Now, $F$ is a differential form, meaning we can write $F = \frac{1}{2}F_{\mu\nu}\df{\chi^{\mu}}\df{\chi^{\nu}}$. As for $\df{A}$ we have
\begin{align*}
	\df{A} = \del{}{\mu}A_{\nu}\df{\chi^{\mu}}\df{\chi^{\nu}} = \frac{1}{2}(\del{}{\mu}A_{\nu} - \del{}{\nu}A_{\mu})\df{\chi^{\mu}}\df{\chi^{\nu}},
\end{align*}
where we in the last step explicitly antisymmetrized the result. Thus we have
\begin{align*}
	F_{\mu\nu} = \del{}{\mu}A_{\nu} - \del{}{\nu}A_{\mu} + \comm{A_{\mu}}{A_{\nu}}.
\end{align*}

Next, defining the gauge covariant derivative
\begin{align*}
	\grad_{\mu} = \del{}{\mu} + A_{\mu}.
\end{align*}
We then have
\begin{align*}
	\comm{\grad_{\mu}}{\grad_{\nu}} =& \comm{\del{}{\mu}}{\del{}{\nu}} + \comm{A_{\mu}}{A_{\nu}} + \comm{\del{}{\mu}}{A_{\nu}} - \comm{\del{}{\nu}}{A_{\mu}}.
\end{align*}
For the first commutator, all components have the same matrix structure, so they commute. For the last two terms we will need to use the product rule to find
\begin{align*}
	\comm{\del{}{\mu}}{A_{\nu}} = \del{}{\mu}A_{\nu} - A_{\nu}\del{}{\mu} = (\del{}{\mu}A_{\nu}) + A_{\nu}\del{}{\mu} - A_{\nu}\del{}{\mu} = (\del{}{\mu}A_{\nu}),
\end{align*}
with the brackets highlighting the terms that are self-contained and do not act as operators. Thus we have
\begin{align*}
	\comm{\grad_{\mu}}{\grad_{\nu}} = (\del{}{\mu}A_{\nu}) - (\del{}{\nu}A_{\mu}) + \comm{A_{\mu}}{A_{\nu}} = F_{\mu\nu}.
\end{align*}
Next, for two vector fields we have
\begin{align*}
	F(X, Y) =& \frac{1}{2}\comm{\grad_{\mu}}{\grad_{\nu}}\df{\chi^{\mu}}(X)\df{\chi^{\nu}}(Y) = \frac{1}{2}\comm{\grad_{\mu}}{\grad_{\nu}}(X^{\mu}Y^{\nu} - X^{\nu}Y^{\mu}).
\end{align*}
We have
\begin{align*}
	\grad_{\rho}X^{\mu}Y^{\nu} = \del{}{\rho}X^{\mu}Y^{\nu} + A_{\rho}(X^{\mu}Y^{\nu}) = Y^{\nu}\del{}{\rho}(X^{\mu}) + X^{\mu}\del{}{\rho}(Y^{\nu}) + X^{\mu}Y^{\nu}\del{}{\rho} + A_{\rho}X^{\mu}Y^{\nu},
\end{align*}
and in particular
\begin{align*}
	\grad_{\nu}X^{\mu}Y^{\nu} =& Y^{\nu}\del{}{\nu}(X^{\mu}) + X^{\mu}\del{}{\nu}(Y^{\nu}) + X^{\mu}Y^{\nu}\del{}{\nu} + A_{\nu}X^{\mu}Y^{\nu} = Y^{\nu}\del{}{\nu}(X^{\mu}) + X^{\mu}\del{}{\nu}(Y^{\nu}) + X^{\mu}\grad_{Y}, \\
	\grad_{\mu}X^{\mu}Y^{\nu} =& Y^{\nu}\del{}{\mu}(X^{\mu}) + X^{\mu}\del{}{\mu}(Y^{\nu}) + Y^{\nu}\grad_{X}.
\end{align*}
Thus we have
\begin{align*}
	\grad_{\mu}\grad_{\nu}X^{\mu}Y^{\nu} =& \del{}{\mu}Y^{\nu}\del{}{\nu}(X^{\mu}) + \del{}{\mu}X^{\mu}\del{}{\nu}(Y^{\nu}) + \del{}{\mu}X^{\mu}\grad_{Y} + A_{\mu}X^{\mu}\grad_{Y} \\
	=& \del{}{\mu}Y^{\nu}\del{}{\nu}(X^{\mu}) + \del{}{\mu}X^{\mu}\del{}{\nu}(Y^{\nu}) + (\del{}{\mu}X^{\mu})\grad_{Y} + \grad_{X}\grad_{Y}, \\
	\grad_{\nu}\grad_{\mu}X^{\mu}Y^{\nu} =& \del{}{\nu}Y^{\nu}\del{}{\mu}(X^{\mu}) + \del{}{\nu}X^{\mu}\del{}{\mu}(Y^{\nu}) + (\del{}{\nu}Y^{\nu})\grad_{X} + \grad_{Y}\grad_{X}
\end{align*}
The final result is found by first computing the difference of the above. One then notes down the result of swapping $X$ and $Y$ in that difference and subtracting that from what you have. First, the two connections net their commutator. The lone connections are found twice after the subtaction. Next, for the other terms the derivative can act on either factor or move to the right. The two former have terms with opposite sign cancelling them, and
\begin{align*}
	\comm{\grad_{\mu}}{\grad_{\nu}}(X^{\mu}Y^{\nu} - X^{\nu}Y^{\mu}) =& 2\comm{\grad_{X}}{\grad_{Y}} + 2\left((\del{}{\mu}X^{\mu})\grad_{Y} - (\del{}{\nu}Y^{\nu})\grad_{X}\right) \\
	&+ 2(Y^{\nu}(\del{}{\nu}X^{\mu}) + X^{\mu}(\del{}{\nu}Y^{\nu}))\del{}{\mu} - 2(Y^{\nu}(\del{}{\mu}X^{\mu}) + X^{\mu}(\del{}{\mu}Y^{\nu}))\del{}{\nu} \\
	=& 2\comm{\grad_{X}}{\grad_{Y}} + 2\left((\del{}{\mu}X^{\mu})\grad_{Y} - (\del{}{\nu}Y^{\nu})\grad_{X}\right) \\
	&+ 2\comm{Y}{X}^{\mu}\del{}{\mu} + 2(X^{\mu}(\del{}{\nu}Y^{\nu})\del{}{\mu} - Y^{\nu}(\del{}{\mu}X^{\mu})\del{}{\nu}) \\
	=& 2\comm{\grad_{X}}{\grad_{Y}} + 2\left((\del{}{\mu}X^{\mu})Y^{\nu}A_{\nu} - (\del{}{\nu}Y^{\nu})X^{\mu}A_{\mu}\right) + 2\comm{Y}{X}^{\mu}\del{}{\mu} \\
	=& 2\left(\comm{\grad_{X}}{\grad_{Y}} + \comm{Y}{X}^{\mu}A_{\mu} + \comm{Y}{X}^{\mu}\del{}{\mu}\right),
\end{align*}
and thus
\begin{align*}
	F(X, Y) = \comm{\grad_{X}}{\grad_{Y}} - \grad_{\comm{X}{Y}}.
\end{align*}

As for the exterior derivative of the field strength, we have
\begin{align*}
	\df{F} =& \frac{1}{2}\del{}{\mu}F_{\nu\rho}\df{\chi^{\mu}}\df{\chi^{\nu}}\df{\chi^{\rho}} \\
	       =& \frac{1}{2}\left(\del{}{\mu}(A_{\nu}A_{\rho}) - \del{}{\mu}(A_{\rho}A_{\nu})\right)\df{\chi^{\mu}}\df{\chi^{\nu}}\df{\chi^{\rho}} \\
	       =& \frac{1}{2}\left(\del{}{\mu}(A_{\nu})A_{\rho} + A_{\nu}\del{}{\mu}(A_{\rho}) - \del{}{\mu}(A_{\rho})A_{\nu} - A_{\rho}\del{}{\mu}(A_{\nu})\right)\df{\chi^{\mu}}\df{\chi^{\nu}}\df{\chi^{\rho}},
\end{align*}
as we have for any differential form $F$ that $\df{\df{F}} = \del{}{\mu}\del{}{\nu}F_{I}\df{\chi^{\mu}}\df{\chi^{\nu}}\df{\chi^{I}} = 0$, using the notation $I$ to refer to some set of indices. Now, by comparison we have
\begin{align*}
	FA - AF = \frac{1}{2}\comm{F_{\mu\nu}}{A_{\rho}}\df{\chi^{\mu}}\df{\chi^{\nu}}\df{\chi^{\rho}} = \frac{1}{2}\left(F_{\mu\nu}A_{\rho} - A_{\mu}F_{\nu\rho}\right)\df{\chi^{\mu}}\df{\chi^{\nu}}\df{\chi^{\rho}},
\end{align*}
using the properties of the indices under cyclic permutation. We find
\begin{align*}
	F_{\mu\nu}A_{\rho} - A_{\mu}F_{\nu\rho} =& \left(\del{}{\mu}A_{\nu} - \del{}{\nu}A_{\mu} + \comm{A_{\mu}}{A_{\nu}}\right)A_{\rho} - A_{\mu}\left(\del{}{\nu}A_{\rho} - \del{}{\rho}A_{\nu} + \comm{A_{\nu}}{A_{\rho}}\right) \\
	                                        =& \del{}{\mu}(A_{\nu})A_{\rho} - \del{}{\nu}(A_{\mu})A_{\rho} - A_{\mu}\del{}{\nu}A_{\rho} + A_{\mu}\del{}{\rho}A_{\nu},
\end{align*}
and permuting indices cyclically we find
\begin{align*}
	\df{F} + AF - FA = 0,
\end{align*}
which is a so-called Bianchi identity.

Next we study the form $F^{2}$. We have
\begin{align*}
	\df{F^{2}} = \df{(F)}F + F\df{F} = (FA - AF)F + F(FA - AF).
\end{align*}
Computing the trace of this involves computing the trace of objects of the form
\begin{align*}
	F_{\mu_{1}\mu_{2}}A_{\mu_{3}}F_{\mu_{4}\mu_{5}}\bigwedge\limits_{i = 1}^{5}\df{\chi^{\mu_{i}}}.
\end{align*}
We note that if the first factor of $F$ can be moved to the right in the trace, we will have shown that it is zero. Traces are invariant under cyclic permutation of matrices, so we can certainly move the components themselves. As for the differential forms, moving the first and second ones to the right requires either passing through $3$ others, providing no net sign and yielding
\begin{align*}
	\tr(\df{F^{2}}) = \df{\tr(F^{2})} = 0.
\end{align*}

Similarly we may consider the form $F^{n}$. Its trace is
\begin{align*}
	\df{\tr(F^{n})} = n\tr(F^{n - 1}\df{F}) = n\tr(F^{n - 1}(FA - AF)).
\end{align*}
By the exact same argument we must have
\begin{align*}
	\df{\tr(F^{n})} = 0.
\end{align*}
Alternatively, let us prove that
\begin{align*}
	\df{F^{n}} = F^{n}A - AF^{n}.
\end{align*}
Evidently it holds for $n = 1$. Next, assuming it to hold for some particular $n$, it follows that
\begin{align*}
	\df{F^{n + 1}} =& \df{(F^{n})}F + F^{n}\df{F} \\
	               =& (F^{n}A - AF^{n})F + F^{n}(FA - AF) \\
	               =& F^{n + 1}A - AF^{n + 1},
\end{align*}
completing the proof. Using the properties of the trace and the cyclic permutivity of the indices, we reobtain the same result.

The form $F^{2}$ is of some more interest. We have
\begin{align*}
	F^{2} = (\df{A})^{2} + A^{2}\df{A} + \df{(A)}A^{2} + A^{4}.
\end{align*}
Let us compute its trace. The last term is the easiest to handle as it is a contraction of a symmetric matrix product with an antisymmetric differential form, and is thus zero. Antisymmetrizing the components does not help due to the trace, which allows you to cyclically permute the matrices without changing the sign. Antisymmetrizing they start with the opposite sign of another term related to the first one by cyclic permutation, and it must be zero. As for the others we have
\begin{align*}
	\tr((\df{A})^{2} + A^{2}\df{A} + \df{(A)}A^{2}) =& \tr(\df{(A\df{A})} + \frac{2}{3}(A^{2}\df{A} + \df{(A)}A^{2} + A\df{(A)}A)) \\
	                                                =& \tr(\df{(A\df{A})} + \frac{2}{3}\df{A^{3}}) \\
	                                                =& \df{\tr((A\df{A}) + \frac{2}{3}A^{3})}.
\end{align*}

Let us finally investigate the topological invariance of integrals of $F^{2}$. Under a small deformation of $A$, we have
\begin{align*}
	\var{\tr(F^{n})} =& n\tr(F^{n - 1}\var{F}) \\
	                 =& n\left(\tr(F^{n - 1}\df{\var{A}}) + \tr(F^{n - 1}\var{A}A) + \tr(F^{n - 1}A\var{A})\right) \\
	                 =& n\left(\tr(F^{n - 1}\df{\var{A}}) - \tr(AF^{n - 1}\var{A}) + \tr(F^{n - 1}A\var{A})\right) \\
	                 =& n\tr(\df{F^{n - 1}\var{A}}).
\end{align*}

\paragraph{Integration of Differential Forms}
Consider a set of $p$ tangent vectors $X_{i}$. The corresponding coordinate displacements are $\dd{\chi_{i}^{a}} = X_{i}^{a}\dd{t_{i}}$, with no sum over $i$. We would now like to compute the $p$-dimensional volume defined by the $X_{i}$ and $\dd{t_{i}}$. We expect that if any of the $X_{i}$ are linearly dependent the volume should be zero. We also expect that the volume be linear in the $X_{i}$. This implies
\begin{align*}
	\dd{V_{p}} = \omega(X_{1}, \dots, X_{p})\dd{t_{1}}\dots\dd{t_{p}}
\end{align*}
for some differential form $\omega$. We now define the integral over the $p$-volume $S$ over the $p$-form $\omega$ as
\begin{align*}
	\inte{S}{}{\omega} = \inte{}{}\dd{t_{1}}{\dots \inte{}{}\dd{t_{p}}{\omega(\dot{\gamma}_{1},\dots, \dot{\gamma}_{p})}}.
\end{align*}
Here the $\gamma_{i}$ are the set of curves that span $S$, the dot symbolizes the derivative with respect to the individual curve parameters and the right-hand integration is performed over the appropriate set of parameter values.

\paragraph{Stokes' Theorem}
Stokes' theorem relates the integral of a differential form $d\omega$ over some subset $V$ of a manifold to an integral over $\bound{V}$ of another differential form. It states that
\begin{align*}
	\inte{V}{}\df{\omega} = \oint\limits_{\bound{V}}\omega.
\end{align*}