\section{Methodology}

Methodology is the study of the design of methods for gaining knowledge. It is different from general philosophy of science in that it does not contain, for instance, comparison, choice and justification of methods.

\paragraph{Choice of Method}
To answer the question of what methods should be chosen, three approaches are typically found:
\begin{itemize}
	\item The conventional approach, in which you choose the same methods as your teachers or peers.
	\item The outcome-oriented approach, in which you choose the method that gives the best results.
	\item The reason-based approach, in which you choose the method for which you have the overall best reasons. Reasons here means considerations of the method with respect to a set of goals that you want to achieve.
\end{itemize}

Their advantages and disadvantages may be summarized as in table \ref{tab:methodChoiceComp}.

\begin{table}[!ht]
	\centering
	\begin{tabular}{| l | p{2in} | p{2in} |}
		\hline
		\textbf{Approach} & \textbf{Advantages} & \textbf{Disadvantages} \\
		\hline
		Conventional      & \begin{itemize}[topsep = 0pt, itemsep = 0pt, partopsep = 0pt, parsep = 0pt, leftmargin = 12pt]
			\item Makes choices easy
		\end{itemize} & \begin{itemize}[topsep = 0pt, itemsep = 0pt, partopsep = 0pt, parsep = 0pt, leftmargin = 12pt]
			\item Leaves you less open to correcting methodological mistakes and being critical of your own results
			\item Makes it hard to collaborate with others due to inflexibililty
	    \end{itemize} \\
    	\hline
    	Outcome-oriented & \begin{itemize}[topsep = 0pt, itemsep = 0pt, partopsep = 0pt, parsep = 0pt, leftmargin = 12pt]
    		\item Oriented towards an intelligent choice of method
    	\end{itemize} & \begin{itemize}[topsep = 0pt, itemsep = 0pt, partopsep = 0pt, parsep = 0pt, leftmargin = 12pt]
    		\item Is too vague - what are the best results, for instance, and who judges this?
    		\item Science often involves long-term planning, so the optimal choice of method might be hard to know a priori
	    \end{itemize} \\
    	\hline
    	Reason-based & \begin{itemize}[topsep = 0pt, itemsep = 0pt, partopsep = 0pt, parsep = 0pt, leftmargin = 12pt]
    		\item Flexible
    	\end{itemize} & \begin{itemize}[topsep = 0pt, itemsep = 0pt, partopsep = 0pt, parsep = 0pt, leftmargin = 12pt]
    		\item Makes choices hard
    	\end{itemize} \\
    	\hline
	\end{tabular}
	\caption{Advantages and disadvantages of approaches to method choice.}
	\label{tab:methodChoiceComp}
\end{table}

\paragraph{Experimental Control}
Experimental control consists of identifying relevant features that might interfere with your experiment and being able to influence these features such that alternative explanations can be ruled out.

A few methods for implementing experimental control are:
\begin{itemize}
	\item Dividing your subjects into treatment and control groups.
	\item Keeping other factors constant by finding or creating situations with the same background.
	\item Eliminating background factors altogether by creating special circumstances. One way to do this is to blind your study.
	\item Separate out external factors by registering and accounting for their contribution.
\end{itemize}

\paragraph{Non-Experimental Procedures}
The types of experiments described by its definition are in principle limited to a lab environment, but there are other kinds of non-theoretical activities that are important in science, but are not experiments.

The first is observational studies, where you study subjects with no ability to manipulate, intervene or control the subjects.

The second is natural experiments, in which you have no ability to manipulate, but circumstances are equivalent to intervention and control having been done.

Next there are field experiments, in which you have the ability to manipulate, but some background factors cannot be controlled through manipulation.

A final one is simulation, where you have the ability to both manipulate, intervene and control, but only on a representation of your system.

\paragraph{Design Errors}
Erroneous design is design that fails to account for some background factor(s). It may manifest as:
\begin{itemize}
	\item Failure to control for all relevant factors.
	\item Confirmation bias(/interpretation problem) in observations.
	\item The observer effect(/influence problem) spoiling your results.
	\item The placebo effect interfering.
	\item Selection bias in your treatment and control groups.
\end{itemize}

To detect such errors, one might employ what knowledge one possesses, of either theory or experimental practice, to identify them, or one might investigate the repeatability, reproducibility and replicability of the experiment to find out where it might have gone wrong.

\paragraph{Randomization}
Randomization is the process of dividing samples into treatment and control groups using randomness. Experiments set up this way are called randomized control trials.

Randomness is desired because it might eliminate selection bias, help convince others that your experiment is not rigged and can be helpful in blinding the identity of the treatment from both investigators and subjects. However, randomization is not the only way to achieve these goals.

Randomization does not help to equally distribute background factors between the treatment and control groups. Imbalances may instead be avoided by being checked and controlled for. One might also use so-called stratified randomization, where background factors are included in the randomization process.

Randomization has no bearing of the broadness of your sample, meaning that it adds nothing to the generalizability of your results to other populations than that which you have sampled.

\paragraph{Blinding}
Blinding is the process of obscuring the identity of the control and treatment groups, with the purpose of removing observer effect. There is single blinding, where the subjects do not know whether they are in the treatment or control group, and double blinding, where neither the subject nor the experimenter knows to which group the subject belongs.

\paragraph{Reducing Error}
Random error can be reduced by repeating measurements and performing new operationalization in such a way that you obtain more precise measurements.

To reduce systematic error, one must identify the causes. One can only be sure that no systematic errors are present if one has a collection of measurement processes that both exhibit divergent validity individually and convergent validity collectively. If this is not found, the search begins, with few general guidelines. A few examples of places to look are background variables, observer effects and the stability and standardization of measurements.

The control of error represents a set of auxillary hypotheses which enter in the hypothetico-deductive method.

\paragraph{Statistics}
Statistics is a set of mathematical methods for dealing with quantitative data. It is divided into descriptive and inferential statistics.

\paragraph{Lying With Statistics}
The practice of lying with statistics involves taking good data and using proper statistical methods to produce false or misleading claims.

\paragraph{Methodology and Statistics}
The methodological aspects of statistics entail choosing the right statistical tool for some particular task, justifying the choice and choosing a proper representation of the data.

\paragraph{Why Use Statistical Inference?}
Statistical inference might be useful for hypothesis testing if:
\begin{itemize}
	\item The hypothesis has stochastic implications.
	\item One wants to quantify error or confidence.
\end{itemize}

Note that the statistical treatment generally weakens individual accounts of confirmations and falsification if the hypothesis is deterministic.

\paragraph{Fisher's Significance Testing}
Fisher's significance testing is a framework for rejecting hypotheses. Its steps are as follows:

\begin{enumerate}
	\item Specify a hypothesis $H$.
	\item Devise an experiment to test $H$ and specify the possible outcomes of the experiments.
	\item Determine the distribution of the test statistics.
	\item Observe the outcome of the experiment.
	\item Calculate the $p$-value, defined as the probability of observing a result as least as extreme as the observed one given $H$.
	\item If $p$ is smaller than some threshold value, termed the significance level, reject $H$.
\end{enumerate}

\paragraph{$p$-Value Abuse}
Fisher's significance testing leaves room for exploitation. A few examples of how this can be done are:
\begin{itemize}
	\item Modifying the hypothesis so as to mislead readers about what you have shown.
	\item Change the experiment or sample size until you get the desired result.
	\item Change how outcomes are partitioned.
	\item Use other sample distributions.
	\item Change the threshold.
\end{itemize}

\paragraph{Neyman-Pearson Testing}
Fisher's framework only leaves room for considering one hypothesis at a time. The Neyman-Pearson framework allows you to test two mutually exclusive and jointly exhaustive hypotheses. Labelling one of them as $H_{0}$, the outcome is designated according to the table below.

\begin{table}[!ht]
	\centering
	\begin{tabular}{| l | l | l |}
		\hline
		                    & $H_{0}$ is true & $H_{0}$ is false \\
		\hline
		$H_{0}$ is accepted & Correct         & Type-II error \\
		\hline
		$H_{0}$ is rejected & Type-I error    & Correct \\
		\hline
	\end{tabular}
	\caption{Designation of outcomes in Neyman-Pearson testing.}
\end{table}

The typical approach is to set the desired type-I error rate to some acceptable value and perform power analysis on your test given this. The power of the test is defined as the probability of rejecting $H_{0}$ given that it is true, and depends on the set type-I error rate, the magnitude of the effect of interest and the sample size. Once that is done, you compare the obtained $p$-value to the set type-I error rate and use that to accept or reject $H_{0}$.

\paragraph{Bayesian Statistics}
The Bayesian approach to statistics provides another way of using statistics for testing a hypothesis. In this approach, probabilities of hypotheses being true are interpreted as subjective confidence in hypotheses. The steps are:
\begin{enumerate}
	\item Formulate a set of competing hypothesis.
	\item Determine prior probabilities of each hypothesis being true.
	\item Collect data not used for informing your assignment of probabilities.
	\item Determine the probability of the data given the hypothesis.
	\item Compute the probability of the hypothesis given the data using Bayes' theorem.
	\item Update the prior probabilities using the above.
\end{enumerate}

Some issues with this approach include:
\begin{itemize}
	\item The issue of assign prior probabilities. This may be solved by approaching the issue in a subjectivist manner, where one realizes that as long as the priors are not $0$ or $1$ everyone will agree in the end, or an objectivist approach, where one starts the process by dividing one's belief equally between the hypotheses.
	\item The issue of old evidence, which may not be reused.
	\item The issue of uncertain evidence, as the Bayesian approach builds on letting the probability of the evidence occuring going to $1$.
\end{itemize}

\paragraph{Modelling Strategies}
I here introduce two modelling strategies. Their approaches reflect how we learn from models.

The first is to consider models as mirrors of the world. In this view you desire your model to be precise, a feature that you typically gain at the cost of simplicity, tractability and transparency. You will still not gain enough precision to avoid issues of external validity, i.e. to guarantee that the model describes the target.

The other view is to view models as isolations of relevant features of a system. This view requires that the target be divisible, at least to some extent, in such a way. It is also difficult to validate, as the target also has interaction effects.

\paragraph{Strategies for Identifying Causality}
While correlations are not sufficient or even necessary for causal relations, they are an important part of the evidence for certain causal relations. One strategy for identifying causal relations is Mill's method of difference, which has the drawback of requiring experiments. Another is instrumental variable analysis, defined by the following steps:
\begin{itemize}
	\item Observe a correlation between $X$ and $Y$.
	\item Find a variable $Z$ that is known to affect $X$, but not $Y$.
	\item Use $Z$ instead of $X$ when estimating the effect of $X$ on $Y$.
\end{itemize}
This strategy lets you work out causal relations only by observing correlations, but requires some causal knowledge in order to be implemented.

\paragraph{Interpretation of Behaviour}
The interpretation of human behaviour is an important part of qualitative studies. The process of interpretation may be explained using two frameworks. The first is simulation theory, where one's own cognitive mechanisms are used to simulate other people's mental state. The other is theory theory, in which a theory of the mind is constructed using evidence and hypotheses.

\paragraph{The Belief-Desire Explanation}
One way of explaining human behaviour is the following:
\begin{itemize}
	\item Assume $i$ desires outcome $X$ over $Y$.
	\item Assume $i$ to believe that action $A$ would bring about $X$ and not $Y$, while action $B$ would bring about $Y$ and not $X$.
	\item Infer that this explains why $i$ chose $A$ over $B$.
\end{itemize}

\paragraph{Methodological Behaviourism}
Methodological behaviourism is the rejection that mental states can be inferred, favouring instead the discovery of regularities between stimulus and and response.

\paragraph{Interpretation as Adopting the Intentional Stance}
Another way to interpret behaviour, human or otherwise, is to adopt the so-called intentional stance, described as follows:
\begin{itemize}
	\item Treat the object the behaviour of which is to be explained as rational.
	\item Figure out a set of beliefs and desires it ought to have given its place in the world and purpose.
	\item Decide what it ought to to given the attributed beliefs and desires.
	\item Predict that it will do what it ought to.
\end{itemize}

\paragraph{Construct Validity}
In observing human behaviour, we need to assume that there is a relationship between the mental attitude of the subject and its response to the investigation of the mental state. If this exists, the observation has construct validity.

\paragraph{Quality Criteria for Qualitative Methods}
The quality criteria for qualitative methods are:
\begin{itemize}
	\item repeatability.
	\item control of observer effect.
	\item reflection on observer bias.
	\item robustness, often ensured by the use of multiple investigation methods.
\end{itemize}

\paragraph{Interpretation Quality}
Interpretation is fallible. Notably, for a single input the process of interpretation involves many assignments of mental states, and many models provide plausible explanations for the same behaviour.

One solution is to avoid interpretation as a whole if possible, adopting methodological behaviourism.

Another solution is to take various steps to improve the quality of your interpretations. This can be done by
\begin{itemize}
	\item minimizing the scope of the interpretations.
	\item find more evidence to help in uncovering mental states and processes.
	\item ensure the competence of the observers.
	\item check for coherence in the interpretation.
	\item perform intersubjective checks with a colleague.
\end{itemize}

\paragraph{Case Studies}
A case study is a study characterized by a low number of cases, all chosen for specific reasons, displaying the same outcome with no experimental manipulation performed. The goal of case studies is to understand the specific case. This is in contrast to multivariate analyses, which involve many cases chosen randomly or representatively where a dependent variable varies and experimental manipulation is performed or mimiced. The goal of multivariate analyses is to identify and understand patterns.

There are many potential purposes for case studies. The first is simple falsification of some claim or hypothesis.

Another is the establishment of analytical narratives. This is done by
\begin{itemize}
	\item making a research question.
	\item selecting cases.
	\item using a narrative to elucidate the principal players, their preferences, key decision points and possibilities.
	\item the evaluation of the model through the testing of its implications.
	\item the consideration of alternative narratives.
\end{itemize}

Yet another possibility is qualitative comparative analysis, which is an analysis of a set of cases performed in order to gain a better understanding of the necessary causes.

Finally there is process tracing, which investigates cause-effect relations in a single case. The involved steps are:
\begin{enumerate}
	\item Formulate hypotheses about any mechanisms in the case.
	\item Work out differences in the empirical implications.
	\item Check the case data for mechanistic fingerprints.
	\item Conclude which mechanism applies.	
\end{enumerate}

\paragraph{Quality in Case Studies}
Steps that can be taken to improve case studies include:
\begin{itemize}
	\item Clearly stating research questions.
	\item Clearly specifying theory background and hypotheses.
	\item Clarifying what constitutes a case unit.
	\item Making case selection explicit.
	\item Specifying what makes different cases comparable.
	\item Investigating all implications of one's theoretical hypothesis.
	\item Investigating rival hypotheses.
\end{itemize}