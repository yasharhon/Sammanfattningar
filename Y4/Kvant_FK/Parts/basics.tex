\section{Basic Concepts}

\paragraph{Observables}
An observable is a Hermitian operator whose orthonormal eigenvectors form a basis.

\paragraph{The Postulates of Quantum Mechanics}
The postulates of quantum mechanics are:
\begin{itemize}
	\item At any fixed time the state of a physical system is specified by a ket in Hilbert space.
	\item Every measurable physical quantity corresponds to an operator on Hilbert space. This is a Hermitian observable. The possible outcomes of a measurement are the eigenvalues of $A$.
	\item The probability of measuring the value $a$ of operator $A$ in a normalized state $\ket{\Psi}$ is $P(a) = \expval{P_{a}}{\Psi}$, where $P_{a}$ is the projector onto the subspace corresponding to the eigenvalue $a$ given by $P_{a} = \dyad{a}{a}$.
	\item If a measurement of an observable $A$ gives an outcome $a$, the state of the system immediately after the measurement is the projection of the state onto the subspace with eigenvalue $a$.
	\item The time evolution of a state is governed by the Schrödinger equation.
\end{itemize}

\paragraph{Consequences of the Probability Picture}
The form of writing the projection operator implies $P(a) = \abs{\bra{a}\ket{\Psi}}^{2}$, or $P(a)\dd{a} = \abs{\bra{a}\ket{\Psi}}^{2}\dd{a}$ in the continuous case. In order for the probability interpretation to be consistent, i.e. for the sum of all probabilities to amount to $1$, it must hold that $\bra{\Psi}\ket{\Psi} = 1$.

\paragraph{Expectation Values}
Expectation values are given by
\begin{align*}
	\expval{A} = \sum aP(a) = \sum a\expval{P_{a}}{\Psi} = \bra{\Psi}\sum a\ket{a}\bra{a}\ket{\Psi} = \expval{A}{\Psi}.
\end{align*}

\paragraph{Physical States}
Modifying a state by a phase factor $e^{i\alpha}$ does not change any expectation values.

\paragraph{Pure and Mixed States}
Pure states are states with a well-defined state vector. Mixed states are states wherein the state vector is not well-defined.

\paragraph{Density Matrices}
The density matrix is defined as
\begin{align*}
	\rho = \op{\Psi}{\Psi}.
\end{align*}
It has some cool properties. For instance:
\begin{align*}
	&\tr{\rho} = \sum\limits_{n}\expval{\rho}{n} = \ev**{\sum\limits_{n}\op{n}{n}}{\psi} = \braket{\Psi} = 1, \\
	&\adj{\rho} = \rho, \\
	&\expval{A} = \sum\limits_{n, m}\braket{\Psi}{n}\mel{n}{A}{m}\braket{m}{\Psi} = \sum\limits_{n, m}\braket{m}{\Psi}\braket{\Psi}{n}\mel{n}{A}{m} = \sum\limits_{n, m}\mel{m}{\rho}{n}\mel{n}{A}{m} = \tr(\rho A), \\
	&\rho^{2} = \rho.
\end{align*}
%TODO: Introduce mixed states
Note that the latter is only true for pure states. Mixed states have a density matrix of the form
\begin{align*}
	\rho = \sum\limits_{j}P_{j}\op{\Psi_{j}}{\Psi_{j}},
\end{align*}
where the $P_{j}$ are the probability that the state of the system is $\ket{\Psi_{j}}$.

\paragraph{The Time Evolution Operator}
Consider the operator $u_{t'}(t)$ which evolves $\ket{\Psi(t')}$ to $\ket{\Psi(t)}$. Inserting it into the Schrödinger equation yields
\begin{align*}
	i\hbar\dv{t}u_{t^{\prime}}(t)\ket{\Psi(t^{\prime})} = Hu_{t^{\prime}}(t)\ket{\Psi(t^{\prime})}, \\
	i\hbar\del{t}{u_{t^{\prime}}} = Hu_{t^{\prime}}(t).
\end{align*}
It follows from In the case of a time-independent Hamiltonian, the solution must be of the form $u_{t^{\prime}}(t) = u(t - t^{\prime})$, and the equation above can be integrated to yield
\begin{align*}
	u_{t^{\prime}}(t) = e^{-i\frac{t - t^{\prime}}{\hbar}H}.
\end{align*}
Hence $H$ generates time translation - at least in time-independent cases.

\paragraph{Space and Space Translation}
We introduce the notion of space as a set of operators $x_{i}$ on the basis states. These operators are postulated to commute, as are their corresponding translations. The latter implies that their generators $k_{i}$ commute as well.

\paragraph{The Momentum Operator}
It turns out that the generators of space translations have a physical interpretation. TO understand this, we note that the generating function of a spatial translation in classical mechanics is
\begin{align*}
	F(\vb{x}, \vb{P}) = \vb{x}\cdot\vb{P} + \vb{p}\cdot\vb{x},
\end{align*}
which contains one term generating the identity and one causing the translation. We are therefore prompted to guess that $k_{i} \propto p_{i}$. When studying de Broglie waves, one finds that the constant of proportionality is $\hbar$. We thus arrive at the final analogue to the canonical commutation relations, namely
\begin{align*}
	\comm{x_{i}}{p_{j}} = i\hbar\delta_{ij}.
\end{align*}
One could of course have started with these as postulates instead, prompting a stronger analogy to classical mechanics. But the symmetry approach is nice too.

What is the representation of a momentum operator in the position basis? We have
\begin{align*}
	\left(1 - i\frac{\var{x_{i}}}{\hbar}p_{i}\right)\ket{\Psi} = \integ{}{}{\vb{x}}{\ket{\vb{x}}\braket{\vb{x} - \var{x}_{i}}{\Psi}} = \integ{}{}{\vb{x}}{\ket{\vb{x}}(\braket{\vb{x}}{\Psi} - \var{x}_{i}\del{x}{\braket{\vb{x}}{\Psi}})},
\end{align*}
implying
\begin{align*}
	\bra{\vb{x}}p_{i} = \frac{\hbar}{i}\del{x}{}.
\end{align*}

\paragraph{Spatial Inversion}
Let $\Pi$ be the spatial inversion operator such that $\Pi\vb{x}\Pi^{-1} = -\vb{x}$. We then have
\begin{align*}
	\vb{x}\Pi\ket{\vb{x}^{\prime}} = -\Pi\vb{x}\ket{\vb{x}^{\prime}} = -\vb{x}^{\prime}\Pi\ket{\vb{x}^{\prime}},
\end{align*}
hence $\Pi\ket{\vb{x}^{\prime}} = \ket{-\vb{x}^{\prime}}$, as the phase provided by spatial inversion may be chosen freely. Next we have
\begin{align*}
	\Pi\ket{\Psi} = \mel{\vb{x}}{\Pi}{\Psi} = \braket{-\vb{x}}{\Psi} = \Psi(-\vb{x}).
\end{align*}
Furthermore, we note that $\Pi^{2} = 1$, hence $\Pi$ has eigenvalues $\pm 1$ and $\Pi^{-1} = \Pi$.

\paragraph{Inversion Symmetry and Selection Rules}
Most observables are either even or odd under inversions, namely $\Pi A\Pi^{-1} = \pi_{A}A,\ \pi_{a} = \pm 1$. If we are working with states with definite parity, we have
\begin{align*}
	\mel{\Psi}{A}{\Phi} &= \pi_{a}\mel{\Psi}{\Pi A\Pi}{\Phi} \\
	                    &= \pi_{a}\pi_{\Psi}\pi_{\Phi}\mel{\Psi}{A}{\Phi},
\end{align*}
meaning that this matrix element is zero if $\pi_{a}\pi_{\Psi}\pi_{\Phi} = -1$. This is an example of a selection rule.

\paragraph{Time Reversal}
Time reversal should preserve position and flip the sign of momentum. This implies, however, that
\begin{align*}
	T(i\hbar)T^{-1} = -i\hbar,
\end{align*}
which can only be satisfied if $T$ is anti-linear and anti-unitary. It can be shown that for spinless particles, the time reversal operator is simply the complex conjugation operator.

\paragraph{Kramer's Degeneracy}
Consider a system which is invariant under time reversal. It would seem that for any eigenvector $\ket{E}$, there must also exist an eigenvector $T\ket{E}$. However, in cases with spin-$\frac{1}{2}$, for which $T^{2} = -1$, we have
\begin{align*}
	\mel{E}{T}{E} &= \cc{(\bra{TE})(\ket{T^{2}E})} = -\cc{(\bra{TE})(\ket{E})} = -\mel{E}{T}{E},
\end{align*}
implying the two vectors are orthogonal. This is called Kramer's degeneracy.

\paragraph{Time Evolution of the Density Matrix}
The time evolution of the density matrix is given by
\begin{align*}
	\rho(t) = \sum P_{i}u_{t_{0}}(t)\ket{\Psi_{i}}\bra{\Psi_{i}}\adj{u_{t_{0}}(t)} = u_{t_{0}}(t)\rho(t_{0})\adj{u_{t_{0}}(t)}.
\end{align*}
This implies
\begin{align*}
	i\hbar\dv{t}\rho = Hu_{t_{0}}(t)\rho(t_{0})\adj{u_{t_{0}}(t)} - u_{t_{0}}(t)\rho(t_{0})\adj{u_{t_{0}}(t)}H = H\rho(t) - \rho(t)H = \comm{H}{\rho}.
\end{align*}

\paragraph{The Heisenberg Equation}
Heisenberg's outlook starts from preserving expectation values under time translations in such a way that all (total) time evolution is contained in the operators, arriving at the transformation rule
\begin{align*}
	A_{\text{H}} = \adj{u_{t_{0}}}(t)A_{\text{S}}u_{t_{0}}(t).
\end{align*}
$A_{\text{H}}$ is the operator according to Heisenberg and $A_{\text{S}}$ is the operator according to Schrödinger. We now have
\begin{align*}
	i\hbar\dv{t}\expval{A_{\text{H}}} &= -\adj{u_{t_{0}}}(t)HA_{\text{S}}u_{t_{0}}(t) + \adj{u_{t_{0}}}(t)(i\hbar\del{t}{A_{\text{S}}})u_{t_{0}}(t) + \adj{u_{t_{0}}}(t)A_{\text{S}}Hu_{t_{0}}(t) \\
	                                  &= -\adj{u_{t_{0}}}(t)Hu_{t_{0}}(t)\adj{u_{t_{0}}}(t)A_{\text{S}}u_{t_{0}}(t) + \adj{u_{t_{0}}}(t)(i\hbar\del{t}{A_{\text{S}}})u_{t_{0}}(t) + \adj{u_{t_{0}}}(t)A_{\text{S}}u_{t_{0}}(t)\adj{u_{t_{0}}}(t)Hu_{t_{0}}(t) \\
	                                  &= -H_{\text{H}}A_{\text{H}} + \adj{u_{t_{0}}}(t)(i\hbar\del{t}{A_{\text{S}}})u_{t_{0}}(t) + A_{\text{H}}H_{\text{H}} \\
	                                  &= -{H_{\text{H}}}\comm{A_{\text{H}}} + (i\hbar\del{t}{A_{\text{S}}})_{\text{H}}.
\end{align*}

\paragraph{Propagators}
The probability amplitude at some point $x$ at time $t$ is given by
\begin{align*}
	\Psi(x, t) = \braket{x}{\Psi(t)} = \mel{x}{u_{0}(t)}{\Psi(0)} = \integ{}{}{x^{\prime}}{\mel{x}{u_{0}(t)}{x^{\prime}}\braket{x^{\prime}}{\Psi(0)}}.
\end{align*}
Defining the propagator $G_{x^{\prime}, t^{\prime}}(x, t) = \mel{x}{u_{t^{\prime}}(t)}{x^{\prime}}$, we arrive at
\begin{align*}
	\Psi(x, t) = \integ{}{}{x^{\prime}}{G_{x^{\prime}, 0}(x, t)\braket{x^{\prime}}{\Psi(0)}} = \integ{}{}{x^{\prime}}{G_{x^{\prime}, 0}(x, t)\Psi(x^{\prime}, 0)}.
\end{align*}
Hence the propagator acts as a Green's function with respect to time, in some sense.

\paragraph{Arriving at Path Integrals}
The general propagator of some state is given by
\begin{align*}
	G_{x^{\prime}, t^{\prime}}(x, t) = \sum\limits_{\gamma}G_{\gamma; x^{\prime}, t^{\prime}}(x, t),
\end{align*}
where the summation is performed over all possible paths $\gamma$ between the two points.

Suppose now that the time evolution is divided into steps such that
\begin{align*}
	u_{t^{\prime}}(t) = \prod\limits_{k = 1}^{n}u_{t_{k - 1}}(t_{k}),\ t_{0} = t^{\prime},\ t_{n} = t,\ t_{k} - t_{k - 1} = \delta t.
\end{align*}
Then
\begin{align*}
	G_{x^{\prime}, t^{\prime}}(x, t) = \mel**{x}{\prod\limits_{k = 1}^{n}u_{t_{k - 1}}(t_{k})}{x^{\prime}}.
\end{align*}
For every $k$ we now introduce an identity according to
\begin{align*}
	G_{x^{\prime}, t^{\prime}}(x, t) &= \mel**{x}{\prod\limits_{k = 1}^{n}u_{t_{k - 1}}(t_{k})\integ{}{}{x_{k}}{\op{x_{k - 1}}{x_{k - 1}}}}{x^{\prime}} \\
	                                 &= \mel**{x}{\prod\limits_{k = 1}^{n}\integ{}{}{x_{k}}{u_{t_{k - 1}}(t_{k})\op{x_{k - 1}}{x_{k - 1}}}}{x^{\prime}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}\mel{x_{k}}{u_{t_{k - 1}}(t_{k})}{x_{k - 1}}.
\end{align*}
The time translation operator has the form $u_{t_{k - 1}}(t_{k}) = e^{-i\frac{\Delta t}{\hbar}H}$. For a Hamiltonian of the form $H = \frac{p^{2}}{2m} + V(\vb{x})$, the terms do not necessarily commute. However, to second order we have
\begin{align*}
	e^{\alpha A}e^{\alpha B} &= \left(1 + \alpha A + \frac{1}{2}\alpha^{2}A^{2} + \dots\right)\left(1 + \alpha B + \frac{1}{2}\alpha^{2}B^{2} + \dots\right), \\
	e^{\alpha(A + B)}  &= 1 + \alpha A + \alpha B + \frac{1}{2}\alpha^{2}(A^{2} + B^{2} + AB + BA) + \dots, \\
	           &= e^{A}e^{B}\left(1 - \frac{1}{2}\alpha^{2}AB + \frac{1}{2}\alpha^{2}BA + \dots\right) \\
	           &= e^{\alpha A}e^{\alpha B}e^{\frac{1}{2}\alpha^{2}\comm{A}{B}}.
\end{align*}
Ignoring the second-order term yields
\begin{align*}
	G_{x^{\prime}, t^{\prime}}(x, t) &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}\mel{x_{k}}{e^{-i\frac{\Delta t}{\hbar}(T + V)}}{x_{k - 1}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}\mel{x_{k}}{e^{-i\frac{\Delta t}{\hbar}T}}{x_{k - 1}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}\mel**{x_{k}}{e^{-i\frac{\Delta t}{\hbar}T}\integ{}{}{p_{k}}{\op{p_{k}}{p_{k}}}}{x_{k - 1}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}\mel**{x_{k}}{\integ{}{}{p_{k}}{e^{-i\frac{\Delta t}{\hbar}T}\op{p_{k}}{p_{k}}}}{x_{k - 1}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}\integ{}{}{p_{k}}{e^{-i\frac{\Delta t}{2m\hbar}p_{k}^{2}}\braket{x_{k}}{p_{k}}\braket{p_{k}}}{x_{k - 1}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}\integ{}{}{p_{k}}{e^{-i\frac{\Delta t}{2m\hbar}p_{k}^{2}}\frac{1}{2\pi\hbar}e^{i\frac{p_{k}(x_{k} - x_{k - 1})}{\hbar}}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}e^{i\frac{m}{2\hbar\Delta t}(x_{k} - x_{k - 1})^{2}}\frac{1}{2\pi\hbar}\integ{}{}{p_{k}}{e^{-i\frac{\Delta t}{2m\hbar}\left(p_{k} - \frac{m}{\Delta t}(x_{k} - x_{k - 1})\right)^{2}}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}e^{i\frac{m}{2\hbar\Delta t}(x_{k} - x_{k - 1})^{2}}\sqrt{\frac{m}{2\pi^{2}\hbar\Delta ti}}\integ{}{}{v_{k}}{e^{-v_{k}^{2}}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}e^{-i\frac{\Delta t}{\hbar}V(x_{k - 1})}e^{i\frac{m}{2\hbar\Delta t}(x_{k} - x_{k - 1})^{2}}\sqrt{\frac{m}{2\pi\hbar\Delta ti}} \\
	                                 &= \int\prod\limits_{k = 1}^{n}\dd{x_{k}}\sqrt{\frac{m}{2\pi\hbar\Delta ti}}e^{i\frac{1}{\hbar}\sum\limits_{k = 1}^{n}\left(\frac{1}{2}m\left(\frac{x_{k} - x_{k - 1}}{\Delta t}\right)^{2} - V(x_{k - 1})\right)\Delta t}.
\end{align*}
In the continuous limit the exponent becomes
\begin{align*}
	i\frac{1}{\hbar}\integ{}{}{t}{\frac{1}{2}m\dot{x}^{2} - V(x)} = i\frac{S}{\hbar}
\end{align*}
where $S$ is the action. The remaining factor, termed the measure, is
\begin{align*}
	D(x(t)) = \lim\limits_{\Delta t \to 0}\prod\limits_{k = 1}^{n}\dd{x_{k}}\sqrt{\frac{m}{2\pi\hbar\Delta ti}}.
\end{align*}
Finally the propagator is given by
\begin{align*}
	G_{x^{\prime}, t^{\prime}}(x, t) &= \int D(x(t))e^{-i\frac{S}{\hbar}}.
\end{align*}
This is termed the path integral.

As a side note, if the action is large compared to $\hbar$, the action varies strongly, causing destructive interference from all paths except for the one such that
\begin{align*}
	\fdv{S}{x} = 0.
\end{align*}
This is Hamilton's principle, the fundamental postulate of classical mechanics.

\paragraph{The Harmonic Oscillator}
The Hamiltonian of the harmonic oscillator is
\begin{align*}
	H = \frac{1}{2m}p^{2} + \frac{1}{2}m\omega^{2}x^{2}.
\end{align*}
To diagonalize it we introduce the lowering operator
\begin{align*}
	a = \frac{1}{\sqrt{2}}\left(\sqrt{\frac{m\omega}{\hbar}}x + \frac{i}{\sqrt{m\omega\hbar}}p\right)
\end{align*}
and its adjoint, the raising operator. Their commutator is
\begin{align*}
	\comm{a}{\adj{a}} &= \comm{\frac{1}{\sqrt{2}}\left(\sqrt{\frac{m\omega}{\hbar}}x + \frac{i}{\sqrt{m\omega\hbar}}p\right)}{\frac{1}{\sqrt{2}}\left(\sqrt{\frac{m\omega}{\hbar}}x - \frac{i}{\sqrt{m\omega\hbar}}p\right)} \\
	                  &= \comm{\frac{1}{\sqrt{2}}\sqrt{\frac{m\omega}{\hbar}}x}{-\frac{1}{\sqrt{2}}\frac{i}{\sqrt{m\omega\hbar}}p} + \comm{\frac{1}{\sqrt{2}}\frac{i}{\sqrt{m\omega\hbar}}p}{\frac{1}{\sqrt{2}}\sqrt{\frac{m\omega}{\hbar}}x} \\
	                  &= \frac{1}{2}\frac{i}{\hbar}\left(\comm{x}{-p} + \comm{p}{x}\right) \\
	                  &= 1.
\end{align*}
The definition of the raising and lowering operators may be inverted to obtain
\begin{align*}
	x = \frac{1}{\sqrt{2}}\sqrt{\frac{\hbar}{m\omega}}(\adj{a} + a),\ p = \frac{i}{\sqrt{2}}\sqrt{m\omega\hbar}(\adj{a} - a).
\end{align*}
The Hamiltonian may now be written in terms of these operators as
\begin{align*}
	H &= \frac{1}{2m}\cdot -\frac{1}{2}m\omega\hbar(\adj{a} - a)^{2} + \frac{1}{2}m\omega^{2}\frac{1}{2}\frac{\hbar}{m\omega}(\adj{a} + a)^{2} \\
	  &= -\frac{1}{4}\hbar\omega(\adj{a} - a)^{2} + \frac{1}{4}\hbar\omega(\adj{a} + a)^{2} \\
	  &= \frac{1}{4}\hbar\omega\left((\adj{a})^{2} + \adj{a}a + a\adj{a} + a^{2} - \left((\adj{a})^{2} - \adj{a}a - a\adj{a} + a^{2}\right)\right) \\
	  &= \frac{1}{2}\hbar\omega\left(\adj{a}a + a\adj{a}\right) \\
	  &= \hbar\omega\left(\adj{a}a + \frac{1}{2}\right).
\end{align*}
We now define the operator $n = \adj{a}a$. It is Hermitian, meaning that an orthonormal basis of its eigenvectors exists (fortunately, as it constitutes the Hamiltonian). These eigenvectors must be studied next. To do this, we use the commutation relations\footnote{What might inspire this? A suggestion might be the fact that if $n$ and the raising and lowering operators commuted, we would find that they share eigenvectors.}
\begin{align*}
	\comm{n}{a} = \adj{a}\comm{a}{a} + \comm{\adj{a}}{a}a = -a,\ \comm{n}{\adj{a}} = \adj{a}\comm{a}{\adj{a}} + \comm{\adj{a}}{\adj{a}}a = \adj{a}
\end{align*}
applied to some eigenvector $\ket{\nu}$ with eigenvalue $\nu$ to obtain
\begin{align*}
	na\ket{\nu} = (an - a)\ket{\nu} = (\nu - 1)a\ket{\nu}.
\end{align*}
Hence, if some eigenvalue $\nu$ exists, we can repeat this argument to show that $\nu - 1,\ \nu - 2, \dots$ are also eigenvalues, assuming no value in this sequence is zero. The length of these eigenvectors is given by
\begin{align*}
	\expval{\adj{a}a}{\nu} = \nu\braket{\nu} \geq 0,
\end{align*}
where the latter is due to the positivity of the inner product. In order for this to work, no negative eigenvalues may exist. This only fits with the previous sequence of eigenvalues if $\nu = 0$ is an eigenvalue.

Having established that, we rename the eigenvalues to $n$. Next, we have
\begin{align*}
	n\adj{a}\ket{n} = (\adj{a}n + \adj{a})\ket{n} = (n + 1)\adj{a}\ket{n}.
\end{align*}
Hence the sequence $n + 1, n + 2, \dots$ also consists of eigenvalues of $n$. The length of such vectors is
\begin{align*}
	\expval{a\adj{a}}{n} = \expval{\adj{a}a + 1}{n} = (n + 1)\braket{n} > 0.
\end{align*}
Now the eigenvalues of the Hamiltonian are found to be
\begin{align*}
	H_{n} = \hbar\omega\left(n + \frac{1}{2}\right),\ H\ket{n} = H_{n}\ket{n}.
\end{align*}

With respect to degeneracy, suppose there is a set of eigenvectors denoted by the index $k$ such that $a\ket{0, k} = 0$. In the coordinate basis we obtain
\begin{align*}
	\mel**{x}{\frac{1}{\sqrt{2}}\left(\sqrt{\frac{m\omega}{\hbar}}x + \frac{i}{\sqrt{m\omega\hbar}}p\right)}{0, k} = \frac{1}{\sqrt{2}}\left(\sqrt{\frac{m\omega}{\hbar}}x + \sqrt{\frac{\hbar}{m\omega}}\dv{x}\right)\Psi_{0, k} = 0.
\end{align*}
The solution to this differential equation is unique, hence the ground state is non-degenerate. The linearity of the raising operator therefore implies that the other eigenvalues are non-degenerate as well.

With respect to normalization, we may require all states to be normalized. Then
\begin{align*}
	\adj{a}\ket{n}      &= c_{n + 1}\ket{n + 1}, \\
	\abs{c_{n + 1}}^{2} &= \expval{a\adj{a}}{n} = \expval{n + 1}{n} = n + 1, \\
	c_{n}               &= \sqrt{n}.
\end{align*}
Next we have
\begin{align*}
	a\adj{a}\ket{n - 1} &= \sqrt{n}a\ket{n} \\
	n\ket{n - 1}        &= \sqrt{n}a\ket{n}, \\
	a\ket{n}            &= \sqrt{n}\ket{n - 1}.
\end{align*}

Finally, the excited states may be found according to
\begin{align*}
	\ket{n} = \frac{1}{\sqrt{n}}\adj{a}\ket{n - 1} = \dots = \frac{1}{\sqrt{n!}}(\adj{a})^{n}\ket{0},
\end{align*}
which when applied to the ground state will reproduce some special function.

\paragraph{Symmetries and Conserved Quantities}
Suppose that there exists some unitary transformation $u = e^{-i\frac{\varepsilon}{\hbar}A}$ such that $\adj{u}Hu = H$. Expanding the symmetry yields
\begin{align*}
	\left(1 + i\frac{\varepsilon}{\hbar}A + \dots\right)H\left(1 - i\frac{\varepsilon}{\hbar}A + \dots\right) = H + i\frac{\varepsilon}{\hbar}(-HA + AH) + \dots = H + i\frac{\varepsilon}{\hbar}\comm{A}{H} + \dots = H,
\end{align*}
implying that $A$ and $H$ commute. Assuming $A$ to have no explicit time dependence, Heisenberg's equations yield that $\expval{A}$ is conserved. These arguments form the basis of some form of Nöether's theorem in quantum mechanics.

\paragraph{Quantum Hall Effect}
The Hamiltonian of a charged particle in a magnetic field is
\begin{align*}
	H = \frac{1}{2m}(\vb{p} - q\vb{A})^{2}.
\end{align*}
We recall that gauge transformations of the electromagnetic field are defined according to $A^{\mu} \to A^{\mu} - \del[\mu]{}{\chi}$ for some function $\chi$. While Maxwell's equations are gauge invariant, Schrödinger's equation is not. We try to remedy this by combining the gauge transformation with a transformation
\begin{align*}
	\ket{\Psi} \to e^{i\frac{q}{\hbar}\chi}\ket{\Psi}.
\end{align*}
The inverse transformation yields
\begin{align*}
	(\vb{p} - q\vb{A})\ket{\Psi} = (\vb{p} - q(\vb{A} - \grad{\chi}))e^{-i\frac{q}{\hbar}\chi}\ket{\Psi},
\end{align*}
which is given by
\begin{align*}
	(\vb{p} - q(\vb{A} - \grad{\chi}))e^{-i\frac{q}{\hbar}\chi}\ket{\Psi} &= e^{i\frac{q}{\hbar}\chi}(\vb{p} - q\grad{\chi} - q(\vb{A} - \grad{\chi}))\ket{\Psi} = e^{-i\frac{q}{\hbar}\chi}(\vb{p} - q\vb{A})\ket{\Psi},
\end{align*}
implying that the transformation does not change the Schrödinger equation.

We will start by studying two-dimensional motion in a rectangular domain with a constant magnetic field in the $z$-direction. In the Landau gauge we choose the vector potential $\vb{A} = Bx\ub{x}$. The Hamiltonian is thus
\begin{align*}
	H = \frac{1}{2m}\left(p_{x}^{2} + (p_{y} - qBx)^{2}\right).
\end{align*}
We see that the Hamiltonian commutes with $p_{y}$, but not with $p_{x}$, implying that the solution is of the form
\begin{align*}
	\Psi(\vb{x}) = \frac{1}{\sqrt{2\pi\hbar}}e^{-ik_{y}y}f(x),
\end{align*}
where $k_{y} = \frac{1}{\hbar}p_{y}$ may be taken to have a definite value. We are thus left with
\begin{align*}
	H = \frac{1}{2m}\left(p_{x}^{2} + \hbar^{2}\left(k_{y} - \frac{1}{l_{B}^{2}}x\right)^{2}\right),\ l_{B}^{2} = \frac{\hbar}{qB}.
\end{align*}
We solve this by introducing raising and lowering operators
\begin{align*}
	a_{k_{y}} = \frac{1}{\sqrt{2}}\left(\frac{x - k_{y}l_{B}^{2}}{l_{B}} + i\frac{l_{B}}{\hbar}p_{x}\right)
\end{align*}
such that
\begin{align*}
	H = \hbar\omega(\adj{a_{k_{y}}}a_{k_{y}} + \frac{1}{2}),
\end{align*}
yielding a harmonic oscillator with the classical cyclotron frequency
\begin{align*}
	\omega = \frac{\hbar}{ml_{B}^{2}} = \frac{eB}{m}.
\end{align*}
The energy levels of this harmonic oscillator are called Landau levels.

To study the degeneracy, we impose periodic boundary conditions in the $y$-direction, implying
\begin{align*}
	k_{y} = \frac{2\pi}{L_{y}}m.
\end{align*}
If you have a large but finite sample of length $L_{x}$ in the $x$-direction, the fact that the state is localized around $k_{y}l_{B}^{2}$ implies that the maximum value of $m$ is
\begin{align*}
	N = \frac{L_{x}}{l_{B}^{2}\frac{2\pi}{L_{y}}} = \frac{qBA}{h}.
\end{align*}
In particular, for $q = e$ we have
\begin{align*}
	H = \frac{\Phi}{\Phi_{0}},
\end{align*}
where $\Phi_{0} = \frac{h}{e}$ is the flux quantum.

To study samples at the edge of the sample, add a potential to represent the edge and assume that it varies slowly when compared to the length scale $l_{B}$. In this case the eigenvalues are modified to
\begin{align*}
	E_{n} = \hbar\omega(n + \frac{1}{2}) + V(x = = -k_{y}l_{B}^{2})
\end{align*}
The edge states (perhaps) carry the current, meaning that such systems that we have studied will display steps in their Hall coefficient. This is the quantum Hall effect.

\paragraph{Aharanov-Bohm Effect}
To demonstrate the principle, consider a metal ring connected to two terminals with magnetic flux through the middle and suppose that current flows from one terminal to the other. The vector potential is non-zero in the ring, and may in fact be written as $\vb{A} = \grad{f}$ here. Performing a gauge transformation preserves the Schrödinger equation, as before. Now, as we may write
\begin{align*}
	f = \integ{\gamma}{}{\vb{x}}{\cdot\vb{A}},
\end{align*}
this implies that the phase of the state is determined by the path taken. Combining this with our knowledge of path integrals yields the transmittion probability
\begin{align*}
	T = \abs{t_{\text{upper}}}^{2} + \abs{t_{\text{lower}}}^{2} + 2\Re\left(t_{\text{upper}}\cc{t_{\text{upper}}}e^{iq\left(\integ{\gamma_{\text{lower}}}{}{\vb{x}}{\cdot\vb{A}} - \integ{\gamma_{\text{upper}}}{}{\vb{x}}{\cdot\vb{A}}\right)}\right) = \abs{t_{\text{upper}}}^{2} + \abs{t_{\text{lower}}}^{2} + 2\Re\left(t_{\text{upper}}\cc{t_{\text{upper}}}e^{-iq\Phi}\right).
\end{align*}
This oscillating transmission probability is the Aharanov-Bohm effect.